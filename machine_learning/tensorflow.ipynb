{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3aa77d0",
   "metadata": {},
   "source": [
    "- CNN to autoencoder for dim reduction\n",
    "- Clustering algorithms\n",
    "- Regression problem with multiple probabilities, as opposed to a classification problem with binary probabilities\n",
    "- How to tell if points are spherical or not? Or if they're a bit like high dimensional moons, all overlapping and tangled together?\n",
    "- Look at adding a [calibration plot](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py)\n",
    "- Restructure loss function to fully reward a model that correctly predicts at least one of a contiguous stretch of non255 labels as being the correct label.\n",
    "\n",
    "```\n",
    "y_true: .....1111.......2222.....33333.........4444.........\n",
    "y_pred: ....11..........2222........33333............4444...\n",
    "reward  0000111110000000111100000011111110000000000000000000\n",
    "```\n",
    "\n",
    "#### Low precision model:\n",
    "Of all items labelled as X, how many are actually X?\n",
    "```\n",
    "y_true: .......11111.......\n",
    "y_pred: .....111111111.....\n",
    "```\n",
    "\n",
    "#### Low recall model:\n",
    "Of all items that are actually X, how many are labelled X?\n",
    "```\n",
    "y_true: .......11111.......\n",
    "y_pred: .........1.........\n",
    "```\n",
    "\n",
    "Try smoothing out the labels, so that they're gradually become more certain of gestureX and then gradually less certain of gestureX instead of instantly gestureX and instantly not gestureX\n",
    "\n",
    "Try using a segmentation NN instead of a different NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d7bfe",
   "metadata": {},
   "source": [
    "New metric: Of all the contiguous sequences, how many of them are classified correctly?\n",
    "\n",
    "Or, number of timesteps to mean of each gesture???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1551f",
   "metadata": {},
   "source": [
    "#### Things to try\n",
    "- Create a real-time visualiser for the data\n",
    "- Create a model that uses xcorr (or just corr?) to predict classes.\n",
    "    - It takes an input class, and figures out which of the given examples in the input class best fits all other examples in that class\n",
    "    - Then repeat on all other classes\n",
    "    - The result is an ensamble of one-vs-rest predictors\n",
    "- Create a wrapper to do some basic hyperparameter tuning based on window size and some other things\n",
    "- Recurrent/LSTM: Don't know if this will actually help\n",
    "- Convolutional NN: Couldn't get it working\n",
    "- Dropout\n",
    "- Preprocess so that the accelerations are orientation invariant\n",
    "- Visualise *every* incorrectly labelled observation. i.e. every example of predicted 255, actually 001 on one figure\n",
    "- Algorithmic simplification of a NN? Given a large NN, can you create a smaller NN which is mathematically identical to the larger one? or identical to within some small error\n",
    "- Maybe a decision tree that only looks at ~10 features per branch\n",
    "- Ensamble of models, one for each finger\n",
    "\n",
    "- AI Assignement 3: Find a general way of classifying benchmark problems. Maybe fourier analysis\n",
    "\n",
    "\n",
    "### Use mode, median, mean for resolving votes from regression ensambles\n",
    "- Regression ensembles give you multiple continuous values which need to be resolved to a single value\n",
    "- the arithmetic mean and the median is bad because it doesn't work for non-gaussian or multimodal data.\n",
    "- Try use KDE and then finding the mode(s) of the regression outputs to give a good estimate\n",
    "- also look into voting theory to figure out how to resolve the votes in an optimal way\n",
    "\n",
    "\n",
    "#### To separate the 255 class from others:\n",
    "- FFT before doing anomaly detection?\n",
    "- Dynamic time warping to try automatically cluster the gestures\n",
    "- Anomoly detection via SVM\n",
    "- Dynamic time warping as the distance metric for kmeans\n",
    "\n",
    "\n",
    "1. ~Try expanding the dataset~\n",
    "2. ~Try just using xcorr~ or dynamic time warping\n",
    "3. Try recording some examples and visualising them to see the problems\n",
    "\n",
    "\n",
    "Problem: Need a loss function that better reflects the reality. Just changing the label offset and window size might be detrimental to actual performance.\n",
    "\n",
    "Maybe set it up so the model just detects if there's a gesture anywhere in the window, and then there's a post processor that only recognises the rising edge of predictions\n",
    "\n",
    "Figure out some other gestures\n",
    "\n",
    "~remove gravity from gestures?~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999271bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T08:53:40.269859Z",
     "start_time": "2022-10-23T08:53:37.133004Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' #Don't print TF INFO messages\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "from ipywidgets import interact\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96a188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T21:00:37.273378Z",
     "start_time": "2022-10-23T21:00:37.220004Z"
    },
    "code_folding": [
     0,
     2,
     36,
     53,
     75,
     82,
     244,
     294,
     320,
     333,
     363,
     429,
     452,
     455,
     478,
     546,
     549,
     601
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function and constant definitions\n",
    "\n",
    "FINGERS = [\n",
    "    'left-5-x',\n",
    "    'left-5-y',\n",
    "    'left-5-z',\n",
    "    'left-4-x',\n",
    "    'left-4-y',\n",
    "    'left-4-z',\n",
    "    'left-3-x',\n",
    "    'left-3-y',\n",
    "    'left-3-z',\n",
    "    'left-2-x',\n",
    "    'left-2-y',\n",
    "    'left-2-z',\n",
    "    'left-1-x',\n",
    "    'left-1-y',\n",
    "    'left-1-z',\n",
    "    'right-1-x',\n",
    "    'right-1-y',\n",
    "    'right-1-z',\n",
    "    'right-2-x',\n",
    "    'right-2-y',\n",
    "    'right-2-z',\n",
    "    'right-3-x',\n",
    "    'right-3-y',\n",
    "    'right-3-z',\n",
    "    'right-4-x',\n",
    "    'right-4-y',\n",
    "    'right-4-z',\n",
    "    'right-5-x',\n",
    "    'right-5-y',\n",
    "    'right-5-z',\n",
    "]\n",
    "\n",
    "\n",
    "def make_batches(X, y, t, window_size=10, window_skip=1):\n",
    "    assert window_skip == 1, 'window_skip is not supported for values other than 1'\n",
    "    ends = np.array(range(window_size, len(y)))\n",
    "    starts = ends - window_size\n",
    "    batched_X = np.empty((ends.shape[0], window_size, X.shape[1]))\n",
    "    batched_y = np.empty((ends.shape[0],), dtype='object')\n",
    "    for i, (start, end) in enumerate(zip(starts, ends)):\n",
    "        # Don't add the X,y pair if it would go over a time boundary\n",
    "        if any(np.diff(t[start:end]) > np.timedelta64(5, 's')):\n",
    "            continue\n",
    "        batched_X[i] = X[start:end]\n",
    "        batched_y[i] = y[end]\n",
    "    batched_X = batched_X[pd.notna(batched_y)]\n",
    "    batched_y = batched_y[pd.notna(batched_y)]\n",
    "    return batched_X, batched_y\n",
    "\n",
    "\n",
    "def gestures_and_indices(y):\n",
    "    labels = sorted(np.unique(y))\n",
    "    g2i_dict = {g: i for i, g in enumerate(labels)}\n",
    "    i2g_dict = {i: g for i, g in enumerate(labels)}\n",
    "\n",
    "    def g2i(g):\n",
    "        not_list = type(g) not in [list, np.ndarray]\n",
    "        if not_list:\n",
    "            g = [g]\n",
    "        result = np.array([g2i_dict.get(gi, gi) for gi in g])\n",
    "        return result[0] if not_list else result\n",
    "\n",
    "    def i2g(i):\n",
    "        not_list = type(i) not in [list, np.ndarray]\n",
    "        if not_list:\n",
    "            i = [i]\n",
    "        result = np.array([i2g_dict.get(ii, ii) for ii in i])\n",
    "        return result[0] if not_list else result\n",
    "\n",
    "    return g2i, i2g\n",
    "\n",
    "\n",
    "def one_hot_and_back(y_all):\n",
    "    return (\n",
    "        lambda y: tf.one_hot(y, len(np.unique(y_all))),\n",
    "        lambda onehot: tf.argmax(one_hot, axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def conf_mat(y_true, y_pred, perc=None, hide_zeros=True, ax=None, cbar=True):\n",
    "    assert perc in ['cols', 'rows', 'both', None]\n",
    "#     y_pred = np.argmax(model.predict(X, verbose=0), axis=1)\n",
    "#     y_true = y\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "\n",
    "    axis = None\n",
    "    if perc == 'cols':\n",
    "        axis = 0\n",
    "        confusion_mtx = confusion_mtx / confusion_mtx.sum(axis=axis) * 100\n",
    "    elif perc == 'rows':\n",
    "        axis = 1\n",
    "        confusion_mtx = (confusion_mtx.T /\n",
    "                         confusion_mtx.sum(axis=axis) * 100).T\n",
    "    elif perc == 'both':\n",
    "        axis = (0, 1)\n",
    "        confusion_mtx = confusion_mtx / confusion_mtx.sum() * 100\n",
    "    elif perc is None:\n",
    "        axis = None\n",
    "\n",
    "    zero_mask = np.where(confusion_mtx == 0)\n",
    "    not_zero_mask = np.where(confusion_mtx != 0)\n",
    "    confusion_mtx = np.round(confusion_mtx).astype(int)\n",
    "\n",
    "    to_print = np.empty(confusion_mtx.shape, dtype='object')\n",
    "    to_print[zero_mask] = ''\n",
    "    to_print[not_zero_mask] = confusion_mtx[not_zero_mask].astype(str)\n",
    "\n",
    "    labels = [i2g(i).replace('gesture0', 'g') for i in range(confusion_mtx.shape[0])]\n",
    "        \n",
    "    sns.heatmap(\n",
    "        confusion_mtx,\n",
    "        annot=to_print,\n",
    "        fmt='',\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        square=True,\n",
    "        cbar=cbar,\n",
    "        vmin=confusion_mtx.min(),\n",
    "#         vmax=confusion_mtx[:-1, :-1].max(),# if perc == None else confusion_mtx.max(),\n",
    "        ax=ax\n",
    "    )\n",
    "    if ax is None:\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "    else:\n",
    "        ax.set_xlabel('Predicted Label')\n",
    "        ax.set_ylabel('True Label')\n",
    "    return confusion_mtx\n",
    "\n",
    "\n",
    "def plot_timeseries(X, y, t=None, per='dimension', axs=None, draw_text=True):\n",
    "    # Make sure the given dataset is correctly formatted\n",
    "    assert X.shape[0] == y.shape[\n",
    "        0], f'There must be one y value for each X value, but got {X.shape[0]} y values and {y.shape[0]} X values'\n",
    "    assert X.shape[1] == len(\n",
    "        FINGERS), f'{X.shape[1]=} doesn\\'t equal the number of finger labels ({len(FINGERS)})'\n",
    "    assert not np.isnan(\n",
    "        X).any(), f'Input dataset has {np.isnan(X).sum()} NaN values. Should have 0'\n",
    "\n",
    "    # If we've got many many points, only show an abridged version of the plot\n",
    "    abridged = X.shape[0] > 4000 or not draw_text\n",
    "    # Only create new axs if we're not plotting on existing axs\n",
    "    if axs is None:\n",
    "        if per == 'dimension':\n",
    "            nrows, ncols = (3, 1)\n",
    "        elif per == 'finger':\n",
    "            nrows, ncols = (5, 2)\n",
    "        _fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(13, 8))\n",
    "        if len(axs.shape) > 1:\n",
    "            axs = axs.T.flatten()\n",
    "    else:\n",
    "        assert axs.shape in [\n",
    "            (3,), (10,)], f'Given axs shape is {ax.shape}, but must only be (3,) or (10,))'\n",
    "        per = 'dimension' if axs.shape == (3,) else 'finger'\n",
    "\n",
    "    ymin = float('inf')\n",
    "    ymax = float('-inf')\n",
    "\n",
    "    max_std = X.std(axis=0).max()\n",
    "    for d in range(X.shape[1]):\n",
    "        if per == 'dimension':\n",
    "            ax_idx = d % 3\n",
    "        elif per == 'finger':\n",
    "            ax_idx = d // 3\n",
    "\n",
    "        ax = axs[ax_idx]\n",
    "        data_to_plot = X[:, d]\n",
    "        ax.plot(\n",
    "            data_to_plot,\n",
    "            alpha=np.clip(data_to_plot.std() / max_std, 0.05, 1.0),\n",
    "            label=FINGERS[d],\n",
    "            c=None if per == 'dimension' else (\n",
    "                'tab:red', 'tab:green', 'tab:blue')[d % 3]\n",
    "        )\n",
    "\n",
    "        # Set the title of each plot\n",
    "        if per == 'dimension':\n",
    "            ax.set_title(f'{FINGERS[d][-1]}')\n",
    "        elif per == 'finger':\n",
    "            ax.set_title(f'{FINGERS[d][:-2]}')\n",
    "\n",
    "        ymax = max(ymax, X[:, d].max())\n",
    "        ymin = min(ymin, X[:, d].min())\n",
    "\n",
    "    # Plot the ticks and legend for each axis\n",
    "    NUM_LABELS = 40 if per == 'dimension' else 40\n",
    "    TICKS_PER_LABEL = max(1, X.shape[0] // NUM_LABELS)\n",
    "    for i, ax in enumerate(axs):\n",
    "        if abridged:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xticks(range(0, X.shape[0], TICKS_PER_LABEL))\n",
    "            if (per == 'dimension' and i != len(axs)-1) or (per == 'finger' and i % 5 != 4):\n",
    "                ax.set_xticklabels([])\n",
    "            elif t is not None:\n",
    "                ax.set_xticklabels(t[::TICKS_PER_LABEL], rotation=90)\n",
    "        if per == 'dimension' and draw_text:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(\n",
    "                handles,\n",
    "                labels,\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1., 0.5)\n",
    "            )\n",
    "    # Plot the labels for each timestep and axis\n",
    "    for dim_idx, ax in enumerate(axs):\n",
    "        backtrack = 0\n",
    "        for time in range(X.shape[0]):\n",
    "#             if abridged:\n",
    "#                 continue\n",
    "            if y[time] not in ['gesture0255', 'g255'] and time != X.shape[0]-1:\n",
    "                backtrack += 1\n",
    "                continue\n",
    "            elif y[time] in ['gesture0255', 'g255'] and backtrack == 0:\n",
    "                continue\n",
    "            else:\n",
    "                ax.fill_betweenx(\n",
    "                    y=[ymin * 0.9, ymax * 1.1],\n",
    "                    x1=[time - backtrack - .5, time - backtrack - .5],\n",
    "                    x2=[time - 0.5, time - 0.5],\n",
    "                    color='grey',\n",
    "                    alpha=0.1\n",
    "                )\n",
    "\n",
    "                txt = y[time - backtrack].replace('gesture0', 'g')\n",
    "                ax.text(\n",
    "                    time - backtrack / 2 - .5,\n",
    "                    (ymax - ymin)/2 + ymin,\n",
    "                    txt,\n",
    "                    va='baseline',\n",
    "                    ha='center',\n",
    "                    rotation=90\n",
    "                )\n",
    "                backtrack = 0\n",
    "        ax.set_ylim((ymin * 0.9, ymax * 1.1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return axs\n",
    "\n",
    "\n",
    "def plot_means(Xs, per='finger'):\n",
    "    assert Xs.shape[-1] == len(\n",
    "        FINGERS), f\"Xs is of shape {Xs.shape}, not (None, None, {len(FINGERS)})\"\n",
    "    assert len(\n",
    "        Xs.shape) == 3, f\"Xs should have 3 dimensions, not {len(Xs.shape)}\"\n",
    "    X_mean = Xs.mean(axis=0)\n",
    "    X_std = Xs.std(axis=0)\n",
    "\n",
    "    blank_labels = np.array(['g255'] * X_mean.shape[0])\n",
    "\n",
    "    axs = plot_timeseries(\n",
    "        X_mean,\n",
    "        blank_labels,\n",
    "        per=per\n",
    "    )\n",
    "\n",
    "    ymin = float('inf')\n",
    "    ymax = float('-inf')\n",
    "    max_std = X_mean.std(axis=0).max()\n",
    "\n",
    "    for d in range(X_mean.shape[1]):\n",
    "        if per == 'dimension':\n",
    "            ax_idx = d % 3\n",
    "        elif per == 'finger':\n",
    "            ax_idx = d // 3\n",
    "\n",
    "        ax = axs[ax_idx]\n",
    "\n",
    "        high = X_mean[:, d] + X_std[:, d]\n",
    "        low = X_mean[:, d] - X_std[:, d]\n",
    "        ymin = min(ymin, min(low))\n",
    "        ymax = max(ymax, max(high))\n",
    "\n",
    "        kwargs = {} if per == 'dimension' else {\n",
    "            'color': ('tab:red', 'tab:green', 'tab:blue')[d % 3]}\n",
    "        ax.fill_between(\n",
    "            range(len(X_mean[:, d])),\n",
    "            low,\n",
    "            high,\n",
    "            alpha=np.clip(X_mean[:, d].std() / (4*max_std), 0.05, 1.0),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_ylim((ymin * 0.9, ymax * 1.1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return axs\n",
    "\n",
    "\n",
    "def plot_mean_gesture(gesture, window_size=15, per='finger'):\n",
    "    y_orig = df['gesture'].to_numpy()\n",
    "    X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "    t_orig = df['datetime'].to_numpy()\n",
    "    # Get a series which is y_orig, but shifted backwards by one\n",
    "    y_offset = np.concatenate((['gesture0255'], y_orig[:-1]))\n",
    "    # Get all the indices where the gesture goes [..., !=gesture, ==gesture, ...]\n",
    "    indices = np.nonzero(y_orig == gesture)[0]\n",
    "    # Filter out those indices too close to the starts/finishes for it to be viable\n",
    "    indices = indices[(indices > window_size) & (\n",
    "        indices + window_size + 1 < X_orig.shape[0])]\n",
    "\n",
    "    Xs = np.empty((\n",
    "        len(indices),\n",
    "        window_size * 2 + 1,\n",
    "        X_orig.shape[-1]\n",
    "    ))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        window_start = idx - window_size\n",
    "        window_finsh = idx + window_size + 1\n",
    "        Xs[i] = X_orig[window_start: window_finsh]\n",
    "\n",
    "    return plot_means(Xs, per=per)\n",
    "\n",
    "\n",
    "def parse_csvs(root='../gesture_data/train/'):\n",
    "    dfs = []\n",
    "    for path in os.listdir(root):\n",
    "        dfs.append(pd.read_csv(\n",
    "            root + path,\n",
    "            names=['datetime', 'gesture'] + FINGERS,\n",
    "            parse_dates=['datetime']\n",
    "        ))\n",
    "    df = pd.concat(dfs)\n",
    "#     df.datetime = df.datetime.apply(pd.Timestamp)\n",
    "    return df\n",
    "\n",
    "\n",
    "class PerClassCallback(keras.callbacks.Callback):\n",
    "    \"\"\"A basic wrapper to calculate the sklearn `classification_report` at \n",
    "    the end of each epoch. Made trickier because `validation_data` isn't\n",
    "    directly available from Keras.\"\"\"\n",
    "    def __init__(self, val_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.model.reports = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        # Only do expensive logging every ~20 epochs\n",
    "        if len(self.model.reports) > 10 and np.random.random() > 0.05:\n",
    "            self.model.reports.append(self.model.reports[-1])\n",
    "            return\n",
    "        y_pred = np.argmax(np.asarray(\n",
    "            self.model.predict(self.validation_data[0], verbose=0)\n",
    "        ), axis=1)\n",
    "        y_true = self.validation_data[1]\n",
    "        self.model.reports.append(classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            target_names=i2g(np.unique(y_true)),\n",
    "            output_dict=True,\n",
    "            zero_division=0,\n",
    "        ))\n",
    "        return\n",
    "\n",
    "\n",
    "def compile_and_fit(X_train, y_train, X_valid, y_valid, config, verbose=1):\n",
    "    normalizer = layers.Normalization(axis=-1)\n",
    "    normalizer.adapt(X_train)\n",
    "    \n",
    "    dense_layers = []\n",
    "    \n",
    "    for layer_number, num_units in config.get(\"n_hidden_units\").items():\n",
    "        dense_layers.append(layers.Dense(\n",
    "            units=num_units,\n",
    "            activation='relu',\n",
    "        ))\n",
    "        dense_layers.append(layers.Dropout(config['dropout_frac']))\n",
    "\n",
    "    def init_biases(shape, dtype=None):\n",
    "        assert shape == [len(config['class_weight'])\n",
    "                         ], f\"Shape {shape} isn't ({len(config['class_weight'])},)\"\n",
    "        inv_freqs = np.array([1/v for v in config['class_weight'].values()])\n",
    "        return np.log(inv_freqs)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=X_train.shape[1:]),\n",
    "        normalizer,\n",
    "        layers.Flatten(),\n",
    "        *dense_layers,\n",
    "        layers.Dense(\n",
    "            len(np.unique(y)),\n",
    "            activation=config.get(\"activation\"),\n",
    "            bias_initializer=init_biases,\n",
    "        ),\n",
    "    ])\n",
    "    \n",
    "    # Define an object that calculates per-class metrics\n",
    "    per_class_callback = PerClassCallback((X_valid, y_valid))\n",
    "\n",
    "    # Instantiate and compile the model\n",
    "    model.compile(\n",
    "        optimizer=config['optimiser'],\n",
    "        loss=config['loss_fn'],\n",
    "        weighted_metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name='sca'),\n",
    "            keras.metrics.SparseCategoricalCrossentropy(name='scce')\n",
    "        ],\n",
    "    )\n",
    "    # Fit the model, using the early stopping callback\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=verbose,\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        validation_data=(X_valid, y_valid),\n",
    "#         class_weight=config['class_weight'],\n",
    "        callbacks=[\n",
    "            per_class_callback,\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=25,\n",
    "                mode='min',\n",
    "                restore_best_weights=True,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    return history, model\n",
    "\n",
    "\n",
    "def plot_losses(history, show_figs, d, results, trimmed_config):\n",
    "    _fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.plot(\n",
    "        history.history['scce']\n",
    "    )\n",
    "    ax.plot(\n",
    "        history.history['val_scce']\n",
    "    )\n",
    "    plt.title(f'Sparse Categorical Cross Entropy\\n{trimmed_config}')\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_ylim((0, ylim[1]))\n",
    "    ax.set_ylabel('SCCE')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'val'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{d}/metrics.pdf')\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrices(\n",
    "    y_valid, y_pred_valid, y_train, y_pred_train, results, trimmed_config, \n",
    "    show_figs, d, cbar=False, perc='both'\n",
    "):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 9))\n",
    "    _ = conf_mat(y_valid, y_pred_valid, ax=axs[0], perc=perc, cbar=cbar)\n",
    "    axs[0].set_title(\n",
    "        f'Validation set (support={len(y_valid)}, $F_1$={results[\"valid_f1\"]})\\nscce={results[\"val_scce\"]}, sca={results[\"val_sca\"]}'\n",
    "    )\n",
    "\n",
    "    _ = conf_mat(y_train, y_pred_train, ax=axs[1], perc=perc, cbar=cbar)\n",
    "    axs[1].set_title(\n",
    "        f'Training set (support={len(y_train)}, $F_1$={results[\"train_f1\"]})\\nscce={results[\"scce\"]}, sca={results[\"sca\"]}'\n",
    "    )\n",
    "\n",
    "    plt.suptitle(\n",
    "        f'Validation and Training Confusion Matrices\\n{trimmed_config}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{d}/confusion_matrices.pdf')\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def plot_metrics(model, d, show_figs):\n",
    "    # Plot the Precisions, recalls, and F1s for all classes\n",
    "    shape = (len(model.reports), len(model.reports[0].keys()) - 3)\n",
    "    precisions = np.zeros(shape)\n",
    "    recalls = np.zeros(shape)\n",
    "    f1s = np.zeros(shape)\n",
    "    for i, report in enumerate(model.reports):\n",
    "        filtered = {k:v for k, v in report.items() if k.startswith('gesture')}\n",
    "        precisions[i] = np.array([v['precision'] for k, v in filtered.items()])\n",
    "        recalls[i]    = np.array([v['recall']    for k, v in filtered.items()])\n",
    "        f1s[i]   = np.array([v['f1-score']  for k, v in filtered.items()])\n",
    "\n",
    "    labels = list({k:v for k, v in model.reports[0].items() if k.startswith('gesture')}.keys())\n",
    "    _fig, axs = plt.subplots(3, 1, figsize=(6, 8))\n",
    "\n",
    "    val_metrics = [\n",
    "        (precisions, \"Precision\"),\n",
    "        (recalls, \"Recall\"),\n",
    "        (f1s, \"$F_1$ Score\"),\n",
    "    ]\n",
    "\n",
    "    for ax, (vals, metric) in zip(axs, val_metrics):\n",
    "        values = vals[:, np.nonzero(np.array(labels) != 'gesture0255')[0]]\n",
    "        mean = np.mean(values, axis=1)\n",
    "        std = np.std(values, axis=1)\n",
    "        ax.fill_between(\n",
    "            x=range(len(mean)),\n",
    "            y1=mean - std,\n",
    "            y2=mean + std,\n",
    "            color='tab:orange',\n",
    "            alpha=0.1,\n",
    "    #         lw=2\n",
    "        )\n",
    "        ax.plot(\n",
    "            vals[:, np.nonzero(np.array(labels) != 'gesture0255')[0]],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        ax.plot(\n",
    "            mean,\n",
    "            c='tab:orange',\n",
    "            lw=2\n",
    "        )\n",
    "        ax.plot(\n",
    "            vals[:, np.nonzero(np.array(labels) == 'gesture0255')[0]],\n",
    "            label='g255',\n",
    "            c='tab:blue',\n",
    "            lw=2\n",
    "        )\n",
    "        ax.set_ylim((0, 1))\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel(f'{metric.title()}')\n",
    "        ax.set_title(f'{metric} for all gesture classes')\n",
    "\n",
    "    axs[2].legend([\n",
    "            mpl.lines.Line2D([0], [0], color='tab:blue', lw=4),\n",
    "            mpl.lines.Line2D([0], [0], color='tab:orange', lw=4),\n",
    "        ], \n",
    "        ['gesture0255', 'mean$\\pm$std.dev. for all other gestures'],\n",
    "        bbox_to_anchor=(0.6, -0.25)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{d}/precision_recall_f1.pdf')\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def eval_and_save(\n",
    "    model, X_train, y_train, X_valid, y_valid, config, history, \n",
    "    show_figs=False, cbar=True, make_plots=True, perc='both'\n",
    "):\n",
    "    print(\"Saving model\")\n",
    "    d = f'./models/{str(datetime.datetime.now()).replace(\" \", \"T\")}'\n",
    "    model.save(d)\n",
    "    with open(f'{d}/config.yaml', 'w') as file:\n",
    "        config['class_weight'] = {int(k): v for k, v in config['class_weight'].items()}\n",
    "        config['gestures'] = [int(i) for i in config['gestures']]\n",
    "        config['i2g'] = {int(i): str(i2g(i)) for i in config['gestures']}\n",
    "        config['g2i'] = {v: k for k, v in config['i2g'].items()}\n",
    "        yaml.dump(config, file)\n",
    "\n",
    "    keys = ['epochs', 'label_expansion', 'n_hidden_units', 'window_size']\n",
    "    trimmed_config = {k: v for k, v in config.items() if k in keys}\n",
    "    results = {k: v[-1] for k, v in history.history.items()}\n",
    "    \n",
    "    # Collect together the precision/recall/F1 reports and combine them into results\n",
    "    filtered = {k:v for k, v in model.reports[-1].items() if k.startswith('gesture')}\n",
    "    merged = [[{f'{k}.{ki}': vi} for ki, vi in v.items()] for k, v in filtered.items()]\n",
    "    for item in sum(merged, []):\n",
    "        results.update(item)\n",
    "\n",
    "    if make_plots:\n",
    "        print(\"Making predictions\")\n",
    "        y_pred_valid = np.argmax(model.predict(X_valid, verbose=0), axis=1)\n",
    "        y_pred_train = np.argmax(model.predict(X_train, verbose=0), axis=1)\n",
    "        results.update({\n",
    "            \"valid_f1\": float(f1_score(y_valid, y_pred_valid, average='weighted')), \n",
    "            \"train_f1\": float(f1_score(y_train, y_pred_train, average='weighted')),\n",
    "        })\n",
    "        print(\"Making plots\")\n",
    "        plot_losses(history, show_figs, d, results, trimmed_config)\n",
    "        plot_confusion_matrices(\n",
    "            y_valid, y_pred_valid, y_train, y_pred_train, results, trimmed_config, \n",
    "            show_figs, d, cbar, perc=perc\n",
    "        )\n",
    "        plot_metrics(model, d, show_figs)\n",
    "\n",
    "\n",
    "    if os.path.exists('./models/results.jsonlines'):\n",
    "        old = pd.read_json('./models/results.jsonlines', lines=True)\n",
    "    else:\n",
    "        old = pd.DataFrame()\n",
    "    new = pd.json_normalize(results | config)\n",
    "    pd.concat((old, new), ignore_index=True).to_json(\n",
    "        './models/results.jsonlines',\n",
    "        orient='records',\n",
    "        lines=True,\n",
    "    )\n",
    "    with open(f'{d}/results.yaml', 'w') as file:\n",
    "        yaml.dump(results, file)\n",
    "\n",
    "\n",
    "def build_dataset(df, config):\n",
    "    print(f\"Making batches with window size of {config['window_size']}\")\n",
    "    X, y = make_batches(\n",
    "        df.drop(['datetime', 'gesture'], axis=1).to_numpy(),\n",
    "        df['gesture'].to_numpy(),\n",
    "        df['datetime'].to_numpy(),\n",
    "        window_size=config['window_size'],\n",
    "        window_skip=config['window_skip'],\n",
    "    )\n",
    "\n",
    "    # Offset the label by some amount\n",
    "    if config.get('label_offset', 0) > 0:\n",
    "        print(f\"Offsetting the labels by {config['label_offset']}\")\n",
    "        padding = np.array(['gesture0255'] * config['label_offset'])\n",
    "        y = np.concatenate((padding, y[:-config['label_offset']]))\n",
    "    elif config.get('center_label', False):\n",
    "        offset = config['window_size'] // 2\n",
    "        padding = np.array(['gesture0255'] * offset)\n",
    "        y = np.concatenate((padding, y[:-offset]))\n",
    "\n",
    "    config['label_before'] = config.get(\n",
    "        'label_expansion', config.get('label_before', 0))\n",
    "    config['label_after'] = config.get(\n",
    "        'label_expansion', config.get('label_after', 0))\n",
    "    # Extend the labels by a certain amount\n",
    "    non255_idxs = np.where(y != 'gesture0255')[0]\n",
    "    for i in range(-config.get('label_before', 0), config.get('label_after', 0)):\n",
    "        if non255_idxs.max() + i >= y.shape[0] or i == 0:\n",
    "            continue\n",
    "        y[non255_idxs + i] = y[non255_idxs]\n",
    "\n",
    "    if config['label_before'] or config['label_after']:\n",
    "        print(\n",
    "            f\"Expanding labels to be in deltas of {config['label_before']} before to {config['label_after']} after\")\n",
    "\n",
    "    # print(np.where(y != 'gesture0255')[0][:16])\n",
    "    if config.get('allowlist', []):\n",
    "        print(f\"Only including gestures in {config['allowlist']}\")\n",
    "        X = X[np.isin(y, config['allowlist'])]\n",
    "        y = y[np.isin(y, config['allowlist'])]\n",
    "\n",
    "    if config.get('omit_0255', False):\n",
    "        print(f\"Omitting the 255 gesture\")\n",
    "        X = X[y != 'gesture0255']\n",
    "        y = y[y != 'gesture0255']\n",
    "\n",
    "    if config.get('g255_vs_rest', False):\n",
    "        print(f\"Grouping gestures to be gesture0255 vs rest\")\n",
    "        y = np.where(\n",
    "            y == 'gesture0255',\n",
    "            'gesture0255',\n",
    "            'gesture0256'\n",
    "        )\n",
    "    config['label_size_over_window_size'] = \\\n",
    "        (config['label_before'] + config['label_after']) / \\\n",
    "        config['window_size']\n",
    "    # Get functions to convert between gestures and indices\n",
    "    g2i, i2g = gestures_and_indices(y)\n",
    "\n",
    "    labels = sorted(np.unique(y))\n",
    "    g2i_dict = {g: i for i, g in enumerate(labels)}\n",
    "    i2g_dict = {i: g for i, g in enumerate(labels)}\n",
    "    print(\"TODO: Don't store i2g and g2i in saved_models/\")\n",
    "    with open(\"saved_models/idx_to_gesture.pickle\", \"wb\") as f:\n",
    "        pickle.dump(i2g_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"saved_models/gesture_to_idx.pickle\", \"wb\") as f:\n",
    "        pickle.dump(g2i_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    y = g2i(y)\n",
    "    # Get functions to convert between indices and one hot encodings\n",
    "    i2ohe, ohe2i = one_hot_and_back(y)\n",
    "\n",
    "    total = len(y)\n",
    "    n_unique = len(np.unique(y))\n",
    "    config['gestures'] = list(np.unique(y))\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=config['test_frac'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    class_weight = {\n",
    "        int(class_): (1/freq) for class_, freq in zip(*np.unique(y_train, return_counts=True))\n",
    "    }\n",
    "    class_weight = {int(k): float(v/sum(class_weight.values()))\n",
    "                    for k, v in class_weight.items()}\n",
    "    default_class_weights = {\n",
    "        int(g): float(1.0/n_unique) for g in np.unique(y_train)\n",
    "    }\n",
    "    config['class_weight'] = class_weight if config['use_class_weights'] else default_class_weights\n",
    "\n",
    "    return config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698675f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T10:25:55.709257Z",
     "start_time": "2022-10-23T10:25:55.693092Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read in the existing config, optionally update it, and then save the result to disk again\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config.update({\n",
    "#     'label_offset': 0,\n",
    "    'center_label': True,\n",
    "    'label_expansion': 5,\n",
    "    'window_size': 10,\n",
    "    'epochs': 500,\n",
    "    'n_hidden_units': {1: 128, 2: 128},\n",
    "    'architecture': 'ffnn',\n",
    "    'dropout_frac': 0.5,\n",
    "    'use_class_weights': False\n",
    "})\n",
    "\n",
    "with open('config.yaml', 'w') as file:\n",
    "    yaml.dump(config, file)\n",
    "\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53251a8",
   "metadata": {},
   "source": [
    "TODO: you're not using softmax even though you mention it in the report. Also the biases need to be recalculated because softmax is no longer being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83aa95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T21:43:26.110697Z",
     "start_time": "2022-10-23T21:43:23.401385Z"
    },
    "code_folding": [
     10
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = parse_csvs()\n",
    "\n",
    "config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid = \\\n",
    "    build_dataset(df, config)\n",
    "    \n",
    "to_print = [\n",
    "    (i2g(i), c, round(config['class_weight'][i], 6)) \n",
    "    for i, c in \n",
    "    zip(*np.unique(y, return_counts=True))\n",
    "]\n",
    "print('\\n'.join([f'{g: <12} {c: >5} {f: >7}' for g, c, f in to_print]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9163b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:25:42.727134Z",
     "start_time": "2022-10-23T17:23:30.402749Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow Feed Forward NN\n",
    "history, model = compile_and_fit(\n",
    "    X_train, y_train, X_valid, y_valid, config, verbose=1)\n",
    "\n",
    "print('Percentage g255: ', (y_train == g2i('gesture0255')).sum() / y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dc10e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T21:59:07.567041Z",
     "start_time": "2022-10-23T21:58:52.335485Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_and_save(\n",
    "    model, X_train, y_train, X_valid, y_valid, config, history, \n",
    "    show_figs=True, cbar=False, make_plots=True, perc='both',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819e846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T18:25:47.110097Z",
     "start_time": "2022-10-20T18:25:47.103960Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d044b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T11:33:02.298999Z",
     "start_time": "2022-10-23T11:33:02.123881Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm models/results.jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae0f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T15:30:34.069269Z",
     "start_time": "2022-10-23T14:23:46.920702Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train models over a range of hyperparameters\n",
    "import itertools\n",
    "\n",
    "config_changes = {\n",
    "#     'label_expansion': [0, 1, 2, 5, 10, 15, 20],\n",
    "#     'window_size':     [5, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'label_expansion': [5, 10],\n",
    "    'window_size':     [25, 30],\n",
    "    'n_layers': [1, 2, 3],\n",
    "    'neurons_per_layer': [64, 128, 256],\n",
    "}\n",
    "num_items = np.prod([len(values) for values in config_changes.values()])\n",
    "pbar = tqdm(total=num_items)\n",
    "\n",
    "# for key, values in config_changes.items():\n",
    "for values in itertools.product(*config_changes.values()):\n",
    "    df = pd.concat((\n",
    "        parse_csvs(),\n",
    "    ))\n",
    "    print(\"Getting dict\")\n",
    "    update_dict = {k:v for k, v in zip(config_changes.keys(), values)}\n",
    "    update_dict['n_hidden_units'] = {\n",
    "        i: update_dict['neurons_per_layer']\n",
    "        for i\n",
    "        in range(1, update_dict['n_layers'] + 1)\n",
    "    }\n",
    "    new_config = config | update_dict\n",
    "    pbar.set_description(str(update_dict))\n",
    "    print(\"Building Dataset\")\n",
    "    new_config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid = \\\n",
    "        build_dataset(df, new_config)\n",
    "    print(\"Compiling and fitting the model\")\n",
    "    history, model = compile_and_fit(X_train, y_train, X_valid, y_valid, new_config, verbose=0)\n",
    "    print(\"Evaluating and saving the model\")\n",
    "    eval_and_save(model, \n",
    "                  X_train, y_train, \n",
    "                  X_valid, y_valid, \n",
    "                  new_config, history, \n",
    "                  show_figs=False, make_plots=False\n",
    "    )\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217cb4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:13:14.793762Z",
     "start_time": "2022-10-23T17:13:14.010243Z"
    }
   },
   "outputs": [],
   "source": [
    "varz = ['label_expansion', 'window_size', 'n_layers', 'neurons_per_layer']\n",
    "WEIGHTING_g255 = 0.5\n",
    "WEIGHTING_n255 = 0.9\n",
    "rename = {\n",
    "    'label_expansion': 'Label Expansion',\n",
    "    'window_size': 'Window Size',\n",
    "    'n_layers': 'Num. Layers',\n",
    "    'neurons_per_layer': 'Neurons/Layer',\n",
    "}\n",
    "\n",
    "value = 'f1-score'\n",
    "df = pd.read_json('./models/results.jsonlines', lines=True)\n",
    "other_f1_scores = [c for c in df.columns if not c.startswith('gesture0255') and c.endswith(value)]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(varz)-1, len(varz)-1,\n",
    "    figsize=(3*len(varz), 3*len(varz))\n",
    ")\n",
    "for x, var1 in enumerate(varz[1:]):\n",
    "    for y, var2 in enumerate(varz[:-1]):\n",
    "        if x < y:\n",
    "            axs[x, y].axis('off')\n",
    "            continue\n",
    "        axs[x, y].set_title(f'{rename[var2]} vs {rename[var1]}')\n",
    "        dedup = df.groupby([var1, var2])[val] \\\n",
    "            .mean() \\\n",
    "            .reset_index()\n",
    "        g255 = df.groupby([var1, var2])[f'gesture0255.{value}'].mean()\n",
    "        n255 = df.groupby([var1, var2])[other_f1_scores].mean().mean(axis=1)\n",
    "\n",
    "        dedup = ((g255*WEIGHTING_g255 + n255*WEIGHTING_n255) /\n",
    "                 (WEIGHTING_g255+WEIGHTING_n255)).reset_index()\n",
    "        dedup.columns = list(dedup.columns[:-1]) + [value]\n",
    "        heatmap = dedup \\\n",
    "            .pivot(index=var1, columns=var2, values=value) \\\n",
    "            .sort_index(ascending=False)\n",
    "        sns.heatmap(\n",
    "            heatmap,\n",
    "            square=True,\n",
    "            vmax=1,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar=False,\n",
    "            ax=axs[x, y],\n",
    "        )\n",
    "        axs[x, y].set_xlabel(rename[var2])\n",
    "        axs[x, y].set_ylabel(rename[var1])\n",
    "        \n",
    "plt.suptitle(f'Mean {value} for different value of:\\n{\", \".join(rename.values())}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../report/imgs/hyperpar_tests_weighted.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f159b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:13:18.125736Z",
     "start_time": "2022-10-23T17:13:18.087771Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_scores = [c for c in df.columns if c.endswith('f1-score')]\n",
    "\n",
    "dedup = df.groupby(varz)[f1_scores] \\\n",
    "    .mean() \\\n",
    "    .reset_index()\n",
    "g255 = df.groupby(varz)[f'gesture0255.f1-score'].mean()\n",
    "n255 = df.groupby(varz)[other_f1_scores].mean().mean(axis=1)\n",
    "\n",
    "dedup = ((g255*WEIGHTING_g255 + n255*WEIGHTING_n255) /\n",
    "         (WEIGHTING_g255+WEIGHTING_n255)).reset_index(name='f1-score')\n",
    "\n",
    "with open('../../report/imgs/best_f1_score.tex', 'w') as f:\n",
    "    topn = 15\n",
    "    dedup[varz] = dedup[varz].astype(int)\n",
    "    tex = (dedup\n",
    "        .sort_values('f1-score', ascending=False)\n",
    "        .rename(columns=rename|{\n",
    "            'f1-score': '$F_1$-score',\n",
    "        })\n",
    "        .head(topn)\n",
    "    )\n",
    "    tex['$F_1$-score'] = np.round(tex['$F_1$-score'], 3)\n",
    "    \n",
    "    f.write(tex.to_latex(\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        caption=f'Top-{topn} Mean $F_1$-scores',\n",
    "        label='tab:best_f1_score'\n",
    "    ).replace(\"{table}\", \"{table*}\"))\n",
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bef1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:13:22.322998Z",
     "start_time": "2022-10-23T17:13:22.315692Z"
    }
   },
   "outputs": [],
   "source": [
    "best = dedup.sort_values('f1-score', ascending=False).iloc[0]\n",
    "best_row = df.loc[\n",
    "    (df['neurons_per_layer'] == best['neurons_per_layer']) & \n",
    "    (df['label_expansion'] == best['label_expansion']) & \n",
    "    (df['n_layers'] == best['n_layers']) & \n",
    "    (df['window_size'] == best['window_size'])\n",
    "].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe3b9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:13:24.268695Z",
     "start_time": "2022-10-23T17:13:24.263958Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "dyn_content = {\n",
    "    \"best-window-size\": str(int(best['window_size'])),\n",
    "    \"best-label-expansion\": str(int(best['label_expansion'])),\n",
    "    \"best-num-hidden-layers\": str(int(best['n_layers'])),\n",
    "    \"best-nodes-per-layer\": str(int(best['neurons_per_layer'])),\n",
    "    \"best-f1-score\": str(np.round(best['f1-score'], 4)),\n",
    "    \"best-scce\": str(np.round(best_row['val_scce'], 4)),\n",
    "}\n",
    "print(dyn_content)\n",
    "with open('../../report/dynamic_content.yaml', 'w') as f:\n",
    "    yaml.dump(dyn_content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bc298",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:15:47.362073Z",
     "start_time": "2022-10-23T17:15:45.694372Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "def models_from_config(needle):\n",
    "    paths = glob.glob('models/*/config.yaml')\n",
    "    viable_paths = []\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            haystack = yaml.unsafe_load(f)\n",
    "        all_match = True\n",
    "        for k1, v1 in needle.items():\n",
    "            for k2, v2 in haystack.items():\n",
    "                if k1 != k2:\n",
    "                    continue\n",
    "                if v1 != v2:\n",
    "                    all_match = False\n",
    "                    break\n",
    "            if not all_match:\n",
    "                break\n",
    "        if all_match:\n",
    "            viable_paths.append(os.sep.join(path.split(os.sep)[:-1]))\n",
    "    return viable_paths\n",
    "\n",
    "paths = models_from_config({\n",
    "    'label_expansion': 10, \n",
    "    'window_size': 25,\n",
    "    'n_layers': 2,\n",
    "    'neurons_per_layer': 256,\n",
    "})\n",
    "if len(paths) == 1:\n",
    "    with open(paths[0] + '/config.yaml', 'r') as f:\n",
    "        config = yaml.unsafe_load(f)\n",
    "        pprint(config)\n",
    "    model = keras.models.load_model(paths[0])\n",
    "    print(paths[0])\n",
    "else:\n",
    "    with open(paths[0] + '/config.yaml', 'r') as f:\n",
    "        config = yaml.unsafe_load(f)\n",
    "    model = keras.models.load_model(paths[0])\n",
    "    print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d95ddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T16:31:56.068611Z",
     "start_time": "2022-10-12T16:31:56.061252Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO create a widget to explore the precision/recall/f1 graphs for different areas in the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29940b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:15:28.348326Z",
     "start_time": "2022-10-23T17:15:27.790436Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dfecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T17:17:58.953920Z",
     "start_time": "2022-10-23T17:17:56.328815Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise the predictions\n",
    "df = pd.concat((\n",
    "    parse_csvs(),\n",
    "))\n",
    "config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid = \\\n",
    "    build_dataset(df, config)\n",
    "\n",
    "window_size = config['window_size']\n",
    "@interact(idx=(2*window_size, len(df) - window_size, 5))\n",
    "def view_predictions(idx=window_size):\n",
    "    if idx < 2*window_size or idx > len(df) - window_size:\n",
    "        print(f\"Clamping idx to between {2*window_size} and {len(df) - window_size}\")\n",
    "        idx = min(len(df) - window_size, max(idx, 2*window_size))\n",
    "    \n",
    "    y_orig = df['gesture'].to_numpy()\n",
    "    X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "    t_orig = df['datetime'].to_numpy()\n",
    "\n",
    "    s, f = idx-window_size, idx+1#+window_size\n",
    "    X_window = X[s:f]\n",
    "    y_window = y[s:f]\n",
    "    \n",
    "\n",
    "    shape = model.get_config()['layers'][0]['config']['batch_input_shape']\n",
    "    assert shape[1] == X_window.shape[1] and shape[2] == X_window.shape[2], \\\n",
    "        f'Shape in config is not the shape of the model'\n",
    "    proba_preds = model.predict(X_window, verbose=0)\n",
    "    X_window = X_window[:, 0, :]\n",
    "    \n",
    "    mask = np.max(proba_preds, axis=1) < 0.0\n",
    "    preds = i2g(np.argmax(proba_preds, axis=1))\n",
    "    preds[mask] = 'gesture0255'\n",
    "    preds = [g.replace('gesture0', 'g').replace('g255', '') for g in preds]\n",
    "\n",
    "#     plot_timeseries(\n",
    "#         X_window,\n",
    "#         i2g(y_window),\n",
    "#         preds,\n",
    "#         per='finger'\n",
    "#     )\n",
    "#     plt.suptitle(f'Observation at {idx}')\n",
    "#     plt.show()\n",
    "#     # TODO also show prediction probabilities over time\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 7))\n",
    "    sns.heatmap(\n",
    "        X[idx].T,\n",
    "        xticklabels=[g.replace('gesture0', 'g').replace('g255', '') for g in i2g(y_window)],\n",
    "        ax=axs[0],\n",
    "        cbar=None,\n",
    "        vmax=900,\n",
    "        vmin=300,\n",
    "    )\n",
    "#     axs[0].set_xticklabels(\n",
    "#         [g.replace('gesture0', 'g').replace('g255', '') for g in i2g(y_window)],\n",
    "#         rotation=90\n",
    "#     )\n",
    "    axs[0].set_title(f'Heatmap of Sensor measurements')\n",
    "    axs[0].set_xlabel(f'Actual labels')\n",
    "    axs[0].set_ylabel(f'Sensor')\n",
    "    cm = plt.get_cmap('tab20')\n",
    "    NUM_COLORS = len(np.unique(y_orig))\n",
    "\n",
    "    axs[1].set_prop_cycle(color=([cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]))\n",
    "    axs[1].plot(\n",
    "        proba_preds, \n",
    "        label=np.unique(y_orig),\n",
    "    )\n",
    "    axs[1].set_title(f'Lineplot of model predictions')\n",
    "    axs[1].set_xticks(range(X[idx].shape[0]))\n",
    "    axs[1].set_ylim((0, 1))\n",
    "    axs[1].set_xlabel(f'Predicted Labels')\n",
    "    axs[1].set_ylabel(f'Softmax of Final Layer')\n",
    "    axs[1].set_xticklabels(preds[-X[idx].shape[0]:], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbee0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T21:17:58.428454Z",
     "start_time": "2022-10-23T21:17:57.421112Z"
    }
   },
   "outputs": [],
   "source": [
    "df = parse_csvs()\n",
    "config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid = \\\n",
    "    build_dataset(df, config | {'label_expansion': 0})\n",
    "idx = np.where(y == g2i('gesture0036'))[0][34]\n",
    "s = idx-105 + 35\n",
    "f = idx+105 + 35\n",
    "labels = [str(dt).replace('2022-10-18 ', '') for dt in df.iloc[s:f]['datetime']]\n",
    "plot_timeseries(X[s:f, -1, :], i2g(y[s:f]), labels, per='finger')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../report/imgs/gesture_over_time.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4dff2f",
   "metadata": {},
   "source": [
    "# No longer used\n",
    "- plot the predicted vs actual gestures as a timeline and explore mispredicted items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2d834",
   "metadata": {},
   "source": [
    "# TensorFlow CNN\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec787576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T19:21:45.640034Z",
     "start_time": "2022-10-20T19:21:45.628733Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_config = {\n",
    "    'activation': 'softmax',\n",
    "    'batch_size': 2048,\n",
    "    'center_label': True,\n",
    "    'epochs': 500,\n",
    "    'g255_vs_rest': False,\n",
    "    'label_expansion': 5,\n",
    "    'label_offset': 0,\n",
    "    'loss_fn': 'sparse_categorical_crossentropy',\n",
    "    'n_hidden_units': {1: 128, 2: 128},\n",
    "    'omit_0255': False,\n",
    "    'optimiser': 'adam',\n",
    "    'test_frac': 0.25,\n",
    "    'use_class_weights': True,\n",
    "    'window_size': 20,\n",
    "    'window_skip': 1,\n",
    "    'architecture': 'cnn',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830c591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T19:21:48.679422Z",
     "start_time": "2022-10-20T19:21:46.594872Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = parse_csvs()\n",
    "\n",
    "cnn_config, g2i, i2g, i2ohe, ohe2i, X, y, X_train, X_valid, y_train, y_valid = \\\n",
    "    build_dataset(df, cnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe2587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T19:23:06.337921Z",
     "start_time": "2022-10-20T19:22:15.635332Z"
    },
    "code_folding": [
     3
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Compiling and fitting the model\")\n",
    "\n",
    "\n",
    "def compile_and_fit_cnn(X_train, y_train, X_valid, y_valid, config, verbose=0):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, (5,), activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(layers.MaxPooling1D((2,)))\n",
    "    model.add(layers.Conv1D(64, (3,), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(len(np.unique(y_train))))\n",
    "    # Define an object that calculates per-class metrics\n",
    "    per_class_callback = PerClassCallback((X_valid, y_valid))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=config['optimiser'],\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['sparse_categorical_accuracy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=verbose,\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        class_weight=config['class_weight'],\n",
    "        callbacks=[\n",
    "            per_class_callback,\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                mode='min',\n",
    "                restore_best_weights=True,\n",
    "                verbose=0,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return history, model\n",
    "\n",
    "history, model = compile_and_fit_cnn(X_train, y_train, X_valid, y_valid, cnn_config, verbose=1)\n",
    "eval_and_save(model, X_train, y_train, X_valid, y_valid, config, history, show_figs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea5b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T15:29:41.838294Z",
     "start_time": "2022-10-11T15:29:41.809601Z"
    },
    "code_folding": [
     0,
     7,
     8
    ]
   },
   "outputs": [],
   "source": [
    "# Create a classifier based on correlations\n",
    "\n",
    "class CorrelationClassifier():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_mean_lag(self,a, b):\n",
    "        def get_lag(v1, v2):\n",
    "            x = v1 - np.mean(v1)\n",
    "            y = v2 - np.mean(v2)\n",
    "            correlation = scipy.signal.correlate(x, y)\n",
    "            lags = scipy.signal.correlation_lags(x.size, y.size)\n",
    "            lag = lags[np.argmax(correlation)]\n",
    "            return lag, np.max(correlation) / (x.std() * y.std() * (x.shape[0]))\n",
    "\n",
    "        lags, xcorrs = zip(*[get_lag(ai, bi) for ai, bi in zip(a.T, b.T)])\n",
    "        weights = [ai.std() * bi.std() for ai, bi in zip(a.T, b.T)]\n",
    "\n",
    "        total_weight = sum(weights)\n",
    "        mean_lag = round(sum(w * l / total_weight for w, l in zip(weights, lags)))\n",
    "        mean_xcorr = sum(w * l / total_weight for w, l in zip(weights, xcorrs))\n",
    "        return mean_lag, mean_xcorr\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, verbose=1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.classes_ = sorted(np.unique(y_train))\n",
    "        self.references = {}\n",
    "        for cls in self.classes_:\n",
    "#             if cls == g2i('gesture0255'):\n",
    "#                 continue\n",
    "            obs_in_cls = self.X_train[self.y_train == cls]\n",
    "            if verbose > 0:\n",
    "                print(f\"Fitting class {cls} with {len(obs_in_cls)} observations\")\n",
    "            best_xcorr = 0\n",
    "            pbar = tqdm.tqdm(total=obs_in_cls.shape[0]*(obs_in_cls.shape[0]-1)//2)\n",
    "            for i, a in enumerate(obs_in_cls):\n",
    "                mean_xcorr = 0\n",
    "                count = 0\n",
    "                for j, b in enumerate(obs_in_cls):\n",
    "                    if i >= j:\n",
    "                        continue\n",
    "                    pbar.update(1)\n",
    "                    lag, xcorr = self._get_mean_lag(a, b)\n",
    "                    mean_xcorr += xcorr\n",
    "                    count += 1\n",
    "\n",
    "                if count == 0:\n",
    "                    best_xcorr = mean_xcorr\n",
    "                    self.references[cls] = a\n",
    "                else:\n",
    "                    mean_xcorr = mean_xcorr / count\n",
    "                    if mean_xcorr > best_xcorr:\n",
    "                        best_xcorr = mean_xcorr\n",
    "                        self.references[cls] = a\n",
    "\n",
    "    def predict_proba(self, X_valid, verbose=1): \n",
    "        corrs_all = []\n",
    "        for x in tqdm.tqdm(X_valid):\n",
    "            corrs_all.append([])\n",
    "            for cls, ref in self.references.items():\n",
    "                corrs_all[-1].append(self._get_mean_lag(ref, x)[1])\n",
    "        return np.array(corrs_all)\n",
    "clf = CorrelationClassifier()\n",
    "clf.fit(X_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c871b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T19:15:47.990443Z",
     "start_time": "2022-10-08T19:15:47.669502Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate and plot metrics per gesture\n",
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    np.argmax(model.predict(X_valid, verbose=0), axis=1), \n",
    "    y_valid\n",
    ").numpy()\n",
    "\n",
    "tab = pd.DataFrame()\n",
    "tab['gesture'] = [g for g in i2g(list(range(confusion_mtx.shape[0])))]\n",
    "tab.index = tab['gesture']\n",
    "# tab = tab.drop(['gesture'], axis=1)\n",
    "tab['precision'] = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=0)\n",
    "tab['recall'] = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=1)\n",
    "tab['weight'] = pd.Series({i2g(k): v for k, v in config['class_weight'].items()})\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fdece",
   "metadata": {},
   "source": [
    "## Visualise the mis-predicted gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d965b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:42:57.993289Z",
     "start_time": "2022-10-08T08:42:55.882337Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_valid, verbose=0), axis=1)\n",
    "y_true = y_valid\n",
    "# incorrect = np.where(y_pred != y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf921025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:25:29.619192Z",
     "start_time": "2022-10-11T13:25:29.575954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_gestures = i2g(np.unique(y))\n",
    "true_gestures = i2g(np.unique(y))\n",
    "\n",
    "@interact(predicted=pred_gestures, true=true_gestures)\n",
    "def view_incorrect(predicted, true):\n",
    "    indices = np.where((y_pred == g2i(predicted)) & (y_true == g2i(true)))[0]\n",
    "    if len(indices) == 0:\n",
    "        print(f\"No gestures where {predicted=} and {true=}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Plotting {indices.shape} examples\")\n",
    "    plot_means(X_valid[indices])\n",
    "\n",
    "    plt.suptitle(f'{len(indices)} gestures where:\\npred={predicted}\\ntrue={true}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'imgs/gestures_where_pred={predicted}_true={true}.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010118e2",
   "metadata": {},
   "source": [
    "# Relabel part of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c67f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T09:03:17.638945Z",
     "start_time": "2022-10-05T09:03:17.240985Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Relabel the dataset\n",
    "gesture = 'gesture0022'\n",
    "window_size = 10\n",
    "y_orig = df['gesture'].to_numpy()\n",
    "ref_idx = np.nonzero(y_orig == gesture)[0][13] - 6\n",
    "\n",
    "ref_idx = 3598\n",
    "reference   = df.drop(['datetime', 'gesture'], axis=1).iloc[ref_idx-window_size:ref_idx+window_size].to_numpy()\n",
    "reference_y = df['gesture'].iloc[ref_idx-window_size:ref_idx+window_size].to_numpy()\n",
    "reference_t = df['datetime'].iloc[ref_idx-window_size:ref_idx+window_size].to_numpy()\n",
    "\n",
    "plot_timeseries(\n",
    "    reference,\n",
    "    reference_y,\n",
    "#     reference_t,\n",
    "    per='finger'\n",
    ")\n",
    "plt.suptitle(f\"ref index: {ref_idx}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be71c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T09:03:32.591444Z",
     "start_time": "2022-10-05T09:03:32.118272Z"
    },
    "code_folding": [
     1,
     7,
     14
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fix labels\n",
    "@interact(val=widgets.BoundedIntText(\n",
    "        value=0,\n",
    "        min=-window_size,\n",
    "        max=window_size,\n",
    "        step=1,\n",
    "        continuous_update=False\n",
    "), INDEX=widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(np.nonzero(y_orig == gesture)[0]),\n",
    "    step=1,\n",
    "    description='index:'\n",
    "))\n",
    "def interact_fix_labels(val=0, INDEX=0):\n",
    "    y_orig = df['gesture'].to_numpy()\n",
    "    X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "    t_orig = df['datetime'].to_numpy()\n",
    "\n",
    "    # Get a series which is y_orig, but shifted backwards by one\n",
    "    y_offset = np.concatenate((['gesture0255'], y_orig[:-1]))\n",
    "    # Get all the indices where the gesture goes [..., !=gesture, ==gesture, ...]\n",
    "    indices = np.nonzero((y_orig == gesture) & (y_offset != gesture))[0]\n",
    "\n",
    "    if INDEX >= len(indices):\n",
    "        print(f\"INDEX {INDEX} >= len(indices) {len(indices)}\")\n",
    "        return\n",
    "    idx = indices[INDEX]\n",
    "    window_start = idx - window_size\n",
    "    window_finsh = idx + window_size+1\n",
    "    X = X_orig[window_start : window_finsh]\n",
    "    t = t_orig[window_start : window_finsh]\n",
    "    y_true = y_orig[window_start : window_finsh]\n",
    "    y_new = y_true.copy()\n",
    "    y_true = np.array([yi.replace('gesture0255', 'g255') for yi in y_true])\n",
    "\n",
    "    lag, xcorr = get_mean_lag(reference, X)\n",
    "\n",
    "    # Remove the old label\n",
    "    y_new[window_size - 5: window_size + 5] = 'gesture0255'\n",
    "    # Get indices for the new label\n",
    "    s = window_size - lag\n",
    "    f = window_size - lag + 1\n",
    "    # Set the new label\n",
    "    y_new[s:f] = gesture\n",
    "\n",
    "    # Plot the new labels and the old labels\n",
    "    if True or xcorr < 0.7 or abs(lag) > 5:\n",
    "        axs = plot_timeseries(\n",
    "            X,\n",
    "            y_new,\n",
    "            y_true,\n",
    "            per='finger'\n",
    "        )\n",
    "        plt.suptitle(f'x-corr: {xcorr:.2f}')\n",
    "\n",
    "        for ax in axs.flatten():\n",
    "            ax.axvline(\n",
    "                window_size - lag, \n",
    "                color='red',\n",
    "                alpha=min(1, xcorr)\n",
    "            )\n",
    "\n",
    "#     print(df.loc[df['datetime'].isin(t[s:f]), ['datetime', 'gesture']])\n",
    "    time_mask = df['datetime'].isin(t)\n",
    "    df.loc[time_mask, 'gesture'] = y_new\n",
    "    \n",
    "    def accept_label(_):\n",
    "        y_new[window_size - lag] = 'gesture0255'\n",
    "        y_new[window_size + val] = gesture\n",
    "        df.loc[time_mask, 'gesture'] = y_new\n",
    "\n",
    "    button_accept = widgets.Button(\n",
    "        description='Accept Label',\n",
    "        button_style='',\n",
    "    )\n",
    "    button_accept.on_click(accept_label)\n",
    "    display(button_accept)\n",
    "\n",
    "    def remove_label(_):\n",
    "        y_new[s:f] = 'gesture0255'\n",
    "        df.loc[time_mask, 'gesture'] = y_new\n",
    "        print(f'Removed. New label is {y_new}')\n",
    "    button_remove = widgets.Button(\n",
    "        description='Remove Label',\n",
    "        button_style='danger',\n",
    "    )\n",
    "    button_remove.on_click(remove_label)\n",
    "    display(button_remove)\n",
    "    \n",
    "    print(f'Time: {t_orig[idx]}, Completed: {INDEX / len(indices) * 100:.0f}%, Gesture: {gesture}, Index: {idx}, \\nLag: {lag} \\nXcorr: {xcorr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156ea5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T09:10:54.498179Z",
     "start_time": "2022-10-05T09:10:54.080706Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../gesture_data/relabelled2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80981619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T12:59:41.946647Z",
     "start_time": "2022-10-03T12:59:41.900177Z"
    },
    "code_folding": [
     9
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the optimal lag to align two gestures, and plot the lagged time series\n",
    "gesture = 'gesture0019'\n",
    "idxs = np.nonzero((df.gesture == gesture).to_numpy())[0]\n",
    "\n",
    "i = 40\n",
    "j = 33\n",
    "\n",
    "s, f = (idxs[i] - 10, idxs[i] + 10)\n",
    "a = df.filter(regex='left|right').iloc[s:f].to_numpy()\n",
    "\n",
    "s, f = (idxs[j] - 10, idxs[j] + 10)\n",
    "b = df.filter(regex='left|right').iloc[s:f].to_numpy()\n",
    "\n",
    "def get_lag(v1, v2):\n",
    "    x = v1 - np.mean(v1)\n",
    "    y = v2 - np.mean(v2)\n",
    "    correlation = scipy.signal.correlate(x, y)\n",
    "    lags = scipy.signal.correlation_lags(x.size, y.size)\n",
    "    lag = lags[np.argmax(correlation)]\n",
    "    return lag, np.max(correlation) / (x.std() * y.std() * (x.shape[0]))\n",
    "\n",
    "def get_mean_lag(a, b):\n",
    "    lags, xcorrs = zip(*[get_lag(ai, bi) for ai, bi in zip(a.T, b.T)])\n",
    "    weights = [ai.std() * bi.std() for ai, bi in zip(a.T, b.T)]\n",
    "\n",
    "    total_weight = sum(weights)\n",
    "    mean_lag = round(sum(w * l / total_weight for w, l in zip(weights, lags)))\n",
    "    mean_xcorr = sum(w * l / total_weight for w, l in zip(weights, xcorrs))\n",
    "    return mean_lag, mean_xcorr\n",
    "\n",
    "mean_lag, mean_xcorr = get_mean_lag(a, b)\n",
    "\n",
    "# fig, axs = plt.subplots(len(a.T)//2, 2, figsize=(10, 15))\n",
    "\n",
    "# for i, (ai, bi) in enumerate(zip(a.T, b.T)):\n",
    "#     offset = -mean_lag\n",
    "#     ai = ai[(-offset if offset < 0 else 0):(-offset if offset > 0 else len(ai))]\n",
    "#     bi = bi[(offset if offset > 0 else 0):(offset if offset < 0 else len(bi))]\n",
    "#     axs.T.flatten()[i].plot(ai)\n",
    "#     axs.T.flatten()[i].plot(bi)\n",
    "\n",
    "# plt.suptitle(f'{mean_lag=}, {mean_xcorr=}')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841750ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T12:59:42.109408Z",
     "start_time": "2022-10-03T12:59:42.096104Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visually confirm that the lag offsetter is working\n",
    "window_size = 1 + 2 * 10\n",
    "gesture = 'gesture0019'\n",
    "idxs = np.nonzero((df.gesture == gesture).to_numpy())[0]\n",
    "reference_idx = 40\n",
    "\n",
    "reference = df.filter(regex='left|right').to_numpy()[\n",
    "    idxs[reference_idx] - window_size // 2: idxs[reference_idx] + window_size // 2\n",
    "]\n",
    "\n",
    "def plot_lags(reference, other):\n",
    "    lag, xcorr = get_mean_lag(reference, other)\n",
    "    fig, axs = plt.subplots(reference.T.shape[0]//2, 2, figsize=(10, 15))\n",
    "    for i, (ai, bi) in enumerate(zip(reference.T, other.T)):\n",
    "        offset = -lag\n",
    "        axs.T.flatten()[i].plot(\n",
    "            ai[(-offset if offset < 0 else 0):(-offset if offset > 0 else len(ai))]\n",
    "        )\n",
    "        axs.T.flatten()[i].plot(\n",
    "            bi[(offset if offset > 0 else 0):(offset if offset < 0 else len(bi))]\n",
    "        )\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.suptitle(f'{lag=}, {xcorr=}')\n",
    "    return fig, axs\n",
    "\n",
    "    \n",
    "# for idx in idxs[:5]:\n",
    "#     s, f = (idx - window_size // 2, idx + window_size // 2)\n",
    "#     other = df.filter(regex='left|right').to_numpy()[s:f]\n",
    "#     plot_lags(reference, other)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe61105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T11:25:48.722486Z",
     "start_time": "2022-10-03T11:25:48.692476Z"
    }
   },
   "outputs": [],
   "source": [
    "gestures = df.reset_index(drop=True).drop_duplicates('gesture', keep='last')['gesture'].sort_values()\n",
    "gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414dcad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T11:25:51.504667Z",
     "start_time": "2022-10-03T11:25:49.655323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate xcorrs between samples from the gestures\n",
    "pad = 20\n",
    "xcorrs = np.zeros((len(gestures), len(gestures)))\n",
    "for i, adx in enumerate(gestures.index):\n",
    "    for j, bdx in enumerate(gestures.index):\n",
    "        a = df.filter(regex='left|right').reset_index(drop=True).iloc[adx-pad:adx+pad].to_numpy()\n",
    "        b = df.filter(regex='left|right').reset_index(drop=True).iloc[bdx-pad:bdx+pad].to_numpy()\n",
    "        lag, xcorr = get_mean_lag(a, b)\n",
    "        xcorrs[i, j] = xcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80184b5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T11:25:52.350867Z",
     "start_time": "2022-10-03T11:25:51.976449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the cross-correlations heatmap between gestures\n",
    "sns.heatmap(\n",
    "    xcorrs,\n",
    "    annot=True,\n",
    "    xticklabels=gestures,\n",
    "    yticklabels=gestures,\n",
    "    fmt='.1f'\n",
    ")\n",
    "\n",
    "plt.title(f'Heatmap of cross correlations for different gestures')\n",
    "plt.savefig('./imgs/heatmap_of_xcorrs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all indices for non-255 gestures that are sequential\n",
    "pad = 20\n",
    "\n",
    "for gesture in gestures:\n",
    "    # Get reference gesture\n",
    "    reference = np.empty()\n",
    "    for index in gesture_idxs:\n",
    "        curr = np.empty()\n",
    "        # Get lag and xcorr between index and reference\n",
    "        lag, xcorr = get_mean_lag(reference, curr)\n",
    "        print(index, lag, xcorr)\n",
    "        if np.abs(lag) > 0 and xcorr > 0.8:\n",
    "            df.iloc[index]['gesture']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7b93a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T08:33:56.733088Z",
     "start_time": "2022-10-03T08:33:56.197168Z"
    }
   },
   "outputs": [],
   "source": [
    "gesture = 'gesture0012'\n",
    "index = 3\n",
    "\n",
    "idxs = np.nonzero((df.gesture == gesture).to_numpy())[0]\n",
    "s, f = (idxs[index] - 16, idxs[index] + 16)\n",
    "print(idxs[index])\n",
    "plot_timeseries(\n",
    "    df.filter(regex='left|right').iloc[s:f].to_numpy(),\n",
    "    df['gesture'].iloc[s:f].to_numpy(),\n",
    "    t=df['datetime'].iloc[s:f].to_numpy(),\n",
    "    per='finger',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7339ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T16:16:25.215682Z",
     "start_time": "2022-09-28T16:16:25.197160Z"
    }
   },
   "outputs": [],
   "source": [
    "df.gesture.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf3651",
   "metadata": {},
   "source": [
    "### Visualise confidence intervals per gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae170f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T12:40:33.358618Z",
     "start_time": "2022-10-11T12:40:33.340340Z"
    }
   },
   "outputs": [],
   "source": [
    "X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "y_orig = df['gesture'].to_numpy()\n",
    "indices = np.nonzero(y_orig == 'gesture0255')[0]\n",
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a533508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T12:40:34.631461Z",
     "start_time": "2022-10-11T12:40:34.619560Z"
    }
   },
   "outputs": [],
   "source": [
    "X_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc73ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T12:40:35.431850Z",
     "start_time": "2022-10-11T12:40:35.336490Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "per='finger'\n",
    "gesture = 'gesture0010'\n",
    "axs = plot_mean_gesture(gesture, per=per)\n",
    "# Add some shading to show which \n",
    "for ax in axs:\n",
    "    ylim = ax.get_ylim()\n",
    "    xlim = ax.get_xlim()\n",
    "    xrange = range(int((xlim[1] - xlim[0]) // 2 + xlim[0])+1, int(xlim[1]))\n",
    "    ax.fill_between(\n",
    "        xrange,\n",
    "        [ylim[0]] * len(xrange),\n",
    "        [ylim[1]] * len(xrange),\n",
    "        color='grey',\n",
    "        alpha=0.3,\n",
    "    )\n",
    "plt.savefig(f'imgs/mean-{gesture}-per-{per}.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80546e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gesture in i2g(np.unique(y)):\n",
    "    per = 'finger'\n",
    "    plot_mean_gesture(gesture, per=per)\n",
    "    plt.savefig(f'imgs/mean-{gesture}-per-{per}.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74167d7f",
   "metadata": {},
   "source": [
    "# TODO: Fix the dataset\n",
    "- Try train on a small, but very good, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7c8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T09:07:19.202157Z",
     "start_time": "2022-10-08T09:07:19.193305Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # May take a while. Make a pair-plot of the datapoints per sensor\n",
    "# cols = df.columns[df.columns.str.contains('z')].to_list()\n",
    "# fig, axs = plt.subplots(len(cols), len(cols), figsize=(len(cols)*2, len(cols)*2))\n",
    "# # Sort the DF to ensure gesture0255 is drawn first, underneath all others\n",
    "# df = df.sort_values('gesture', ascending=False)\n",
    "# for i, x_var in enumerate(cols):\n",
    "#     print(f'{i} ({x_var}): ', end='')\n",
    "#     for j, y_var in enumerate(cols):\n",
    "#         if i > j:\n",
    "#             print(f'{j}({y_var}) ', end='')\n",
    "#             axs[i, j].scatter(\n",
    "#                 df[x_var],\n",
    "#                 df[y_var],\n",
    "#                 c=pd.get_dummies(df['gesture']).values.argmax(1),\n",
    "#                 s=1,\n",
    "#                 alpha=np.where(df['gesture'] == 'gesture0255', 0.1, 1),\n",
    "#             )\n",
    "#         else:\n",
    "#             axs[i, j].axis('off')\n",
    "#         if i != len(cols) - 1:\n",
    "#             axs[i,j].set_xticks([])\n",
    "#             axs[i,j].set_xticklabels([])\n",
    "#         else:\n",
    "#             axs[i,j].set_xlabel(y_var)\n",
    "            \n",
    "#         if j != 0:\n",
    "#             axs[i,j].set_yticks([])\n",
    "#             axs[i,j].set_yticklabels([])\n",
    "#         else:\n",
    "#             axs[i,j].set_ylabel(x_var)\n",
    "            \n",
    "#     print()\n",
    "# print(\"Resolving layout\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033afd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T12:44:55.261461Z",
     "start_time": "2022-10-11T12:44:54.809655Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Visualise items in the dataset\n",
    "gesture = 'gesture0000'\n",
    "if gesture in i2g(np.unique(y)):\n",
    "    Xs = X[y == g2i(gesture)]\n",
    "    plot_means(\n",
    "        Xs\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b07d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70562c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T19:19:25.472978Z",
     "start_time": "2022-10-08T19:19:24.817080Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Train the outlier detector on a *different* train \n",
    "# and validation set to the actuall NN so that the NN's\n",
    "# validation set doesn't have loads of g0255 and the NN's\n",
    "# train set has basically none.\n",
    "X_binary_train, X_binary_valid, y_binary_train, y_binary_valid = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=config['test_frac'], \n",
    "    random_state=42+1\n",
    ")\n",
    "\n",
    "\n",
    "X_binary_train = X_binary_train.reshape((-1, np.prod(X_binary_train.shape[1:])))\n",
    "y_binary_train = np.where(y_binary_train == g2i('gesture0255'), 1, 0)\n",
    "\n",
    "X_binary_valid = X_binary_valid.reshape((-1, np.prod(X_binary_train.shape[1:])))\n",
    "y_binary_valid = np.where(y_binary_valid == g2i('gesture0255'), 1, 0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5, class_weight='balanced')\n",
    "print(\"Training Random Forest...\")\n",
    "clf = clf.fit(\n",
    "    X_binary_train,\n",
    "    y_binary_train,\n",
    ")\n",
    "print(\"Scoring Random Forest...\")\n",
    "clf.score(\n",
    "    X_binary_valid,\n",
    "    y_binary_valid,\n",
    ")\n",
    "print(\"Creating confusion matrix...\")\n",
    "y_pred = clf.predict(X_binary_valid)\n",
    "cm = confusion_matrix(y_binary_valid, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=['not g255', 'g255']\n",
    ")\n",
    "disp.plot()\n",
    "plt.title('Validation Confusion Matrix: g255 vs rest\\n(Random Forest Classifier)')\n",
    "plt.savefig('imgs/conf_mat_255_vs_rest_rfc.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075014bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:19:48.500020Z",
     "start_time": "2022-10-08T08:19:48.495852Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./models/255_vs_rest.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "with open('./models/255_vs_rest.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cb994",
   "metadata": {},
   "source": [
    "Intelligently remove predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fce55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:19:48.818375Z",
     "start_time": "2022-10-08T08:19:48.548609Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get a new train-valid split that will be used for the NN\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=config['test_frac'], \n",
    "    random_state=42\n",
    ")\n",
    "# Create reusable masks that only keep observations the RF classifies as `not255`\n",
    "train_mask = (clf.predict(X_train.reshape((-1, np.prod(X_train.shape[1:]))) != 0))\n",
    "valid_mask = (clf.predict(X_valid.reshape((-1, np.prod(X_valid.shape[1:]))) != 0))\n",
    "\n",
    "# Remove all `g255` gestures from the NN's train and valid set\n",
    "y_train = y_train[train_mask]\n",
    "X_train = X_train[train_mask]\n",
    "y_valid = y_valid[valid_mask]\n",
    "X_valid = X_valid[valid_mask]\n",
    "\n",
    "# Recalculate the class weights\n",
    "class_weight = {\n",
    "    int(class_): (1/freq) for class_, freq in zip(*np.unique(y_train, return_counts=True))\n",
    "}\n",
    "class_weight = {k: v/sum(class_weight.values()) for k, v in class_weight.items()}\n",
    "config['class_weight'] = class_weight if config['use_class_weights'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80e9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T19:19:31.134490Z",
     "start_time": "2022-10-08T19:19:31.123588Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_print = [\n",
    "    (i2g(i), c, round(config['class_weight'][i], 6)) \n",
    "    for i, c in \n",
    "    zip(*np.unique(y_train, return_counts=True))\n",
    "]\n",
    "print('\\n'.join([f'{g: <12} {c: >5} {f: >7}' for g, c, f in to_print]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
