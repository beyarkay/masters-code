{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999271bc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2ded3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"window_size\": 30,\n",
    "    \"window_skip\": 1,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 32,\n",
    "    \"test_frac\": 0.25,\n",
    "    \"use_class_weights\": True,\n",
    "    \"n_hidden_units\": {\n",
    "        1: 128,\n",
    "    },\n",
    "    \"lr\": 1e-4,\n",
    "}\n",
    "wandb.init(\n",
    "    project=\"ergo\", \n",
    "    entity=\"beyarkay\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea697b7",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Function and constant definitions\n",
    "\n",
    "FINGERS = [\n",
    "    'left-5-x',\n",
    "    'left-5-y',\n",
    "    'left-5-z',\n",
    "    'left-4-x',\n",
    "    'left-4-y',\n",
    "    'left-4-z',\n",
    "    'left-3-x',\n",
    "    'left-3-y',\n",
    "    'left-3-z',\n",
    "    'left-2-x',\n",
    "    'left-2-y',\n",
    "    'left-2-z',\n",
    "    'left-1-x',\n",
    "    'left-1-y',\n",
    "    'left-1-z',\n",
    "    'right-1-x',\n",
    "    'right-1-y',\n",
    "    'right-1-z',\n",
    "    'right-2-x',\n",
    "    'right-2-y',\n",
    "    'right-2-z',\n",
    "    'right-3-x',\n",
    "    'right-3-y',\n",
    "    'right-3-z',\n",
    "    'right-4-x',\n",
    "    'right-4-y',\n",
    "    'right-4-z',\n",
    "    'right-5-x',\n",
    "    'right-5-y',\n",
    "    'right-5-z',    \n",
    "]\n",
    "\n",
    "def make_batches(X, y, window_size=10, window_skip=1):\n",
    "    assert window_skip == 1, 'window_skip is not supported for values other than 1'\n",
    "    ends = np.array(range(window_size, len(y) - 1))\n",
    "    starts = ends - window_size\n",
    "    batched_X = np.empty((ends.shape[0], window_size, X.shape[1]))\n",
    "    batched_y = np.empty((ends.shape[0],), dtype='object')\n",
    "    for i in range(batched_y.shape[0]):\n",
    "        batched_X[i] = X[starts[i]:ends[i]]\n",
    "        batched_y[i] = y[ends[i]]\n",
    "    return batched_X, batched_y\n",
    "\n",
    "def gestures_and_indices(y):\n",
    "    labels = sorted(np.unique(y))\n",
    "    g2i_dict = {g:i for i, g in enumerate(labels)}\n",
    "    i2g_dict = {i:g for i, g in enumerate(labels)}\n",
    "    def g2i(g):\n",
    "        return np.array([g2i_dict[gi] for gi in g])\n",
    "    def i2g(i):\n",
    "        return np.array([i2g_dict[ii] for ii in i])\n",
    "    return g2i, i2g\n",
    "\n",
    "def one_hot_and_back(y_all):\n",
    "    return (\n",
    "        lambda y: tf.one_hot(y, len(np.unique(y_all))),\n",
    "        lambda onehot: tf.argmax(one_hot, axis=1)\n",
    "    )\n",
    "\n",
    "def conf_mat(model, X, y):\n",
    "    y_pred = np.argmax(model.predict(X), axis=1)\n",
    "    y_true = y\n",
    "\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    labels = [i2g([i])[0] for i in range(confusion_mtx.shape[0])]\n",
    "    sns.heatmap(\n",
    "        confusion_mtx, \n",
    "        annot=True, \n",
    "        fmt='g',\n",
    "        xticklabels=labels, \n",
    "        yticklabels=labels,\n",
    "    )\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    return confusion_mtx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6e212",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in data and format to {X,y}_{train,test}\n",
    "root = '../gesture_data/train/'\n",
    "dfs = []\n",
    "for path in os.listdir(root):\n",
    "#     print(f'reading data from {path}')\n",
    "    dfs.append(pd.read_csv(\n",
    "        root + path,\n",
    "        names=['datetime', 'gesture'] + FINGERS,\n",
    "        parse_dates=[1]\n",
    "    ))\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df.datetime = df.datetime.apply(pd.Timestamp)\n",
    "X, y = make_batches(    \n",
    "    df.drop(['datetime', 'gesture'], axis=1).to_numpy(), \n",
    "    df['gesture'].to_numpy(),\n",
    "    window_size=wandb.config['window_size'],\n",
    "    window_skip=wandb.config['window_skip'],\n",
    ")\n",
    "# Get functions to convert between gestures and indices\n",
    "g2i, i2g = gestures_and_indices(y)\n",
    "y = g2i(y)\n",
    "# Get functions to convert between indices and one hot encodings\n",
    "i2ohe, ohe2i = one_hot_and_back(y)\n",
    "\n",
    "total = len(y)\n",
    "n_unique = len(np.unique(y))\n",
    "wandb.config['gestures'] = np.unique(y)\n",
    "class_weight = {\n",
    "    int(class_): (1/weight * total/n_unique) for class_, weight in zip(*np.unique(y, return_counts=True))\n",
    "}\n",
    "\n",
    "wandb.config['class_weight'] = class_weight if wandb.config.use_class_weights else None\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=wandb.config['test_frac'], \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba225f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i2g([i])[0], c) for i, c in zip(*np.unique(y, return_counts=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b494d8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "inputs = layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train)\n",
    "x = normalizer(inputs)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(units=wandb.config.n_hidden_units['1'])(x)\n",
    "\n",
    "outputs = layers.Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=wandb.config.lr),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy('acc')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159302a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MultiClassAccAndRecallCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, training_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.training_data = training_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calculate per-class {validation,training} {recall,precision}\n",
    "        datas = [\n",
    "            self.validation_data,\n",
    "            self.training_data,\n",
    "        ]\n",
    "        keys = ['valid', 'train']\n",
    "        for key, data in zip(keys, datas):\n",
    "            X, y = data\n",
    "            conf_mat = tf.math.confusion_matrix(\n",
    "                np.argmax(self.model.predict(X, verbose=0), axis=1), \n",
    "                y,\n",
    "            ).numpy()\n",
    "            precision = np.diag(conf_mat)  / conf_mat.sum(axis=0)\n",
    "            recall = np.diag(conf_mat)  / conf_mat.sum(axis=1)\n",
    "            \n",
    "            ipr = list(zip(range(len(precision)), precision, recall))\n",
    "            prec_and_recall = {i2g([i])[0]: {'precision': p, 'recall': r} for i, p, r in ipr}\n",
    "            wandb.log({key: prec_and_recall}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971c7dd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=wandb.config['batch_size'], \n",
    "    epochs=wandb.config['epochs'],\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[WandbCallback(), MultiClassAccAndRecallCallback((X_valid, y_valid), (X_train, y_train))],\n",
    "    class_weight=wandb.config['class_weight'],\n",
    ")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d99c5",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_gesture0255 = (y_valid != g2i(['gesture0255'])[0])\n",
    "conf_mat(model, X_valid[no_gesture0255], y_valid[no_gesture0255])\n",
    "plt.title('Validation set\\n(`gesture0255` removed)')\n",
    "plt.show()\n",
    "\n",
    "# no_gesture0255 = (y_train != g2i(['gesture0255'])[0])\n",
    "# conf_mat(model, X_train[no_gesture0255], y_train[no_gesture0255])\n",
    "# plt.title('Training set\\n(`gesture0255` removed)')\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04859e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    np.argmax(model.predict(X_valid, verbose=0), axis=1), \n",
    "    y_valid\n",
    ").numpy()\n",
    "precision = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=0)\n",
    "recall = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=1)\n",
    "ipr = list(zip(range(len(precision)), precision, recall))\n",
    "prec_and_recall = {i2g([i])[0]: {'precision': p, 'recall': r} for i, p, r in ipr}\n",
    "\n",
    "print('\\n'.join([f'{i2g([i])[0]}:    precision:{p:.3f}, recall: {r:.3f}' for i, p, r in ipr]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fb104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef262bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
