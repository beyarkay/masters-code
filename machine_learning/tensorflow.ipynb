{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e1551f",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- Relative probabilities are interesting\n",
    "    - Probability of a firetruck being classified as a bmw is small, but much larger than an image of a firetruck being classified as a toad.\n",
    "- An ensamble of specialised learners\n",
    "    - Create a group of specialists, which only learn to distinguish between easily confused classes and throws any other classes into a \"OTHER\" group-class\n",
    "- High precision       => Many of the predicted class X are actually class X\n",
    "- Increasing precision => Fewer non-X gestures are being predicted as gesture-X\n",
    "- High recall          => Many of class X are actually classified as class X\n",
    "- Increasing recall    => Fewer of gesture-X are predicted as anything but X\n",
    "\n",
    "#### Things to try\n",
    "- Recurrent/LSTM\n",
    "- Convolutional NN\n",
    "- Dropout\n",
    "- Drop some g255 to make the classes equal\n",
    "- Tweak the class weightings\n",
    "- pass std as a feature\n",
    "- Make sure the gestures are labelled correctly\n",
    "- Why isn't the validation loss getting weighted like the training loss is?\n",
    "- Get some dumb thresholds to spot the rising/falling edge and only then send it off to the model\n",
    "\n",
    "#### Unanswered questions\n",
    "- Why is recall so low for every gesture except g255\n",
    "- Why don't the inverted frequencies work as class weights\n",
    "- Why does precision.g255 decrease as all others increase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999271bc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.utils.set_random_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698675f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"window_size\": 15,\n",
    "    \"window_skip\": 1,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 2048,\n",
    "    \"test_frac\": 0.25,\n",
    "    \"use_class_weights\": True,\n",
    "    \"n_hidden_units\": {\n",
    "        1: 128,\n",
    "        2: 128,\n",
    "        3: 128,\n",
    "    },\n",
    "    \"lr\": 1e-3,\n",
    "    \"loss_fn\": keras.losses.SparseCategoricalCrossentropy(),\n",
    "    'activation': \"softmax\",\n",
    "    \"omit_0255\": False,\n",
    "    \"g255_vs_rest\": False,\n",
    "    \"use_wandb\": False,\n",
    "}\n",
    "config['optimiser'] = keras.optimizers.Adam(learning_rate=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2ded3",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# config['use_wandb'] = True\n",
    "# wandb.init(\n",
    "#     project=\"ergo\",\n",
    "#     entity=\"beyarkay\",\n",
    "#     config=config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea697b7",
   "metadata": {
    "code_folding": [
     2,
     35,
     46,
     64,
     70
    ]
   },
   "outputs": [],
   "source": [
    "# Function and constant definitions\n",
    "\n",
    "FINGERS = [\n",
    "    'left-5-x',\n",
    "    'left-5-y',\n",
    "    'left-5-z',\n",
    "    'left-4-x',\n",
    "    'left-4-y',\n",
    "    'left-4-z',\n",
    "    'left-3-x',\n",
    "    'left-3-y',\n",
    "    'left-3-z',\n",
    "    'left-2-x',\n",
    "    'left-2-y',\n",
    "    'left-2-z',\n",
    "    'left-1-x',\n",
    "    'left-1-y',\n",
    "    'left-1-z',\n",
    "    'right-1-x',\n",
    "    'right-1-y',\n",
    "    'right-1-z',\n",
    "    'right-2-x',\n",
    "    'right-2-y',\n",
    "    'right-2-z',\n",
    "    'right-3-x',\n",
    "    'right-3-y',\n",
    "    'right-3-z',\n",
    "    'right-4-x',\n",
    "    'right-4-y',\n",
    "    'right-4-z',\n",
    "    'right-5-x',\n",
    "    'right-5-y',\n",
    "    'right-5-z',    \n",
    "]\n",
    "\n",
    "def make_batches(X, y, window_size=10, window_skip=1):\n",
    "    assert window_skip == 1, 'window_skip is not supported for values other than 1'\n",
    "    ends = np.array(range(window_size, len(y) - 1))\n",
    "    starts = ends - window_size\n",
    "    batched_X = np.empty((ends.shape[0], window_size, X.shape[1]))\n",
    "    batched_y = np.empty((ends.shape[0],), dtype='object')\n",
    "    for i in range(batched_y.shape[0]):\n",
    "        batched_X[i] = X[starts[i]:ends[i]]\n",
    "        batched_y[i] = y[ends[i]]\n",
    "    return batched_X, batched_y\n",
    "\n",
    "def gestures_and_indices(y):\n",
    "    labels = sorted(np.unique(y))\n",
    "    g2i_dict = {g:i for i, g in enumerate(labels)}\n",
    "    i2g_dict = {i:g for i, g in enumerate(labels)}\n",
    "    def g2i(g):\n",
    "        not_list = type(g) not in [list, np.ndarray]\n",
    "        if not_list: g = [g]\n",
    "        result = np.array([g2i_dict[gi] for gi in g])\n",
    "        return result[0] if not_list else result\n",
    "\n",
    "    def i2g(i):\n",
    "        not_list = type(i) not in [list, np.ndarray]\n",
    "        if not_list: i = [i]\n",
    "        result = np.array([i2g_dict[ii] for ii in i])\n",
    "        return result[0] if not_list else result\n",
    "    \n",
    "    return g2i, i2g\n",
    "\n",
    "def one_hot_and_back(y_all):\n",
    "    return (\n",
    "        lambda y: tf.one_hot(y, len(np.unique(y_all))),\n",
    "        lambda onehot: tf.argmax(one_hot, axis=1)\n",
    "    )\n",
    "\n",
    "def conf_mat(model, X, y):\n",
    "    y_pred = np.argmax(model.predict(X), axis=1)\n",
    "    y_true = y\n",
    "\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    labels = [i2g(i) for i in range(confusion_mtx.shape[0])]\n",
    "    sns.heatmap(\n",
    "        confusion_mtx, \n",
    "        annot=True, \n",
    "        fmt='g',\n",
    "        xticklabels=labels, \n",
    "        yticklabels=labels,\n",
    "        vmin=confusion_mtx.min(),\n",
    "        vmax=confusion_mtx[:-1, :-1].max(),\n",
    "    )\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    return confusion_mtx\n",
    "\n",
    "def plot_timeseries(X, y, t=None, per='dimension'):\n",
    "    # Make sure the given dataset is correctly formatted\n",
    "    assert X.shape[0] == y.shape[0], 'There must be one y value for each X value'\n",
    "    assert X.shape[1] == len(FINGERS), f'{X.shape[1]=} doesn\\'t equal the number of finger labels ({len(FINGERS)})'\n",
    "    assert not np.isnan(X_mean).any(), f'Input dataset has {np.isnan(X_mean).sum()} NaN values. Should have 0'\n",
    "    \n",
    "    # If we've got many many points, only show an abridged version of the plot\n",
    "    abridged = X.shape[0] > 4000\n",
    "    if per == 'dimension':\n",
    "        nrows, ncols = (3, 1)\n",
    "    elif per == 'finger':\n",
    "        nrows, ncols = (5, 2)\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(13, 8))\n",
    "    if len(axs.shape) > 1:\n",
    "        axs = axs.T.flatten()\n",
    "\n",
    "    ymin = float('inf')\n",
    "    ymax = float('-inf')\n",
    "\n",
    "    max_std = X.std(axis=0).max()\n",
    "    for d in range(X.shape[1]):\n",
    "        if per == 'dimension':\n",
    "            ax_idx = d % 3\n",
    "        elif per == 'finger':\n",
    "            ax_idx = d // 3\n",
    "            \n",
    "        ax = axs[ax_idx]\n",
    "        data_to_plot = X[:, d]\n",
    "        ax.plot(\n",
    "            data_to_plot, \n",
    "            alpha=np.clip(data_to_plot.std() / max_std, 0.05, 1.0),\n",
    "            label=FINGERS[d],\n",
    "            c=None if per == 'dimension' else ('tab:red', 'tab:green', 'tab:blue')[d%3]\n",
    "        )\n",
    "        \n",
    "        # Set the title of each plot\n",
    "        if per == 'dimension':\n",
    "            ax.set_title(f'{FINGERS[d][-1]}')\n",
    "        elif per == 'finger':\n",
    "            ax.set_title(f'{FINGERS[d][:-2]}')\n",
    "            \n",
    "        ymax = max(ymax, X[:, d].max())\n",
    "        ymin = min(ymin, X[:, d].min())\n",
    "\n",
    "    # Plot the ticks and legend for each axis\n",
    "    NUM_LABELS = 40 if per == 'dimension' else 20\n",
    "    TICKS_PER_LABEL = max(1, X.shape[0] // NUM_LABELS)\n",
    "    for i, ax in enumerate(axs):\n",
    "        if abridged:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xticks(range(0, X.shape[0], TICKS_PER_LABEL))\n",
    "            if (per == 'dimension' and i != len(axs)-1) or (per == 'finger' and i % 5 != 4):\n",
    "                ax.set_xticklabels([])\n",
    "            elif t is not None:\n",
    "                ax.set_xticklabels(t[::TICKS_PER_LABEL], rotation=90)\n",
    "        if per == 'dimension':\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(\n",
    "                handles, \n",
    "                labels, \n",
    "                loc='center left', \n",
    "                bbox_to_anchor=(1., 0.5)\n",
    "            )\n",
    "    # Plot the labels for each timestep and axis\n",
    "    for dim_idx, ax in enumerate(axs):\n",
    "        backtrack = 0\n",
    "        for time in range(X.shape[0]):\n",
    "            if abridged:\n",
    "                continue\n",
    "            if y[time] not in ['gesture0255', 'g255'] and time != X.shape[0]-1:\n",
    "                backtrack += 1\n",
    "                continue\n",
    "            elif y[time] in ['gesture0255', 'g255'] and backtrack == 0:\n",
    "                continue\n",
    "            else:\n",
    "                ax.fill_betweenx(\n",
    "                    y=[ymin * 0.9, ymax * 1.1],\n",
    "                    x1=[time - backtrack - .5, time - backtrack - .5],\n",
    "                    x2=[time - 0.5, time - 0.5],\n",
    "                    color='grey',\n",
    "                    alpha=0.1\n",
    "                )\n",
    "\n",
    "                txt = y[time - backtrack].replace('gesture0', 'g')\n",
    "                ax.text(\n",
    "                    time - backtrack / 2 - .5,\n",
    "                    (ymax - ymin)/2 + ymin,\n",
    "                    txt,\n",
    "                    va='baseline',\n",
    "                    ha='center',\n",
    "                    rotation=90\n",
    "                )\n",
    "                backtrack = 0\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c1d15",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Read in data and format to {X,y}_{train,test}\n",
    "\n",
    "def parse_csvs(root='../gesture_data/train/'):\n",
    "    print(\"TODO does this take into account how batches shouldn't straddle non-contiguous datasets?\")\n",
    "    dfs = []\n",
    "    for path in os.listdir(root):\n",
    "    #     print(f'reading data from {path}')\n",
    "        dfs.append(pd.read_csv(\n",
    "            root + path,\n",
    "            names=['datetime', 'gesture'] + FINGERS,\n",
    "            parse_dates=[1]\n",
    "        ))\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    df.datetime = df.datetime.apply(pd.Timestamp)\n",
    "    return df\n",
    "df = parse_csvs()\n",
    "# df = pd.read_csv('../gesture_data/relabelled_gesture0001.csv')\n",
    "X, y = make_batches(    \n",
    "    df.drop(['datetime', 'gesture'], axis=1).to_numpy(), \n",
    "    df['gesture'].to_numpy(),\n",
    "    window_size=config['window_size'],\n",
    "    window_skip=config['window_skip'],\n",
    ")\n",
    "\n",
    "if config.get('omit_0255', False):\n",
    "    X = X[y != 'gesture0255']\n",
    "    y = y[y != 'gesture0255']\n",
    "    \n",
    "if config.get('g255_vs_rest', False):\n",
    "    y = np.where(\n",
    "        y == 'gesture0255',\n",
    "        'gesture0255',\n",
    "        'gesture0000'\n",
    "    )\n",
    "\n",
    "# Get functions to convert between gestures and indices\n",
    "g2i, i2g = gestures_and_indices(y)\n",
    "y = g2i(y)\n",
    "# Get functions to convert between indices and one hot encodings\n",
    "i2ohe, ohe2i = one_hot_and_back(y)\n",
    "\n",
    "total = len(y)\n",
    "n_unique = len(np.unique(y))\n",
    "config['gestures'] = np.unique(y)\n",
    "class_weight = {\n",
    "    int(class_): (1/freq * total/n_unique) for class_, freq in zip(*np.unique(y, return_counts=True))\n",
    "}\n",
    "\n",
    "# class_weight[g2i('gesture0255')] *= 2\n",
    "\n",
    "config['class_weight'] = class_weight if config['use_class_weights'] else None\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=config['test_frac'], \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba225f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i2g(i), c) for i, c in zip(*np.unique(y, return_counts=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b494d8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "inputs = layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train)\n",
    "x = normalizer(inputs)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "for layer_number, num_units in config.get(\"n_hidden_units\").items():\n",
    "    x = layers.Dense(\n",
    "        units=num_units,\n",
    "    )(x)\n",
    "\n",
    "\n",
    "def init_biases(shape, dtype=None):\n",
    "    assert shape == [len(class_weight)], f\"Shape {shape} isn't (11,)\"\n",
    "    inv_freqs = np.array([1/v for v in class_weight.values()])\n",
    "    return np.log(inv_freqs)\n",
    "\n",
    "outputs = layers.Dense(\n",
    "    len(np.unique(y)), \n",
    "    activation=config.get(\"activation\"),\n",
    "    bias_initializer=init_biases,\n",
    ")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.SparseCategoricalAccuracy(name='sca'),\n",
    "    keras.metrics.SparseCategoricalCrossentropy(name='scce')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=config['optimiser'],\n",
    "    loss=config['loss_fn'],\n",
    "    weighted_metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81920d6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define a custom callback for multi-class accuracy/recall/precision\n",
    "import time\n",
    "class MultiClassAccAndRecallCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, training_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.training_data = training_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        start = time.time()\n",
    "        # Calculate per-class {validation,training} {recall,precision}\n",
    "        datas = [\n",
    "            self.validation_data,\n",
    "            self.training_data,\n",
    "        ]\n",
    "        keys = ['valid', 'train']\n",
    "        for key, data in zip(keys, datas):\n",
    "            X, y = data\n",
    "            conf_mat = tf.math.confusion_matrix(\n",
    "                np.argmax(self.model.predict(X, verbose=0), axis=1),\n",
    "                y,\n",
    "            ).numpy()\n",
    "            precision = np.diag(conf_mat)  / conf_mat.sum(axis=0)\n",
    "            recall = np.diag(conf_mat)  / conf_mat.sum(axis=1)\n",
    "\n",
    "            ipr = list(zip(range(len(precision)), precision, recall))\n",
    "            prec_and_recall = {i2g([i])[0]: {'precision': p, 'recall': r} for i, p, r in ipr}\n",
    "            if config['use_wandb']:\n",
    "                wandb.log({key: prec_and_recall}, commit=False)\n",
    "        duration = time.time() - start\n",
    "        if config['use_wandb']:\n",
    "            wandb.log({'tt_calc_precision_recall': duration}, commit=False)\n",
    "        \n",
    "# class LogConfusionMatrixCallback(keras.callbacks.Callback):\n",
    "#     def __init__(self, validation_data):\n",
    "#         super().__init__()\n",
    "#         self.validation_data = validation_data\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         labels = np.unique(self.validation_data[1])        \n",
    "#         cm = wandb.plot.confusion_matrix(\n",
    "#             y_true=self.validation_data[1],\n",
    "#             preds=np.argmax(self.model.predict(self.validation_data[0], verbose=0), axis=1),\n",
    "#             class_names=labels\n",
    "#         )\n",
    "#         wandb.log({\"conf_mat\": cm}, commit=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971c7dd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "if config['use_wandb']:\n",
    "    callbacks = [\n",
    "        WandbCallback(),\n",
    "        MultiClassAccAndRecallCallback((X_valid, y_valid), (X_train, y_train)),\n",
    "    ]\n",
    "else:\n",
    "    callbacks = []\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=config['batch_size'], \n",
    "    epochs=config['epochs'],\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=config['class_weight'],\n",
    ")\n",
    "if config['use_wandb']:\n",
    "    wandb.finish()\n",
    "model.save(f'models/{datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec46b9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot metrics from history\n",
    "items = list(history.history.keys())\n",
    "items = items[:len(items)//2]\n",
    "_fig, axs = plt.subplots(1, len(items), figsize=(5*len(items), 5))\n",
    "\n",
    "for item, ax in zip(items, axs):\n",
    "    ax.plot(\n",
    "        history.history[f'{item}']\n",
    "    )\n",
    "    ax.plot(\n",
    "        history.history[f'val_{item}']\n",
    "    )\n",
    "    ax.set_title(f'model {item}')\n",
    "\n",
    "    if item == 'sca':\n",
    "        ax.set_ylim((0, 1))\n",
    "    else:\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_ylim((0, ylim[1]))\n",
    "    ax.set_ylabel(item)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'val'], loc='best')\n",
    "\n",
    "plt.suptitle('Without \"fixed\" gesture0001')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d99c5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "subtitle = 'Without fixed gesture0001'\n",
    "conf_mat(model, X_valid, y_valid)\n",
    "plt.title(f'Validation set\\n{subtitle}')\n",
    "plt.show()\n",
    "\n",
    "conf_mat(model, X_train, y_train)\n",
    "plt.title(f'Training set\\n{subtitle}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04859e38",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate precision and recall for each gesture\n",
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    np.argmax(model.predict(X_valid, verbose=0), axis=1), \n",
    "    y_valid\n",
    ").numpy()\n",
    "precision = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=0)\n",
    "recall = np.diag(confusion_mtx)  / confusion_mtx.sum(axis=1)\n",
    "ipr = list(zip(range(len(precision)), precision, recall))\n",
    "prec_and_recall = {i2g(i): {'precision': p, 'recall': r} for i, p, r in ipr}\n",
    "\n",
    "print('\\n'.join([f'{i2g(i)}:    precision:{p:.3f}, recall: {r:.3f}' for i, p, r in ipr]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dc192",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Ratio of true predictions over g255\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(\n",
    "    x=range(confusion_mtx.shape[0]),\n",
    "    height=np.diag(confusion_mtx) / confusion_mtx[:, -1]\n",
    ")\n",
    "ax.set_xticks(range(confusion_mtx.shape[0]))\n",
    "labels = i2g(list(range(confusion_mtx.shape[0])))\n",
    "labels = [l.replace('gesture0', 'g') for l in labels]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('Ratio of True Predictions over classified-as-g255')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99aea8d",
   "metadata": {},
   "source": [
    "### Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eceb1e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "START_IDX = 0\n",
    "FINSH_IDX = 150\n",
    "\n",
    "df = pd.read_csv('../gesture_data/relabelled.csv')\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "data = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(data)\n",
    "data = normalizer(data).numpy()\n",
    "# data = data[START_IDX:FINSH_IDX, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa9f47",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Explore the dataset between a given range\n",
    "# @interact(rng=widgets.IntRangeSlider(\n",
    "#     value=[0, 150],\n",
    "#     min=0,\n",
    "#     max=(df.shape[0] // 10),\n",
    "#     step=5,\n",
    "#     continuous_update=False\n",
    "# ))\n",
    "STEP = 25\n",
    "@interact(rng=widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=df.shape[0],\n",
    "    step=STEP,\n",
    "    continuous_update=False\n",
    "))\n",
    "def interact_plot_timeseries(rng):\n",
    "#     start, finsh = (rng[0]*10, rng[1]*10)\n",
    "    start, finsh = ((rng), (rng+2*STEP))\n",
    "    data = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "    data = normalizer(data).numpy()[start:finsh, :]\n",
    "    plot_timeseries(\n",
    "        data, \n",
    "        df['gesture'].to_numpy()[start:finsh],\n",
    "        df['datetime'].dt.strftime('%h-%d %H:%m:%S').to_numpy()[start:finsh],\n",
    "        per='finger'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8b312",
   "metadata": {},
   "source": [
    "Rule for re-labelling measurements\n",
    "1. Measurements are <250ms before or after an existing label\n",
    "2. Labels are all contiguous\n",
    "3. Windows are no longer than 60ms long (3 measurements)\n",
    "4. Measurements have std > 3 in more than 1 dimenison\n",
    "\n",
    "\n",
    "Also delete all non-0255 gestures that occur in the first 250ms of a recording\n",
    "\n",
    "Does the batching process take into account that the df is non-contiguous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be71c4f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Relabel the dataset\n",
    "gesture = 'gesture0006'\n",
    "window_size = 20\n",
    "y_orig = df['gesture'].to_numpy()\n",
    "\n",
    "df = pd.read_csv('../gesture_data/relabelled.csv')\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "@interact(\n",
    "    val=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=-window_size,\n",
    "        max=window_size,\n",
    "        step=1,\n",
    "        continuous_update=False\n",
    "#     rng=widgets.IntRangeSlider(\n",
    "#         value=[0, 1],\n",
    "#         min=-window_size,\n",
    "#         max=window_size,\n",
    "#         step=1,\n",
    "#         continuous_update=False\n",
    "), INDEX=widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(np.nonzero(y_orig == gesture)[0]),\n",
    "    step=1,\n",
    "    description='INDEX:'\n",
    "))\n",
    "def interact_fix_labels(val=0, INDEX=0):\n",
    "    rng = (val, val+1)\n",
    "    y_orig = df['gesture'].to_numpy()\n",
    "    X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "    t_orig = df['datetime'].to_numpy()\n",
    "    # Get a series which is y_orig, but shifted backwards by one\n",
    "    y_offset = np.concatenate((['gesture0255'], y_orig[:-1]))\n",
    "    # Get all the indices where the gesture goes [..., !=gesture, ==gesture, ...]\n",
    "    indices = np.nonzero((y_orig == gesture) & (y_offset != gesture))[0]\n",
    "\n",
    "    start, finsh = rng\n",
    "    idx = indices[INDEX]\n",
    "    print(f'{INDEX / len(indices) * 100:.0f}%')\n",
    "    window_start = idx - window_size\n",
    "    window_finsh = idx + window_size+1\n",
    "    X = X_orig[window_start : window_finsh]\n",
    "    t = t_orig[window_start : window_finsh]\n",
    "    y_true = y_orig[window_start : window_finsh]\n",
    "    y_new = y_true.copy()\n",
    "    y_true = np.array([yi.replace('gesture0255', 'g255') for yi in y_true])\n",
    "    \n",
    "    # Remove the old label\n",
    "    y_new[window_size - 5: window_size + 5] = 'gesture0255'\n",
    "    # Get indices for the new label\n",
    "    s = window_size + start\n",
    "    f = window_size + finsh\n",
    "    # Set the new label\n",
    "    y_new[s:f] = gesture\n",
    "    \n",
    "    # Plot the new labels and the old labels\n",
    "    plot_timeseries(\n",
    "        X, \n",
    "        y_new,\n",
    "        y_true,\n",
    "        per='finger'\n",
    "    )\n",
    "#     print(df.loc[df['datetime'].isin(t[s:f]), ['datetime', 'gesture']])\n",
    "    time_mask = df['datetime'].isin(t_orig[window_start : window_finsh])\n",
    "    def change_df(_):\n",
    "        df.loc[time_mask, 'gesture'] = y_new\n",
    "        print(f'Modified {sum(time_mask)} measurements.')\n",
    "        \n",
    "    button = widgets.Button(\n",
    "        description='Save',\n",
    "        button_style='danger',\n",
    "    )\n",
    "    button.on_click(change_df)\n",
    "    display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e083b3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../gesture_data/relabelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0aba8",
   "metadata": {
    "code_folding": [
     11,
     17,
     38,
     60
    ]
   },
   "outputs": [],
   "source": [
    "# Visualise confidence intervals per finger\n",
    "gesture = 'gesture0006'\n",
    "y_orig = df['gesture'].to_numpy()\n",
    "X_orig = df.drop(['datetime', 'gesture'], axis=1).to_numpy()\n",
    "t_orig = df['datetime'].to_numpy()\n",
    "# Get a series which is y_orig, but shifted backwards by one\n",
    "y_offset = np.concatenate((['gesture0255'], y_orig[:-1]))\n",
    "# Get all the indices where the gesture goes [..., !=gesture, ==gesture, ...]\n",
    "indices = np.nonzero((y_orig == gesture) & (y_offset != gesture))[0]\n",
    "\n",
    "\n",
    "Xs = np.empty((\n",
    "    len(indices), \n",
    "    window_size * 2 + 1,\n",
    "    X_orig.shape[-1]\n",
    "))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    window_start = idx - window_size\n",
    "    window_finsh = idx + window_size + 1\n",
    "    Xs[i] = X_orig[window_start : window_finsh]\n",
    "\n",
    "X_mean = Xs.mean(axis=0)\n",
    "X_std = Xs.std(axis=0)\n",
    "\n",
    "blank_labels = np.array(['g255'] * X.shape[0])\n",
    "\n",
    "PER = 'finger'\n",
    "_fig, axs = plot_timeseries(\n",
    "    X_mean,\n",
    "    blank_labels,\n",
    "    per=PER\n",
    ")\n",
    "\n",
    "ymin = float('inf')\n",
    "ymax = float('-inf')\n",
    "max_std = X_mean.std(axis=0).max()\n",
    "\n",
    "for d in range(X_mean.shape[1]):\n",
    "    if PER == 'dimension':\n",
    "        ax_idx = d % 3\n",
    "    elif PER == 'finger':\n",
    "        ax_idx = d // 3\n",
    "\n",
    "    ax = axs[ax_idx]\n",
    "\n",
    "    high = X_mean[:, d] + X_std[:, d]\n",
    "    low = X_mean[:, d] - X_std[:, d]\n",
    "    ymin = min(ymin, min(low))\n",
    "    ymax = max(ymax, max(high))\n",
    "    \n",
    "    kwargs = {} if PER == 'dimension' else {'color': ('tab:red', 'tab:green', 'tab:blue')[d%3]}\n",
    "    ax.fill_between(\n",
    "        range(len(X_mean[:, d])),\n",
    "        low,\n",
    "        high,\n",
    "        alpha=np.clip(X_mean[:, d].std() / (4*max_std), 0.05, 1.0),\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim((ymin * 0.9, ymax * 1.1))\n",
    "    \n",
    "title = f'Mean measurements for {gesture}\\n(per {PER})'\n",
    "plt.suptitle(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs/' + title.lower().replace(' ', '-') + '.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74167d7f",
   "metadata": {},
   "source": [
    "# TODO: Fix the dataset\n",
    "- Try train on a small, but very good, dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
