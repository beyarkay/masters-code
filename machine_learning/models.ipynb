{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b94d03",
   "metadata": {},
   "source": [
    "# Create models from *Ergo* data\n",
    "This notebook contains the code for models used to predict the *Ergo* data. See the report [here](https://git.cs.sun.ac.za/Computer-Science/rw771/2022/26723077-TG7-doc) or the source code behind the data [here](https://git.cs.sun.ac.za/Computer-Science/rw771/2022/26723077-TG7-src).\n",
    "\n",
    "### Items to explore\n",
    "\n",
    "- What is the optimal number of PCs for model performance?\n",
    "- Which is the optimal dimensionality reduction method: tSNE, Autoencoder, PCA?\n",
    "- Compare different model types: Random Forest, SVM, NN, Nïeve Bayes, Quadratic Discriminent Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d042fe",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from common_utils import *\n",
    "\n",
    "import pickle\n",
    "from matplotlib import cm\n",
    "from time import time\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Distributions\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1044a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_W_AND_B = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09dd19",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some metadata and descriptions about the gestures\n",
    "gesture_info = get_gesture_info()\n",
    "\n",
    "# Get a hashmap of the form `directory` => [`file1`, `file2`, ...]\n",
    "dir_files = get_dir_files()\n",
    "\n",
    "# Print out all the gestures that we've got data for\n",
    "format_string = \"\\n- \".join([\n",
    "    f'{k}: {gesture_info.get(k, {}).get(\"description\", \"<No description>\"):<40} ({len(v)} files)' \n",
    "    for k,v in dir_files.items()\n",
    "])\n",
    "print(f'The following gestures have data recorded for them:\\n- {format_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324eff7d",
   "metadata": {},
   "source": [
    "## Read in the data to an `np.array`\n",
    "\n",
    "TODO: Convert this into a method in `common_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sensors, n_timesteps = 30, 40\n",
    "\n",
    "# Exclude all classes which do not have at least 300 observations\n",
    "n_classes = len([d for d,fs in dir_files.items() if len(fs) > 300])\n",
    "n_obs = sum([len(fs) for d, fs in dir_files.items() if len(fs) > 300])\n",
    "print(f'{n_classes=}, {n_obs=}')\n",
    "\n",
    "# Create arrays to store the observations and labels\n",
    "X = np.zeros((n_obs, n_sensors * n_timesteps))\n",
    "y = np.zeros((n_obs,))\n",
    "# Also keep track of the paths from which each observation originated\n",
    "paths = []\n",
    "\n",
    "# Create hashmaps to easily convert from and from indexes (0, 1, 2, 3, ...) \n",
    "# and gestures ('gesture0001', 'gesture0002', ...)\n",
    "idx_to_gesture = {}\n",
    "gesture_to_idx = {}\n",
    "\n",
    "# The `obs_idx` increments with every observation\n",
    "obs_idx = 0\n",
    "# The `label_idx` increments with every label iff \n",
    "# there's > 300 observations for that label\n",
    "label_idx = 0\n",
    "\n",
    "# Iterate over every gesture\n",
    "for gesture_index, filenames in dir_files.items():\n",
    "    if len(filenames) > 300:\n",
    "        # Populate the idx <-> gesture mapping\n",
    "        idx_to_gesture[label_idx] = gesture_index\n",
    "        gesture_to_idx[gesture_index] = label_idx\n",
    "        \n",
    "        \n",
    "        print(f\"Processing {gesture_index} ({gesture_info[gesture_index]['desc']})\")\n",
    "        # Iterate over every observation for the current gesture\n",
    "        for file in filenames:\n",
    "            # Keep track of the path for bookkeeping purposes\n",
    "            paths.append(f'../gesture_data/train/{gesture_index}/{file}')\n",
    "            # Read in the raw sensor data. Normalisation is done later on via sklearn\n",
    "            df = read_to_df(paths[-1], normalise=False)\n",
    "            # Make sure the data is the correct shape\n",
    "            if df.shape != (n_timesteps, n_sensors):\n",
    "                print(df)\n",
    "            # Save observation as a plain `np.array` in the X array\n",
    "            X[obs_idx] = df.to_numpy().T.flatten()\n",
    "            # If there are any NaNs, the observation is probably \n",
    "            # incomplete and should be removed\n",
    "            if np.any(np.isnan(X[obs_idx])):\n",
    "                print(f'rm {paths[-1]}')\n",
    "            # Save the label of the current observation\n",
    "            y[obs_idx] = label_idx\n",
    "            \n",
    "            obs_idx += 1\n",
    "        label_idx += 1\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58c5c2",
   "metadata": {},
   "source": [
    "### Train-test split and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45148741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, paths_train, paths_test = train_test_split(\n",
    "    X, y, np.array(paths), test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe363252",
   "metadata": {},
   "source": [
    "## Train models without dimensionality reduction\n",
    "\n",
    "\n",
    "Training KNeighborsClassifier(n_neighbors=21)\n",
    "- Time taken: 153.927s\n",
    "- Best performing model\n",
    "`KNeighborsClassifier(algorithm='ball_tree', n_neighbors=21)`\n",
    "- Score: train: 0.9679, test: 0.9774\n",
    "\n",
    "\n",
    "Training MLPClassifier(max_iter=1000)\n",
    "- Time taken: 81.279s\n",
    "- Best performing model\n",
    "```MLPClassifier(activation='tanh', alpha=0.0013330009770265291, hidden_layer_sizes=400, max_iter=1000)```\n",
    "- Score: train: 0.9907, test: 0.9947\n",
    "\n",
    "Training MLPClassifier(max_iter=1000)\n",
    "- Time taken: 27.189s\n",
    "- Best performing model\n",
    "`MLPClassifier(alpha=0.0016877545702567223, hidden_layer_sizes=100, max_iter=1000)`\n",
    "- Score: train: 0.9903, test: 0.9950\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc8e4d3",
   "metadata": {},
   "source": [
    "15h44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models = []\n",
    "\n",
    "models.append(\n",
    "    (MLPClassifier(max_iter=1000), {\n",
    "        'hidden_layer_sizes': [(100), (200), (400), (100, 50), (200, 100), (400, 200), \n",
    "                               (100, 50, 25), (200, 100, 50), (400, 200, 100)],\n",
    "#         'hidden_layer_sizes': [(50)],\n",
    "        'activation' : ['logistic', 'tanh', 'relu'],\n",
    "        'solver' : ['lbfgs', 'adam'],\n",
    "        'alpha': loguniform(1e-6, 1e-2),\n",
    "    })\n",
    ")\n",
    "\n",
    "clfs = []\n",
    "for model, param_grid in models:\n",
    "    print(f'\\nTraining {model}')\n",
    "    start = time()\n",
    "    clf = RandomizedSearchCV(\n",
    "        model, param_grid, n_iter=10\n",
    "    )\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(f'- Time taken: {time() - start:.3f}s\\n- Best performing model\\n`{clf.best_estimator_}`\\n- Score: train: {clf.best_score_:.4f}, test: {clf.score(X_test, y_test):.4f}')\n",
    "    clfs.append(clf.best_estimator_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d677905",
   "metadata": {},
   "source": [
    "### Visualise important features from full-dimensionality classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = clfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 4\n",
    "fig, axes = plt.subplots(n_classes//num_cols+1, num_cols)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for gesture_idx, ax in enumerate(axes.ravel()):\n",
    "    if gesture_idx >= n_classes:\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.grid(False)\n",
    "        continue\n",
    "        \n",
    "    multiplied = mlp.coefs_[0]\n",
    "    for layer in range(1, len(mlp.coefs_)):\n",
    "        multiplied = multiplied @ mlp.coefs_[layer]\n",
    "\n",
    "    importances = multiplied[:, gesture_idx].reshape(n_sensors, n_timesteps)\n",
    "#     importances = (mlp.coefs_[0] @ mlp.coefs_[1][:, gesture_idx]).reshape(n_sensors, n_timesteps)\n",
    "    \n",
    "    gesture_label = idx_to_gesture[gesture_idx]\n",
    "    gesture_description = gesture_info[gesture_label]['description']\n",
    "    plot_raw_gesture(\n",
    "        importances.reshape(n_sensors, n_timesteps).T,\n",
    "        f'{gesture_label}\\n{gesture_description}',\n",
    "        ax=ax,\n",
    "        show_cbar=False,\n",
    "        show_xticks=False,\n",
    "        show_yticks=False,\n",
    "        delim_lw=0\n",
    "    )\n",
    "\n",
    "plt.suptitle('Importances per gesture for the trained MLP')\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs/importances.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "\n",
    "fig, axes = plt.subplots(5, 5)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(\n",
    "        coef.reshape(n_sensors, n_timesteps), \n",
    "        cmap=plt.cm.gray, \n",
    "        vmin=0.5 * vmin, \n",
    "        vmax=0.5 * vmax\n",
    "    )\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da7ca0",
   "metadata": {},
   "source": [
    "### Reduce dimensionality via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71298177",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_components = 10\n",
    "\n",
    "print(f'Fitting PCA with {n_components} components on {X_train.shape[0]} observations')\n",
    "pca = PCA(\n",
    "    n_components=n_components,\n",
    "    svd_solver=\"randomized\", \n",
    "    whiten=True\n",
    ").fit(X_train)\n",
    "\n",
    "print(f\"PCA explained {100*sum(pca.explained_variance_ratio_):.2f}% of the variance with {n_components} PCs\")\n",
    "\n",
    "# PCA-transform the input test and train data\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea526e0c",
   "metadata": {},
   "source": [
    "## Train multiple models on the data\n",
    "Each model is defined in its own cell, and appended to the list `models`. \n",
    "After all the definitions, every model in the list is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a28159",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b07af5",
   "metadata": {},
   "source": [
    "---\n",
    "Support Vector Machine\n",
    "- Time taken: 7.731s\n",
    "- Best performing model\n",
    "`SVC(C=35891.14381335473, class_weight='balanced', gamma=0.057667711437645666)`\n",
    "- Score: train: 0.9896, test: 0.9901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65004ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (SVC(kernel=\"rbf\", class_weight=\"balanced\"), {\n",
    "        \"C\": loguniform(1e3, 1e5),\n",
    "        \"gamma\": loguniform(1e-4, 1e-1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479958a6",
   "metadata": {},
   "source": [
    "---\n",
    "Linear Support Vector Machine\n",
    "\n",
    "- Time taken: 367.828s\n",
    "- Best performing model: SVC(C=1284.851851420933, class_weight='balanced', kernel='linear')\n",
    "- Score: train: 0.9780, test: 0.9784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c48000",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (SVC(kernel=\"linear\", class_weight=\"balanced\"), {\n",
    "        \"C\": loguniform(1e3, 1e5),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e7aa2",
   "metadata": {},
   "source": [
    "---\n",
    "K-Nearest Neighbours\n",
    "- Time taken: 0.820s\n",
    "- Best performing model\n",
    "`KNeighborsClassifier(algorithm='ball_tree', n_neighbors=21)`\n",
    "- Score: train: 0.9849, test: 0.9851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (KNeighborsClassifier(n_neighbors=n_classes), {\n",
    "        \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef3419",
   "metadata": {},
   "source": [
    "---\n",
    "Ada Boost\n",
    "- Time taken: 268.507s\n",
    "- Best performing model: AdaBoostClassifier(learning_rate=0.20109497487437183, n_estimators=792)\n",
    "- Score: train: 0.7856, test: 0.7867\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (AdaBoostClassifier(), {\n",
    "        'n_estimators': range(10, 1000),\n",
    "        'learning_rate': np.linspace(1e-4, 2, num=200),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a1301",
   "metadata": {},
   "source": [
    "---\n",
    "Decision Tree\n",
    "- Time taken: 1.136s\n",
    "- Best performing model\n",
    "`DecisionTreeClassifier(class_weight='balanced', max_depth=186,\n",
    "                       min_samples_split=0.26530612244897955)`\n",
    "- Score: train: 0.4396, test: 0.4712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (DecisionTreeClassifier(class_weight=\"balanced\"), {\n",
    "        'max_depth': range(1, 200),\n",
    "        'min_samples_split': np.linspace(0, 1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a119016",
   "metadata": {},
   "source": [
    "---\n",
    "Random Forest\n",
    "- Time taken: 31.299s\n",
    "- Best performing model\n",
    "\n",
    "`RandomForestClassifier(max_depth=187, max_features=0.836734693877551,\n",
    "                       min_samples_split=0.16326530612244897, n_estimators=176)`\n",
    "- Score: train: 0.6110, test: 0.6095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98baf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (RandomForestClassifier(), {\n",
    "        'n_estimators': range(10, 500), \n",
    "        'max_depth': range(1, 200), \n",
    "        'max_features': np.linspace(0, 1),\n",
    "        'min_samples_split': np.linspace(0, 1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaff8d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Multi-layer Perceptron\n",
    "- Time taken: 484.457s\n",
    "- Best performing model\n",
    "\n",
    "```MLPClassifier(activation='tanh', alpha=2.8761865563186644e-05,\n",
    "              hidden_layer_sizes=(400, 200), max_iter=1000)```\n",
    "- Score: train: 0.9914, test: 0.9919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (MLPClassifier(max_iter=1000), {\n",
    "        'hidden_layer_sizes': [(100), (200), (400), (100, 50), (200, 100), (400, 200), \n",
    "                               (100, 50, 25), (200, 100, 50), (400, 200, 100)],\n",
    "        'activation' : ['logistic', 'tanh', 'relu'],\n",
    "        'solver' : ['lbfgs', 'adam'],\n",
    "        'alpha': loguniform(1e-6, 1e-2),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9fbe6",
   "metadata": {},
   "source": [
    "---\n",
    "Gaussian Naïve Bayes\n",
    "- Time taken: 0.031s\n",
    "- Best performing model: GaussianNB()\n",
    "- Score: train: 0.9255, test: 0.9264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((GaussianNB(), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5717c",
   "metadata": {},
   "source": [
    "---\n",
    "Quadratic Discriminant Analysis\n",
    "- Time taken: 0.040s\n",
    "- Best performing model: QuadraticDiscriminantAnalysis()\n",
    "- Score: train: 0.9854, test: 0.9837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c54a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((QuadraticDiscriminantAnalysis(), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06570c",
   "metadata": {},
   "source": [
    "---\n",
    "## Fit and evaluate all models in `models`\n",
    "Now actually evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd348a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for model, param_grid in models:\n",
    "    print(f'\\nTraining {model}')\n",
    "    start = time()\n",
    "    clf = RandomizedSearchCV(\n",
    "        model, param_grid, n_iter=10\n",
    "    )\n",
    "    clf = clf.fit(X_train_pca, y_train)\n",
    "    print(f'- Time taken: {time() - start:.3f}s\\n- Best performing model\\n`{clf.best_estimator_}`\\n- Score: train: {clf.best_score_:.4f}, test: {clf.score(X_test_pca, y_test):.4f}')\n",
    "    clfs.append(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092345f",
   "metadata": {},
   "source": [
    "### Get detailed analyses of the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75400dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clf in clfs:\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    clf_name = f'{str(type(clf))}'.split('.')[-1][:-2]\n",
    "\n",
    "    print(f\"Test set results for {clf_name}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=gesture_to_idx.keys()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    ConfusionMatrixDisplay.from_estimator(\n",
    "        clf, \n",
    "        X_test_pca, \n",
    "        y_test, \n",
    "        display_labels=gesture_to_idx.keys(), \n",
    "        xticks_rotation=\"vertical\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.title(f'Confusion Matrix of \\n{clf}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'imgs/conf_mat_{clf}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedbf4a",
   "metadata": {},
   "source": [
    "## Plot the incorrect observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830014b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs[0]\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "X_test_incorrect = X_test[y_pred != y_test]\n",
    "y_pred_incorrect = y_pred[y_pred != y_test]\n",
    "y_test_incorrect = y_test[y_pred != y_test]\n",
    "paths_test_incorrect = paths_test[y_pred != y_test]\n",
    "\n",
    "\n",
    "@interact(idx=(0, y_pred_incorrect.shape[0], 1))\n",
    "def plot_incorrect(idx=0):\n",
    "    predicted = idx_to_gesture[y_pred_incorrect[idx]]\n",
    "    pred_desc = gesture_info[predicted]['description']\n",
    "    \n",
    "    actual = idx_to_gesture[y_test_incorrect[idx]]\n",
    "    actu_desc = gesture_info[actual]['description']\n",
    "    \n",
    "    path = '/'.join(paths_test_incorrect[idx].split('/')[3:])\n",
    "    \n",
    "    # Create 3 vertical axs:\n",
    "    # - top is an example of the actual gesture, \n",
    "    # - middle is the incorrectly predicted gesture,\n",
    "    # - bottom is an example of the predicted gesture\n",
    "    fig, axs = plt.subplots(3)\n",
    "    \n",
    "    # First plot an example of the actual gesture\n",
    "    actual_idx = next(i for i, yi in enumerate(y_train) if yi == y_pred_incorrect[idx])\n",
    "    gesture_label = idx_to_gesture[y_train[actual_idx]]\n",
    "    gesture_description = gesture_info[idx_to_gesture[y_train[actual_idx]]][\"description\"]\n",
    "    plot_raw_gesture(\n",
    "        X_train[actual_idx], \n",
    "        f'Example of {gesture_label} ({gesture_description})',\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    # Second plot the misclassified gesture\n",
    "    plot_raw_gesture(\n",
    "        X_test_incorrect[idx], \n",
    "        f'Predicted: {predicted} ({pred_desc})\\nActual: {actual} ({actu_desc})',\n",
    "        ax=axs[1],\n",
    "    )\n",
    "    \n",
    "    # Last plot an example of the predicted gesture\n",
    "    predicted_idx = next(i for i, yi in enumerate(y_train) if yi == y_test_incorrect[idx])\n",
    "    gesture_label = idx_to_gesture[y_train[predicted_idx]]\n",
    "    gesture_description = gesture_info[idx_to_gesture[y_train[predicted_idx]]][\"description\"]\n",
    "    plot_raw_gesture(\n",
    "        X_train[predicted_idx], \n",
    "        f'Example of {gesture_label} ({gesture_description})',\n",
    "        ax=axs[2],\n",
    "    )\n",
    "    \n",
    "    # Finally, tell matplotlib to recompute the layout\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97441e61",
   "metadata": {},
   "source": [
    "## Plot 2-component PCA to assess separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384e29c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PCA can be either 2D or 3D\n",
    "PLOT_2D = True\n",
    "\n",
    "# Transform the data via PCA. Either 2 or 3 components are used\n",
    "pca = PCA(n_components=(2 if PLOT_2D else 3))\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Each observation gets a different colour on the scatter plot, and\n",
    "# similar colours get different markers to better differentiate them\n",
    "colours = cm.get_cmap('turbo', n_classes)\n",
    "markers = ['.', 'x', '*', 'd']\n",
    "\n",
    "\n",
    "if PLOT_2D:\n",
    "    # Use 2D subplots\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "else:\n",
    "    # Use 3D subplots\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Optionally also plot the observation indices along with the points.\n",
    "# This helps when removing outliers, but increases the amount of clutter\n",
    "# if PLOT_2D:\n",
    "#     for i, yi in enumerate(y):\n",
    "#         ax.annotate(\n",
    "#             i, \n",
    "#             (X_r[i, 0], X_r[i, 1]),\n",
    "#             color=colours(yi/n_classes),\n",
    "#             size=5,\n",
    "#             alpha=0.5,\n",
    "#         )\n",
    "\n",
    "# Iterate over each label/gesture\n",
    "for i, label_idx in enumerate(idx_to_gesture.keys()):\n",
    "    # Args either has 2 items (if 2D) or 3 (if 3D)\n",
    "    args = [\n",
    "        X_r[y == label_idx, 0], \n",
    "        X_r[y == label_idx, 1],\n",
    "    ]\n",
    "    if not PLOT_2D:\n",
    "        args.append(X_r[y == label_idx, 2])\n",
    "    \n",
    "    # Get a shortened version of the gesture index for the legend\n",
    "    gesture_idx = idx_to_gesture[label_idx].replace('gesture', '')\n",
    "    # Get the short gesture description for the legend\n",
    "    gesture_desc = gesture_info[idx_to_gesture[label_idx]][\"desc\"]\n",
    "    \n",
    "    # Actually plot the points, either in 2 or 3 dimensions\n",
    "    ax.scatter(\n",
    "        *args,\n",
    "        color=colours(label_idx/n_classes),\n",
    "        alpha=0.3,\n",
    "        s=10,\n",
    "        marker=markers[label_idx % 4],\n",
    "        label=f'{gesture_idx} ({gesture_desc})'\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "#\n",
    "#   modified from https://stackoverflow.com/a/4701285/14555505\n",
    "#\n",
    "# Shrink current axis's height by 10% on the bottom so the legend will fit\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.2,\n",
    "                 box.width, box.height * 0.80])\n",
    "# Put a legend below current axis in the newly made space\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Give the plot a title and save it\n",
    "plt.title(f\"PCA with {'two' if PLOT_2D else 'three'} components over {n_classes} gestures\")\n",
    "plt.savefig(f'imgs/{2 if PLOT_2D else 3}_pca_{n_classes}_classes_{n_obs}_obs.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89df56",
   "metadata": {},
   "source": [
    "Define a widget that, given an observation's index, will display the raw sensor measurements. This is\n",
    "useful for identifying and removing outliers or bad observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd37f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx='0')\n",
    "def plot_from_index(idx='0'):\n",
    "    if len(idx) == 0:\n",
    "        return\n",
    "    idx = int(idx)\n",
    "    gesture_idx = idx_to_gesture[y[idx]]\n",
    "    plot_raw_gesture(\n",
    "        X[idx], \n",
    "        f'{gesture_idx}: {gesture_info[gesture_idx][\"description\"]}\\n{paths[idx]}'\n",
    "    )\n",
    "    print(f'{gesture_info[gesture_idx][\"description\"]}')\n",
    "    print('rm ' + '/'.join(paths[idx].split('/')[3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d82edc",
   "metadata": {},
   "source": [
    "## Train TensorFlow neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8abf33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "if USE_W_AND_B:\n",
    "    import wandb\n",
    "    from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"resample_period\": 25,\n",
    "}\n",
    "if USE_W_AND_B:\n",
    "    wandb.init(project=\"ergo\", entity=\"beyarkay\")\n",
    "    wandb.config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128f939",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/csv#multiple_files_2\n",
    "dirs = sorted(list(dir_files.keys()))\n",
    "\n",
    "list_ds = tf.data.Dataset.list_files('../gesture_data/train/*/*.txt')\n",
    "\n",
    "def preprocess_features(numbers):\n",
    "    # Convert the np.array to a pd.DataFrame\n",
    "    df = pd.DataFrame(data=numbers.numpy())\n",
    "    \n",
    "    # Set the index to be column 0 (The column containing the miliseconds \n",
    "    # since the start of the gesture)\n",
    "    df.index = pd.TimedeltaIndex(df[0], unit='ms', name='offset_ms')\n",
    "    \n",
    "    # Delete the milliseconds column (We won't use it for training)\n",
    "    del df[0]\n",
    "    \n",
    "    # If the start and end items don't explicitly exist => add them\n",
    "    start = pd.Timedelta('0 days 00:00:00.000')\n",
    "    end = pd.Timedelta('0 days 00:00:00.975')\n",
    "    if start not in df.index:\n",
    "        df.loc[start] = pd.Series(dtype='float64')\n",
    "    if end not in df.index:\n",
    "        df.loc[end] = pd.Series(dtype='float64')\n",
    "\n",
    "    # Resample the data so we've got values exactly every 25ms\n",
    "    df = df.resample(f\"{config['resample_period']}ms\").mean().ffill()\n",
    "    \n",
    "    # Normalise the data to have zero-mean and unit-variance\n",
    "    df = (df - df.stack().mean()) / df.stack().std()\n",
    "    return np.array(df)\n",
    "    \n",
    "    \n",
    "def preprocess_label(label):\n",
    "#     print(label)\n",
    "    label //=  2\n",
    "    return tf.keras.utils.to_categorical(label-1, num_classes=len(dirs))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def process_path(file_path):\n",
    "    # Get the label of the observation from the file path\n",
    "    label = tf.strings.split(file_path, os.sep)[-2]    \n",
    "    label = tf.strings.regex_replace(label, \"gesture\", \"\")\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    [label,] = tf.py_function(preprocess_label, [label], [tf.float32])\n",
    "    label.set_shape(len(dirs))\n",
    "    \n",
    "    # Read in the actual file\n",
    "    file = tf.io.read_file(file_path)\n",
    "    # Split by newlines to get an array of each line\n",
    "    lines = tf.strings.split(file, \"\\n\")\n",
    "    # Split each line by ',' to get an array of arrays of strings\n",
    "    items = tf.strings.split(lines, ',')\n",
    "    # Convert the array of array of strings to a 2D array of float32\n",
    "    nums = tf.strings.to_number(items, out_type=tf.dtypes.float32)\n",
    "    # preprocess the raw sensor values via pandas\n",
    "    [nums,] = tf.py_function(preprocess_features, [nums], [tf.float32])\n",
    "    nums.set_shape((40, 30))\n",
    "    \n",
    "    return nums, label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path)\n",
    "labeled_ds = labeled_ds.shuffle(buffer_size=1000)\n",
    "labeled_ds = labeled_ds.batch(config['batch_size'])\n",
    "\n",
    "for sensor_data, label in labeled_ds.take(1):\n",
    "    print(list(zip(sensor_data.numpy(), label.numpy()))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9aa265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(40, 30), name='input'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(len(dirs), name='output'),\n",
    "], name='Ergo')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "metrics = [\n",
    "#     tf.keras.metrics.Accuracy(),\n",
    "#     tf.keras.metrics.Precision(),\n",
    "#     tf.keras.metrics.Recall(),\n",
    "#     tf.keras.metrics.TrueNegatives(),\n",
    "#     tf.keras.metrics.TruePositives(),\n",
    "#     tf.keras.metrics.FalseNegatives(),\n",
    "#     tf.keras.metrics.FalsePositives(),\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.CategoricalCrossentropy(),\n",
    "#     tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # Use `categorical_crossentropy` because the labels are one-hot-encoded\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "callbacks = [] if not USE_W_AND_B else [WandbCallback()]\n",
    "\n",
    "history = model.fit(\n",
    "    labeled_ds, \n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# # You can also evaluate or predict on a dataset.\n",
    "# print(\"Evaluate\")\n",
    "# result = model.evaluate(labeled_ds)\n",
    "# dict(zip(model.metrics_names, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(labeled_ds)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1630e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for d, l in labeled_ds.take(5):\n",
    "    for item in l:\n",
    "        print(np.argmax(predictions[i]), np.argmax(item))\n",
    "        i += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
