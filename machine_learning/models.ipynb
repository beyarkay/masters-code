{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b94d03",
   "metadata": {},
   "source": [
    "# Create models from *Ergo* data\n",
    "This notebook contains the code for models used to predict the *Ergo* data. See the report [here](https://git.cs.sun.ac.za/Computer-Science/rw771/2022/26723077-TG7-doc) or the source code behind the data [here](https://git.cs.sun.ac.za/Computer-Science/rw771/2022/26723077-TG7-src).\n",
    "\n",
    "### Items to explore\n",
    "\n",
    "- What is the optimal number of PCs for model performance?\n",
    "- Which is the optimal dimensionality reduction method: tSNE, Autoencoder, PCA?\n",
    "- Compare different model types: Random Forest, SVM, NN, Nïeve Bayes, Quadratic Discriminent Analysis\n",
    "- Restructure this to have a better order\n",
    "    - imports, get data, PCA on data, train model, visualise model's conf matrix, visualise model's mislabeled observations\n",
    "- Note: The model might struggle with how gesture classification is independant of when the gesture was performed. How to modify training data to account for this? and how to verify that models aren't fixating on *when* a gesture happens, as opposed to *which* gestures happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d042fe",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from common_utils import *\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "from time import time\n",
    "from matplotlib import cm\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Distributions\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324eff7d",
   "metadata": {},
   "source": [
    "# Read in the data to an `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, paths = read_to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58c5c2",
   "metadata": {},
   "source": [
    "# Train-test split and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebe90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, paths_train, paths_test, scaler = train_test_split_scale(X, y, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e75983",
   "metadata": {},
   "source": [
    "# Train models without dimensionality reduction\n",
    "\n",
    "\n",
    "Training KNeighborsClassifier(n_neighbors=21)\n",
    "- Time taken: 153.927s\n",
    "- Best performing model\n",
    "`KNeighborsClassifier(algorithm='ball_tree', n_neighbors=21)`\n",
    "- Score: train: 0.9679, test: 0.9774\n",
    "\n",
    "\n",
    "Training MLPClassifier(max_iter=1000)\n",
    "- Time taken: 81.279s\n",
    "- Best performing model\n",
    "```MLPClassifier(activation='tanh', alpha=0.0013330009770265291, hidden_layer_sizes=400, max_iter=1000)```\n",
    "- Score: train: 0.9907, test: 0.9947\n",
    "\n",
    "Training MLPClassifier(max_iter=1000)\n",
    "- Time taken: 27.189s\n",
    "- Best performing model\n",
    "`MLPClassifier(alpha=0.0016877545702567223, hidden_layer_sizes=100, max_iter=1000)`\n",
    "- Score: train: 0.9903, test: 0.9950\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558196ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models = []\n",
    "\n",
    "models.append(\n",
    "    (MLPClassifier(max_iter=1000), {\n",
    "        'hidden_layer_sizes': [(100), (200), (400), (100, 50), (200, 100), (400, 200), \n",
    "                               (100, 50, 25), (200, 100, 50), (400, 200, 100)],\n",
    "        'activation' : ['logistic', 'tanh', 'relu'],\n",
    "        'solver' : ['lbfgs', 'adam'],\n",
    "        'alpha': loguniform(1e-6, 1e-2),\n",
    "    })\n",
    ")\n",
    "\n",
    "clfs = []\n",
    "for model, param_grid in models:\n",
    "    print(f'\\nTraining {model}')\n",
    "    start = time()\n",
    "    clf = RandomizedSearchCV(\n",
    "        model, param_grid, n_iter=10\n",
    "    )\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(f'- Time taken: {time() - start:.3f}s\\n- Best performing model\\n`{clf.best_estimator_}`\\n- Score: train: {clf.best_score_:.4f}, test: {clf.score(X_test, y_test):.4f}')\n",
    "    clfs.append(clf.best_estimator_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb6dd1",
   "metadata": {},
   "source": [
    "### Confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe32e4",
   "metadata": {},
   "source": [
    "Get a `pd.DataFrame` with counts of the most often mislabeled gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361541ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = pd.DataFrame(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "np.fill_diagonal(conf_mat.values, 0)\n",
    "\n",
    "conf_mat.index = gesture_to_idx.keys()\n",
    "conf_mat.columns = gesture_to_idx.keys()\n",
    "# conf_mat\n",
    "mislabeled = conf_mat.stack()\n",
    "mislabeled = mislabeled[mislabeled > 0].reset_index()\n",
    "mislabeled.columns = ['true', 'predicted', 'count']\n",
    "mislabeled = mislabeled.sort_values(\n",
    "    ['count', 'true', 'predicted'], \n",
    "    ascending=[False, True, True]\n",
    ")\n",
    "mislabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs[0]\n",
    "y_pred = clf.predict(X_test)\n",
    "clf_name = f'{str(type(clf))}'.split('.')[-1][:-2]\n",
    "\n",
    "print(f\"Test set results for {clf_name}\")\n",
    "print(classification_report(y_test, y_pred, target_names=gesture_to_idx.keys()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    clf, \n",
    "    X_test,\n",
    "    y_test, \n",
    "    display_labels=gesture_to_idx.keys(), \n",
    "    xticks_rotation=\"vertical\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.grid(False)\n",
    "plt.title(f'Confusion Matrix of \\n{clf}')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'imgs/conf_mat_{clf}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567c350",
   "metadata": {},
   "source": [
    "### Visualise important features from full-dimensionality classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = clfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 4\n",
    "fig, axes = plt.subplots(n_classes//num_cols+1, num_cols)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for gesture_idx, ax in enumerate(axes.ravel()):\n",
    "    if gesture_idx >= n_classes:\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.grid(False)\n",
    "        continue\n",
    "        \n",
    "    multiplied = mlp.coefs_[0]\n",
    "    for layer in range(1, len(mlp.coefs_)):\n",
    "        multiplied = multiplied @ mlp.coefs_[layer]\n",
    "\n",
    "    importances = multiplied[:, gesture_idx].reshape(n_timesteps, n_sensors)\n",
    "    \n",
    "    gesture_label = idx_to_gesture[gesture_idx]\n",
    "    gesture_description = gesture_info[gesture_label]['description']\n",
    "    plot_raw_gesture(\n",
    "        importances.reshape(n_timesteps, n_sensors),\n",
    "        f'{gesture_label}\\n{gesture_description}',\n",
    "        ax=ax,\n",
    "        show_cbar=False,\n",
    "        show_xticks=False,\n",
    "        show_yticks=False,\n",
    "        delim_lw=1\n",
    "    )\n",
    "\n",
    "plt.suptitle('Importances per gesture for the trained MLP')\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs/importances.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb4b39",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6165e41",
   "metadata": {},
   "source": [
    "# Compare self-classified observations with manually classified observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad2dc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_files_sc = get_dir_files('../gesture_data/self-classified')\n",
    "gesture = list(dir_files_sc.keys())[0]\n",
    "file = dir_files_sc[gesture][0]\n",
    "path = f'../gesture_data/self-classified/{gesture}/{file}'\n",
    "\n",
    "df = read_to_df(path)\n",
    "obs = df.to_numpy()\n",
    "obs_wrapped = np.zeros((1, n_sensors * n_timesteps))\n",
    "obs_wrapped[0] = obs.flatten()\n",
    "txd = scaler.transform(obs_wrapped)\n",
    "plot_raw_gesture(txd[0], f'{gesture}\\n{path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec77b149",
   "metadata": {},
   "source": [
    "TODO: create a common method of scaling with a saved scaler before plotting the observation\n",
    "TODO: create a method of visualising how data flows through the MLP so you can troubleshoot misclassified real-time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743938b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(obs_wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1669051",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df.to_numpy()\n",
    "obs_wrapped = np.zeros((1, n_sensors * n_timesteps))\n",
    "obs_wrapped[0] = obs.flatten()\n",
    "prediction = clf.predict_proba(scaler.transform(obs_wrapped))\n",
    "predictions = []\n",
    "for i, prob in enumerate(prediction[0]):\n",
    "    predictions.append((i, prob))\n",
    "predictions.sort(key=lambda ip: -ip[1])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da7ca0",
   "metadata": {},
   "source": [
    "# Reduce dimensionality via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71298177",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_components = 10\n",
    "\n",
    "print(f'Fitting PCA with {n_components} components on {X_train.shape[0]} observations')\n",
    "pca = PCA(\n",
    "    n_components=n_components,\n",
    "    svd_solver=\"randomized\", \n",
    "    whiten=True\n",
    ").fit(X_train)\n",
    "\n",
    "print(f\"PCA explained {100*sum(pca.explained_variance_ratio_):.2f}% of the variance with {n_components} PCs\")\n",
    "\n",
    "# PCA-transform the input test and train data\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea526e0c",
   "metadata": {},
   "source": [
    "## Train multiple models on the data\n",
    "Each model is defined in its own cell, and appended to the list `models`. \n",
    "After all the definitions, every model in the list is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a28159",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b07af5",
   "metadata": {},
   "source": [
    "---\n",
    "Support Vector Machine\n",
    "- Time taken: 7.731s\n",
    "- Best performing model\n",
    "`SVC(C=35891.14381335473, class_weight='balanced', gamma=0.057667711437645666)`\n",
    "- Score: train: 0.9896, test: 0.9901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65004ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (SVC(kernel=\"rbf\", class_weight=\"balanced\"), {\n",
    "        \"C\": loguniform(1e3, 1e5),\n",
    "        \"gamma\": loguniform(1e-4, 1e-1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479958a6",
   "metadata": {},
   "source": [
    "---\n",
    "Linear Support Vector Machine\n",
    "\n",
    "- Time taken: 367.828s\n",
    "- Best performing model: SVC(C=1284.851851420933, class_weight='balanced', kernel='linear')\n",
    "- Score: train: 0.9780, test: 0.9784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c48000",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (SVC(kernel=\"linear\", class_weight=\"balanced\"), {\n",
    "        \"C\": loguniform(1e3, 1e5),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e7aa2",
   "metadata": {},
   "source": [
    "---\n",
    "K-Nearest Neighbours\n",
    "- Time taken: 0.820s\n",
    "- Best performing model\n",
    "`KNeighborsClassifier(algorithm='ball_tree', n_neighbors=21)`\n",
    "- Score: train: 0.9849, test: 0.9851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (KNeighborsClassifier(n_neighbors=n_classes), {\n",
    "        \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef3419",
   "metadata": {},
   "source": [
    "---\n",
    "Ada Boost\n",
    "- Time taken: 268.507s\n",
    "- Best performing model: AdaBoostClassifier(learning_rate=0.20109497487437183, n_estimators=792)\n",
    "- Score: train: 0.7856, test: 0.7867\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (AdaBoostClassifier(), {\n",
    "        'n_estimators': range(10, 1000),\n",
    "        'learning_rate': np.linspace(1e-4, 2, num=200),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a1301",
   "metadata": {},
   "source": [
    "---\n",
    "Decision Tree\n",
    "- Time taken: 1.136s\n",
    "- Best performing model\n",
    "`DecisionTreeClassifier(class_weight='balanced', max_depth=186,\n",
    "                       min_samples_split=0.26530612244897955)`\n",
    "- Score: train: 0.4396, test: 0.4712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (DecisionTreeClassifier(class_weight=\"balanced\"), {\n",
    "        'max_depth': range(1, 200),\n",
    "        'min_samples_split': np.linspace(0, 1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a119016",
   "metadata": {},
   "source": [
    "---\n",
    "Random Forest\n",
    "- Time taken: 31.299s\n",
    "- Best performing model\n",
    "\n",
    "`RandomForestClassifier(max_depth=187, max_features=0.836734693877551,\n",
    "                       min_samples_split=0.16326530612244897, n_estimators=176)`\n",
    "- Score: train: 0.6110, test: 0.6095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98baf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (RandomForestClassifier(), {\n",
    "        'n_estimators': range(10, 500), \n",
    "        'max_depth': range(1, 200), \n",
    "        'max_features': np.linspace(0, 1),\n",
    "        'min_samples_split': np.linspace(0, 1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaff8d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Multi-layer Perceptron\n",
    "- Time taken: 484.457s\n",
    "- Best performing model\n",
    "\n",
    "```MLPClassifier(activation='tanh', alpha=2.8761865563186644e-05,\n",
    "              hidden_layer_sizes=(400, 200), max_iter=1000)```\n",
    "- Score: train: 0.9914, test: 0.9919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(\n",
    "    (MLPClassifier(max_iter=1000), {\n",
    "        'hidden_layer_sizes': [(100), (200), (400), (100, 50), (200, 100), (400, 200), \n",
    "                               (100, 50, 25), (200, 100, 50), (400, 200, 100)],\n",
    "        'activation' : ['logistic', 'tanh', 'relu'],\n",
    "        'solver' : ['lbfgs', 'adam'],\n",
    "        'alpha': loguniform(1e-6, 1e-2),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9fbe6",
   "metadata": {},
   "source": [
    "---\n",
    "Gaussian Naïve Bayes\n",
    "- Time taken: 0.031s\n",
    "- Best performing model: GaussianNB()\n",
    "- Score: train: 0.9255, test: 0.9264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((GaussianNB(), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5717c",
   "metadata": {},
   "source": [
    "---\n",
    "Quadratic Discriminant Analysis\n",
    "- Time taken: 0.040s\n",
    "- Best performing model: QuadraticDiscriminantAnalysis()\n",
    "- Score: train: 0.9854, test: 0.9837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c54a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((QuadraticDiscriminantAnalysis(), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06570c",
   "metadata": {},
   "source": [
    "---\n",
    "## Fit and evaluate all models in `models`\n",
    "Now actually evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd348a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for model, param_grid in models:\n",
    "    print(f'\\nTraining {model}')\n",
    "    start = time()\n",
    "    clf = RandomizedSearchCV(\n",
    "        model, param_grid, n_iter=10\n",
    "    )\n",
    "    clf = clf.fit(X_train_pca, y_train)\n",
    "    print(f'- Time taken: {time() - start:.3f}s\\n- Best performing model\\n`{clf.best_estimator_}`\\n- Score: train: {clf.best_score_:.4f}, test: {clf.score(X_test_pca, y_test):.4f}')\n",
    "    clfs.append(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bf626",
   "metadata": {},
   "source": [
    "Alternatively just load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda92c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"saved_models/MLPClassifier(activation='tanh',alpha=5.532519953153552e-05,hidden_layer_sizes=(400,200),max_iter=1000,solver='lbfgs').pickle\"\n",
    "clfs = [load_model(model_path)]\n",
    "# Read in the scaler\n",
    "scaler_path = f\"saved_models/StandardScaler().pickle\"\n",
    "scaler = load_model(scaler_path)\n",
    "# Read in the index-to-gesture mapping\n",
    "with open('saved_models/idx_to_gesture.pickle', 'rb') as f:\n",
    "    idx_to_gesture = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092345f",
   "metadata": {},
   "source": [
    "### Get detailed analyses of the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75400dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clf in clfs:\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    clf_name = f'{str(type(clf))}'.split('.')[-1][:-2]\n",
    "\n",
    "    print(f\"Test set results for {clf_name}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=gesture_to_idx.keys()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    ConfusionMatrixDisplay.from_estimator(\n",
    "        clf, \n",
    "        X_test_pca, \n",
    "        y_test, \n",
    "        display_labels=gesture_to_idx.keys(), \n",
    "        xticks_rotation=\"vertical\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.title(f'Confusion Matrix of \\n{clf}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'imgs/conf_mat_{clf}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedbf4a",
   "metadata": {},
   "source": [
    "## Plot the incorrect observations\n",
    "TODO: this should actually show the model activations for the actual and predicted gestures, and not just some random (maybe unrepresentative) example observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830014b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs[0]\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "X_test_incorrect = X_test[y_pred != y_test]\n",
    "y_pred_incorrect = y_pred[y_pred != y_test]\n",
    "y_test_incorrect = y_test[y_pred != y_test]\n",
    "paths_test_incorrect = paths_test[y_pred != y_test]\n",
    "\n",
    "\n",
    "@interact(idx=(0, y_pred_incorrect.shape[0]-1, 1))\n",
    "def plot_incorrect(idx=0):\n",
    "    predicted = idx_to_gesture[y_pred_incorrect[idx]]\n",
    "    pred_desc = gesture_info[predicted]['description']\n",
    "    \n",
    "    actual = idx_to_gesture[y_test_incorrect[idx]]\n",
    "    actu_desc = gesture_info[actual]['description']\n",
    "    \n",
    "    path = '/'.join(paths_test_incorrect[idx].split('/')[3:])\n",
    "    \n",
    "    # Create 3 vertical axs:\n",
    "    # - top is an example of the actual gesture, \n",
    "    # - middle is the incorrectly predicted gesture,\n",
    "    # - bottom is an example of the predicted gesture\n",
    "    fig, axs = plt.subplots(3)\n",
    "    \n",
    "    # First plot an example of the actual gesture\n",
    "    actual_idx = next(i for i, yi in enumerate(y_train) if yi == y_pred_incorrect[idx])\n",
    "    gesture_label = idx_to_gesture[y_train[actual_idx]]\n",
    "    gesture_description = gesture_info[idx_to_gesture[y_train[actual_idx]]][\"description\"]\n",
    "    plot_raw_gesture(\n",
    "        X_train[actual_idx], \n",
    "        f'Example of {gesture_label} ({gesture_description})',\n",
    "        ax=axs[0],\n",
    "        show_xticks=False,\n",
    "    )\n",
    "\n",
    "    # Second plot the misclassified gesture\n",
    "    plot_raw_gesture(\n",
    "        X_test_incorrect[idx], \n",
    "        f'Predicted: {predicted} ({pred_desc})\\nActual: {actual} ({actu_desc}\\n{paths_test_incorrect[idx]})',\n",
    "        ax=axs[1],\n",
    "        show_xticks=False,\n",
    "    )\n",
    "    \n",
    "    # Last plot an example of the predicted gesture\n",
    "    predicted_idx = next(i for i, yi in enumerate(y_train) if yi == y_test_incorrect[idx])\n",
    "    gesture_label = idx_to_gesture[y_train[predicted_idx]]\n",
    "    gesture_description = gesture_info[idx_to_gesture[y_train[predicted_idx]]][\"description\"]\n",
    "    plot_raw_gesture(\n",
    "        X_train[predicted_idx], \n",
    "        f'Example of {gesture_label} ({gesture_description})',\n",
    "        ax=axs[2],\n",
    "        show_xticks=False,\n",
    "    )\n",
    "    \n",
    "    # Finally, tell matplotlib to recompute the layout\n",
    "    plt.tight_layout()\n",
    "    print(paths_test_incorrect[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97441e61",
   "metadata": {},
   "source": [
    "## Plot 2-component PCA to assess separation\n",
    "TODO: indicate for a given model which observations were correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384e29c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PCA can be either 2D or 3D\n",
    "PLOT_2D = True\n",
    "\n",
    "# Transform the data via PCA. Either 2 or 3 components are used\n",
    "pca = PCA(n_components=(2 if PLOT_2D else 3))\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Each observation gets a different colour on the scatter plot, and\n",
    "# similar colours get different markers to better differentiate them\n",
    "colours = cm.get_cmap('turbo', n_classes)\n",
    "markers = ['.', 'x', '*', 'd']\n",
    "\n",
    "\n",
    "if PLOT_2D:\n",
    "    # Use 2D subplots\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "else:\n",
    "    # Use 3D subplots\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Optionally also plot the observation indices along with the points.\n",
    "# This helps when removing outliers, but increases the amount of clutter\n",
    "if PLOT_2D:\n",
    "    for i, yi in enumerate(y):\n",
    "        ax.annotate(\n",
    "            i, \n",
    "            (X_r[i, 0], X_r[i, 1]),\n",
    "            color=colours(yi/n_classes),\n",
    "            size=5,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "# Iterate over each label/gesture\n",
    "for i, label_idx in enumerate(idx_to_gesture.keys()):\n",
    "    # Args either has 2 items (if 2D) or 3 (if 3D)\n",
    "    args = [\n",
    "        X_r[y == label_idx, 0], \n",
    "        X_r[y == label_idx, 1],\n",
    "    ]\n",
    "    if not PLOT_2D:\n",
    "        args.append(X_r[y == label_idx, 2])\n",
    "    \n",
    "    # Get a shortened version of the gesture index for the legend\n",
    "    gesture_idx = idx_to_gesture[label_idx].replace('gesture', '')\n",
    "    # Get the short gesture description for the legend\n",
    "    gesture_desc = gesture_info[idx_to_gesture[label_idx]][\"desc\"]\n",
    "    \n",
    "    # Actually plot the points, either in 2 or 3 dimensions\n",
    "    ax.scatter(\n",
    "        *args,\n",
    "        color=colours(label_idx/n_classes),\n",
    "        alpha=0.3,\n",
    "        s=10,\n",
    "        marker=markers[label_idx % 4],\n",
    "        label=f'{gesture_idx} ({gesture_desc})'\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "#\n",
    "#   modified from https://stackoverflow.com/a/4701285/14555505\n",
    "#\n",
    "# Shrink current axis's height by 10% on the bottom so the legend will fit\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.2,\n",
    "                 box.width, box.height * 0.80])\n",
    "# Put a legend below current axis in the newly made space\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Give the plot a title and save it\n",
    "plt.title(f\"PCA with {'two' if PLOT_2D else 'three'} components over {n_classes} gestures\")\n",
    "filename = f'imgs/{2 if PLOT_2D else 3}_pca_{n_classes}_classes_{n_obs}_obs.pdf'\n",
    "plt.savefig(filename)\n",
    "print(f'Saved as {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89df56",
   "metadata": {},
   "source": [
    "Define a widget that, given an observation's index, will display the raw sensor measurements. This is\n",
    "useful for identifying and removing outliers or bad observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd37f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx='0')\n",
    "def plot_from_index(idx='0'):\n",
    "    if len(idx) == 0:\n",
    "        return\n",
    "    idx = int(idx)\n",
    "    gesture_idx = idx_to_gesture[y[idx]]\n",
    "    plot_raw_gesture(\n",
    "        X[idx],\n",
    "        f'{gesture_idx}: {gesture_info[gesture_idx][\"description\"]}\\n{paths[idx]}'\n",
    "    )\n",
    "    print(f'{gesture_info[gesture_idx][\"description\"]}')\n",
    "    print('rm ' + '/'.join(paths[idx].split('/')[3:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
