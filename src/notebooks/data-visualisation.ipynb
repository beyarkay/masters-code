{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69b0d03",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff0b1d",
   "metadata": {},
   "source": [
    "## Notes and Quick ideas\n",
    "\n",
    "- Now do plots with the repetitions baked in. Show which hyperparameter combinations have the least variance\n",
    "\n",
    "- Figure out what went wrong in the labelling\n",
    "    - Potentially relabel validation/training/testing(!)\n",
    "- Redo difference graph after the relabelling\n",
    "- Give a description of the dataset, what's in it\n",
    "- Load dataset onto zenodo\n",
    "- Create a bridge from background chapter to how the models are used\n",
    "\n",
    "### Meeting notes\n",
    "- [x] Check (before writing results chapter) that the delay isn't too big\n",
    "- [x] Make *very* sure that the model can be run in real time, with the gloves\n",
    "- [x] Conf matrix should be %age of the class\n",
    "- [x] Explain Conf matrix structure (diagonals/orientations/fingers) in thesis\n",
    "- [x] Include 'dummy' models which perfectly predict only finger/orientation/hand, etc\n",
    "     - put it in a separate section in methodology\n",
    "- [x] Look into plotting error on FFNN\n",
    "- Discuss precision/recall for 51 gesture FFNN/HMM/CuSUM  -> Why would this happen\n",
    "- Error types: (wrong timestep) x (wrong gesture)\n",
    "    - It seems like the FFNN is not getting the timestep wrong, it's just wrong\n",
    "- Explore plots of hpars affecting regularization and validation performance\n",
    "- Make note that the HMM is only predicting 200 g255 gestures\n",
    "\n",
    "### Changes made\n",
    "\n",
    "- F1 score was being set to NaN, resulting in the average being too high (and F1 ~= 1.0)\n",
    "- Grid search was unable to explore the search space fully, so [Optuna](https://optuna.readthedocs.io/en/stable/) was used for the search.\n",
    "    - Specifically, the [Tree-structured Parzen Estimator](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler) performs the search. Bergstra, James et al. “Algorithms for Hyper-Parameter Optimization.” NIPS (2011). [Explanatory Blog](http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#tree-structured-parzen-estimators-tpe)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139088",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a2aca",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change directory to keep paths consistent\n",
    "%cd /Users/brk/projects/masters/SU/ergo/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22165a6e",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d078368",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import vis\n",
    "import common\n",
    "import read\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import tqdm\n",
    "import logging as l\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f\n",
    "\n",
    "mpl.rc('font', family='serif', serif='cmr10')\n",
    "mpl.rc('axes.formatter', use_mathtext=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbd3fa",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1411",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "def prettify_col_name(x):\n",
    "    return x.split('.')[-1].replace('_', ' ').title()\n",
    "\n",
    "def calculate_prediction_ellipse(x, y, alpha=0.95):\n",
    "    \"\"\"Given some x and y data, calculate the (1-alpha) confidence ellipse.\"\"\"\n",
    "    data = np.column_stack((x, y)) # Combine x and y into a single data array\n",
    "    num_dimensions = data.shape[1]\n",
    "    num_data_points = data.shape[0]\n",
    "    # Estimate the sample covariance matrix\n",
    "    sample_covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Calculate the sample mean for each dimension\n",
    "    sample_mean = np.mean(data, axis=0)\n",
    "    # Generate angles for the ellipse\n",
    "    theta = np.linspace(0, 2*np.pi, num=100)\n",
    "    # Calculate the radius of the ellipse. `f.ppf` is the inverse of the CDF\n",
    "    radius = np.sqrt(\n",
    "        num_dimensions * (num_data_points - 1) / (num_data_points - num_dimensions) *\n",
    "        (1 + 1/num_data_points) * f.ppf(1 - alpha, num_dimensions, num_data_points - num_dimensions)\n",
    "    )\n",
    "#     print(sample_covariance_matrix)\n",
    "    # Compute the Cholesky decomposition of the covariance matrix\n",
    "    chol_cov_matrix = np.linalg.cholesky(sample_covariance_matrix)\n",
    "    # Generate ellipse offset based on Cholesky decomposition\n",
    "    ellipse_offset = np.outer(np.cos(theta), chol_cov_matrix[0, :]) + np.outer(np.sin(theta), chol_cov_matrix[1, :])\n",
    "    # Calculate the points of the prediction interval ellipse\n",
    "    prediction_ellipse_points = sample_mean + radius * ellipse_offset\n",
    "    return prediction_ellipse_points\n",
    "\n",
    "def get_npz_data_from_model(model_dir):\n",
    "    \"\"\"Given a directory of a model, return it's y_pred and y_true.\"\"\"\n",
    "    data = np.load(f'{model_dir}/y_val_true_y_val_pred.npz')\n",
    "    y_true = data['y_true']\n",
    "    y_pred = data['y_pred']\n",
    "    return y_true, y_pred\n",
    "\n",
    "def show_conf_mat_from_model(model_dir, ax=None):\n",
    "    \"\"\"Given a directory of a model, plot its confidence matrix\"\"\"\n",
    "    y_true, y_pred = get_npz_data_from_model(model_dir)\n",
    "    cm_val = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    p = vis.conf_mat(cm_val / cm_val.sum(axis=0), ax=ax)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46788",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab12f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data from hpar optimisation\n",
    "paths = sorted(glob.glob('../saved_models/results_*_optuna.jsonl'))\n",
    "print(f'Reading data from\\n', \"\\n\".join(paths))\n",
    "dfs = map(\n",
    "    lambda path: pd.read_json(path, lines=True),\n",
    "    paths\n",
    ")\n",
    "# Concat the dataframes together, and then do a \n",
    "# copy to avoid a dataframe fragmentation warning\n",
    "# Reset the index to avoid a seaborn error https://github.com/mwaskom/seaborn/issues/3291\n",
    "df = pd.concat(dfs).reset_index(drop=True).copy()\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].fillna('51')\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].astype(int).astype(str)\n",
    "\n",
    "# 50-class HFFNNs don't make sense, remove them\n",
    "df = df[~(\n",
    "    (df['model_type'] == 'HFFNN')\n",
    "    & (df['preprocessing.num_gesture_classes'] == '50')\n",
    ")]\n",
    "\n",
    "df.groupby(['model_type', 'preprocessing.num_gesture_classes']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3baaa",
   "metadata": {},
   "source": [
    "## Constants to keep colours consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc79b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colours = {\n",
    "    'FFNN': 'tab:blue',\n",
    "    'HFFNN': 'tab:orange',\n",
    "    'CuSUM': 'tab:green',\n",
    "    'HMM': 'tab:red',\n",
    "    'SVM': 'tab:purple',\n",
    "}\n",
    "palette = 'Spectral'\n",
    "other_colours = [\n",
    "    'tab:brown',\n",
    "    'tab:pink',\n",
    "    'tab:grey',\n",
    "    'tab:olive',\n",
    "    'tab:cyan',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1f85",
   "metadata": {},
   "source": [
    "## Calculate some auxillary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18c065",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data a little bit, and get a list of dependant variables\n",
    "# Preprocess the df a bit to get some nice-to-use columns\n",
    "\n",
    "prefixes = (\n",
    "    'ffnn.nodes_per_layer',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer',\n",
    ")\n",
    "for i in (1, 2, 3):\n",
    "    for prefix in prefixes:\n",
    "        print(f'{prefix}.{i}')\n",
    "        df[f'{prefix}.{i}'] = df[prefix].apply(\n",
    "            lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else None\n",
    "        )\n",
    "\n",
    "# Calculate ratios\n",
    "avgs = ('macro avg', 'weighted avg')\n",
    "metrics = ('f1-score', 'precision', 'recall')\n",
    "\n",
    "for avg in avgs:\n",
    "    for metric in metrics:\n",
    "        df[f'ratio.{avg}.{metric}'] = df[f'trn.{avg}.{metric}'] / df[f'val.{avg}.{metric}']\n",
    "        df[f'ratio.{avg}.{metric}'] = np.where(\n",
    "            np.isfinite(df[f'ratio.{avg}.{metric}']),\n",
    "            df[f'ratio.{avg}.{metric}'],\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "# Print out a list of dependant variables\n",
    "dep_vars = sorted([\n",
    "    c for c in df.columns \n",
    "    if 'val' not in c and 'trn' not in c and 'ratio' not in c and c not in (\n",
    "        'saved_at', 'fit_time', 'preprocessing.gesture_allowlist', \n",
    ")], key=lambda c: str(c))\n",
    "print(f\"Dependant variables: {dep_vars}\")\n",
    "# print(\"\\nVariables which change:\")\n",
    "# max_len = max(map(lambda x: len(x), dep_vars))\n",
    "# Print out all dependant variables that change\n",
    "# for var in dep_vars:\n",
    "#     uniq = df[var].apply(lambda x: str(x) if isinstance(x, list) else x).unique()\n",
    "#     if len(uniq) > 1:\n",
    "#         print(f\"{var: <{max_len}} {uniq}\")\n",
    "        \n",
    "df['ffnn.dropout_rate'] = np.round(df['ffnn.dropout_rate'], 6)\n",
    "\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['trn.pred_time_per_obs'] = df['trn.pred_time'] / df['trn.num_observations']\n",
    "df['fit_time_per_obs'] = df['fit_time'] / df['trn.num_observations']\n",
    "\n",
    "\n",
    "# Add some log10 columns\n",
    "log10_cols = [\n",
    "    'val.loss',\n",
    "    'trn.loss',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]\n",
    "df[[f'{c}.log10' for c in log10_cols]] = np.log10(df[log10_cols])\n",
    "\n",
    "# There are a *lot* of columns. Here's a more-useful subset\n",
    "subset_cols = [\n",
    "    c for c in df.columns\n",
    "    if (not re.search(r'((trn|val)\\.\\d+\\.)|weighted avg', c)) and \n",
    "        (c not in [\n",
    "            'hmm', 'lstm', 'ffnn', 'nn', 'hffnn', 'cusum', 'svm',\n",
    "            'preprocessing.n_timesteps',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5643dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "ngestures = ('51', '50', '5')\n",
    "xmin = None\n",
    "xmax = None\n",
    "for ax, ngesture in zip(axs, ngestures):\n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == ngesture],\n",
    "        x='saved_at',\n",
    "        y='preprocessing.seed',\n",
    "        hue='model_type',\n",
    "        s=10,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "    #     alpha=0.1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f'{ngesture} gestures')\n",
    "#     if xmin is None: xmin = ax.get_xlim()[0]\n",
    "#     if xmax is None: xmax = ax.get_xlim()[1]\n",
    "#     xmin = min(xmin, ax.get_xlim()[0])\n",
    "#     xmax = min(xmax, ax.get_xlim()[1])\n",
    "# for ax in axs:\n",
    "#     ax.set_xlim((xmin, xmax))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[\n",
    "    (df['model_type'] != 'HFFNN')\n",
    "    | (df['saved_at'] > pd.to_datetime('2023-10-01T11:00:00'))\n",
    "]\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eeb4a",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1a042",
   "metadata": {},
   "source": [
    "## Bar plot of number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "counts = pd.Series(y_trn).value_counts()\n",
    "axs[0].bar(counts.index, counts)\n",
    "\n",
    "\n",
    "counts = pd.Series(y_trn[y_trn != 50]).value_counts()\n",
    "axs[1].bar(counts.index, counts)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Count of classes in the training dataset\\n',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Count of classes in the training dataset\\n(excluding class 50)',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_class_imbalance.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c94d8c",
   "metadata": {},
   "source": [
    "## Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4427f33",
   "metadata": {},
   "source": [
    "### 51 classes, Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.1, 1, 10), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_xlim((-0.1, 1.1))\n",
    "axs[0].set_ylim((-0.1, 1.1))\n",
    "axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0].set_title(f'Precision vs Recall for models trained on 51 classes\\n(contours denote $F_1$)')\n",
    "axs[0].set_xlabel(f'Precision')\n",
    "axs[0].set_ylabel(f'Recall')\n",
    "axs[0].legend().set_title(\"Model \")\n",
    "\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='model_type',\n",
    "    s=2,\n",
    "    alpha=0.5,\n",
    "    order=list(model_colours.keys()),\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "axs[1].set_title(f'$F_1$-score for models trained on 51 classes')\n",
    "axs[1].set_xlabel(f'Model Type')\n",
    "axs[1].set_ylabel(f'$F_1$-score')\n",
    "axs[1].set_ylim((-0.1, 1.1))\n",
    "axs[1].grid(axis='y')\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_51_classes.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "data = df.loc[\n",
    "    df['preprocessing.num_gesture_classes'] == '51',\n",
    "    ['model_type', 'val.macro avg.recall', 'val.macro avg.precision']\n",
    "].melt(\n",
    "    id_vars=['model_type'], \n",
    "    var_name='metric', \n",
    "    value_name='value'\n",
    ")\n",
    "data['metric'] = data['metric'].replace({\n",
    "    'val.macro avg.recall': 'Recall',\n",
    "    'val.macro avg.precision': 'Precision',\n",
    "})\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x=\"model_type\", \n",
    "    y=\"value\", \n",
    "    hue=\"metric\",\n",
    "    order=list(model_colours.keys()),\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    alpha=0.75,\n",
    "    size=2,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "\n",
    "ax.set_title(f'Precision and recall for all model types')\n",
    "ax.set_xlabel(f'Model Type')\n",
    "ax.set_ylabel(f'Metric Value')\n",
    "ax.legend().set_title(\"Metric\")\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "ax.set_yticklabels(np.round(np.arange(0, 1.1, .1), 1))\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_stripplot.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1b84",
   "metadata": {},
   "source": [
    "### Precision vs Recall for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760213ee",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for ax, n_classes in zip(axs, n_gesture_classes):\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == n_classes],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        hue='model_type',\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlim((-0.1, 1.1))\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{n_classes} gesture classes')\n",
    "    ax.legend().set_title('Model Type')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77f603",
   "metadata": {},
   "source": [
    "## Best model by highest lower 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109bfea",
   "metadata": {
    "code_folding": [
     14
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight'],\n",
    "}\n",
    "\n",
    "def tenth_conf_interval(series):\n",
    "    mean = np.mean(series)\n",
    "    sem = stats.sem(series)\n",
    "    if sem == 0:\n",
    "        return mean\n",
    "    confidence_interval = stats.t.interval(\n",
    "        0.90, \n",
    "        len(series) - 1, \n",
    "        loc=mean, \n",
    "        scale=sem\n",
    "    )\n",
    "#     print(mean, sem, confidence_interval)\n",
    "    return confidence_interval[0]\n",
    "\n",
    "\n",
    "all_hpars = ['model_type'] + [\n",
    "    item \n",
    "    for sublist in list(type_to_hpars.values()) \n",
    "    for item in sublist\n",
    "]\n",
    "\n",
    "subset = df[(df['preprocessing.num_gesture_classes'] == '51')]\n",
    "# print(subset.shape)\n",
    "gb = subset.groupby(all_hpars, dropna=False)\n",
    "subset['val.macro avg.f1-score.count'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "subset = subset[\n",
    "    subset['val.macro avg.f1-score.count'].between(5, 100)\n",
    "]\n",
    "\n",
    "subset['val.macro avg.f1-score.tenth_conf_interval'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform(tenth_conf_interval)\n",
    ")\n",
    "subset['val.macro avg.f1-score.mean']  = gb['val.macro avg.f1-score'].transform('mean')\n",
    "subset['val.macro avg.f1-score.min']   = gb['val.macro avg.f1-score'].transform('min')\n",
    "subset['val.macro avg.f1-score.max']   = gb['val.macro avg.f1-score'].transform('max')\n",
    "subset['val.macro avg.f1-score.std']   = gb['val.macro avg.f1-score'].transform('std')\n",
    "subset['val.macro avg.f1-score.count'] = gb['val.macro avg.f1-score'].transform('count')\n",
    "\n",
    "subset['group_idx'] = gb.ngroup()\n",
    "subset = subset.sort_values('val.macro avg.f1-score.tenth_conf_interval')\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718259c",
   "metadata": {},
   "source": [
    "### Plot models grouped by hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(40, 8))\n",
    "\n",
    "order = subset.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval'\n",
    ")['group_idx'].unique()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=subset,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "    order=order,\n",
    "    size=5,\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=subset, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=5, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='$F_1$ score for each set of hyperparameters, by model type',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    "    ylim=((-0.05, 1.05))\n",
    ")\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(\n",
    "    order,\n",
    "    rotation=90,\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.add_artist(plt.legend(handles[:-5], labels[:-5], title=\"Model Type\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "data = subset[subset['val.macro avg.f1-score.tenth_conf_interval'] > 0.6]\n",
    "\n",
    "order = data.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval'\n",
    ")['group_idx'].unique()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "    order=order,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    size=5,\n",
    "    jitter=False,\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=data, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=5, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='$F_1$ score for each set of hyperparameters\\n(Lower bound of the 90% CI $>$ 0.6)',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    ")\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(\n",
    "    order,\n",
    "    rotation=90,\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.add_artist(plt.legend(handles[:5], labels[:5], title=\"Model Type\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_best_hpar_comparison.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357da9c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_type = 'FFNN'\n",
    "\n",
    "def prettify_col(col):\n",
    "    return {\n",
    "        'val.macro avg.f1-score.mean': '$F_1$-score Mean',\n",
    "        'val.macro avg.f1-score.std': '$F_1$-score Std.Dev.',\n",
    "        'group_idx': 'Index',\n",
    "        'cusum.thresh': 'Threshold',\n",
    "        'ffnn.dropout_rate': 'Dropout Rate',\n",
    "        'ffnn.l2_coefficient': 'L2 Coefficient',\n",
    "        'ffnn.l2_coefficient.log10': '$\\log_{10}(\\text{L2 Coefficient})$',\n",
    "        'ffnn.nodes_per_layer.1': 'Nodes (layer 1)',\n",
    "        'ffnn.nodes_per_layer.2': 'Nodes (layer 2)',\n",
    "        'ffnn.nodes_per_layer.3': 'Nodes (layer 3)',\n",
    "        'hffnn.majority.ffnn.dropout_rate': 'Majority: Dropout Rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient': 'Majority: L2 Coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1': 'Majority: Nodes (layer 1)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2': 'Majority: Nodes (layer 2)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3': 'Majority: Nodes (layer 3)',\n",
    "        'hffnn.majority.nn.batch_size': 'Majority: Batch Size',\n",
    "        'hffnn.majority.nn.epochs': 'Majority: Epochs',\n",
    "        'hffnn.majority.nn.learning_rate': 'Majority: Learning Rate',\n",
    "        'hffnn.majority.nn.optimizer': 'Majority: Optimizer',\n",
    "        'hffnn.minority.ffnn.dropout_rate': 'Minority: Dropout Rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient': 'Minority: L2 Coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1': 'Minority: Nodes (layer 1)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2': 'Minority: Nodes (layer 2)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3': 'Minority: Nodes (layer 3)',\n",
    "        'hffnn.minority.nn.batch_size': 'Minority: Batch Size',\n",
    "        'hffnn.minority.nn.epochs': 'Minority: Epochs',\n",
    "        'hffnn.minority.nn.learning_rate': 'Minority: Learning Rate',\n",
    "        'hffnn.minority.nn.optimizer': 'Minority: Optimizer',\n",
    "        'hmm.covariance_type': 'Covariance Type',\n",
    "        'nn.batch_size': 'Batch Size',\n",
    "        'nn.batch_size.log10': '$\\log_{10}(\\text{Batch Size})$',\n",
    "        'nn.epochs': 'Epochs',\n",
    "        'nn.learning_rate': 'Learning Rate',\n",
    "        'nn.learning_rate.log10': '$\\log_{10}(\\text{Learning Rate})$',\n",
    "        'nn.optimizer': 'Optimizer',\n",
    "        'svm.c': 'C',\n",
    "        'svm.class_weight': 'Class Weight',\n",
    "    }.get(col, col)\n",
    "\n",
    "def df_to_latex(df, model_type):\n",
    "    path = f'../../report/src/tables/05_best_{model_type.lower().replace(\" \", \"_\")}_hpars.generated.tex'\n",
    "    print('DONT FORGET TO UPDATE LaTeX tables: ', path)\n",
    "    df.to_latex(\n",
    "        path,\n",
    "        caption=f'Top {len(df)} performing {model_type} hyperparameter combinations, ordered by '\n",
    "                f'the lower bound of the 90 percent confidence interval for $F_1$-score.',\n",
    "        label=f'tab:05_best_{model_type.lower().replace(\" \", \"_\")}_hpars',\n",
    "        index=False,\n",
    "        float_format=lambda x: '%.3e' % x,\n",
    "        na_rep='-'\n",
    "    )\n",
    "\n",
    "for model_type in type_to_hpars.keys():\n",
    "    latex_df = (\n",
    "        subset[\n",
    "            subset['model_type'] == model_type\n",
    "        ]\n",
    "        .sort_values('val.macro avg.f1-score.tenth_conf_interval', ascending=False)\n",
    "        .groupby('group_idx')\n",
    "        .tail(1)\n",
    "        [\n",
    "            ['group_idx', 'val.macro avg.f1-score.mean', 'val.macro avg.f1-score.std'] \n",
    "            + type_to_hpars[model_type]\n",
    "        ]\n",
    "        .head(10)\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns=prettify_col)\n",
    "        .replace({\n",
    "            'tied': 'Tied',\n",
    "            'spherical': 'Spherical',\n",
    "            'diag': 'Diagonal',\n",
    "            'full': 'Full',\n",
    "            'balanced': 'Balanced',\n",
    "        } | {} if model_type != 'SVM' else {\n",
    "            np.nan: 'Unbalanced',\n",
    "        } | {} if model_type not in ('HFFNN', 'FFNN') else {\n",
    "            np.nan: 'None',\n",
    "        })\n",
    "    )\n",
    "    display(latex_df)\n",
    "    \n",
    "    if model_type == 'HFFNN':\n",
    "        majority = latex_df[[c for c in latex_df.columns if 'Minority' not in c]]\n",
    "        minority = latex_df[[c for c in latex_df.columns if 'Majority' not in c]]\n",
    "        df_to_latex(majority, 'Majority HFFNN')\n",
    "        df_to_latex(minority, 'Minority HFFNN')\n",
    "    else:\n",
    "        df_to_latex(latex_df, model_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fae603",
   "metadata": {},
   "source": [
    "### Model types grouped by hpar index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f251b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "ax3 = fig.add_subplot(gs[2, :])\n",
    "ax4 = fig.add_subplot(gs[3, 0])\n",
    "ax5 = fig.add_subplot(gs[3, 1])\n",
    "# axs = np.array([ax1, ax2, ax3, ax4, ax5])\n",
    "model_axs = {\n",
    "    'FFNN':  ax1,\n",
    "    'HFFNN': ax2,\n",
    "    'SVM':   ax3,\n",
    "    'HMM':   ax4,\n",
    "    'CuSUM': ax5,\n",
    "}\n",
    "\n",
    "for model_type, color in model_colours.items():\n",
    "    ax = model_axs[model_type]\n",
    "    data = subset[subset['model_type'] == model_type]\n",
    "    \n",
    "    order = data.sort_values(\n",
    "        'val.macro avg.f1-score.tenth_conf_interval'\n",
    "    )['group_idx'].unique()\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='group_idx',\n",
    "#         hue='model_type',\n",
    "        color=color,\n",
    "        order=order,\n",
    "        size=5,\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "        jitter=False,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    sns.pointplot(\n",
    "        data=data, \n",
    "        x=\"group_idx\", \n",
    "        y=\"val.macro avg.f1-score\", \n",
    "        hue=\"model_type\",\n",
    "        linestyle=\"none\", \n",
    "        errorbar=None,\n",
    "        marker=\"_\", \n",
    "        markersize=5, \n",
    "        palette='dark:black',\n",
    "        markeredgewidth=1,\n",
    "        zorder=10,\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "    )\n",
    "    \n",
    "    ax.set(\n",
    "        title=f'$F_1$-score for each set of {model_type} hyperparameters',\n",
    "        xlabel='Hyperparameter index',\n",
    "        ylabel='$F_1$-score',\n",
    "        ylim=((-0.05, 1.05)),\n",
    "    )\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(order, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_hpar_comparison_per_model_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0e507",
   "metadata": {},
   "source": [
    "## Top X performing models by precision/recall/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# NOTE: Since every model gets 5 repetitions, the \"top 5\" will likely only contain one model.\n",
    "top_n = 9\n",
    "metric = 'val.macro avg.f1-score'\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "].sort_values(metric, ascending=False).head(top_n)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    best = data.iloc[i]\n",
    "    show_conf_mat_from_model(f\"../{best['model_dir']}\", ax)\n",
    "    ax.set(\n",
    "        title=f\"{best['model_type']}\\n$F_1=${np.round(best['val.macro avg.f1-score'], 4)}\",\n",
    "    )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102c42e",
   "metadata": {},
   "source": [
    "## Get statistics for each hyperparameter combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') & \n",
    "    (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "    (df['preprocessing.seed'] == 42.0)\n",
    "]\n",
    "\n",
    "data[[c for c in subset_cols if 'ffnn.' in c or 'nn.' in c]].head(31)\n",
    "data[subset_cols].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813866a",
   "metadata": {},
   "source": [
    "## ECDF for all model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "for model_type, color in model_colours.items():\n",
    "    scores = df.loc[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type),\n",
    "        'val.macro avg.f1-score'\n",
    "    ]\n",
    "    sorted_scores = np.sort(scores)\n",
    "    ecdf = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "    ax.plot(sorted_scores, ecdf, color=color, label=model_type)\n",
    "plt.legend()\n",
    "ax.set(\n",
    "    title='ECDF for all model types',\n",
    "    xlabel='$F_1$-score',\n",
    "    ylabel='Cumulative Probability',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c935d3a7",
   "metadata": {},
   "source": [
    "## Training vs Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978757cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 2],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 2],\n",
    ")\n",
    "\n",
    "axs[0, 0].plot([0, 0.1], [0, 0.1], color='black', alpha=.1)\n",
    "axs[0, 1].plot([0, 0.005], [0, 0.005], color='black', alpha=.1)\n",
    "axs[0, 2].plot([0, 0.00005], [0, 0.00005], color='black', alpha=.1)\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference times (seconds per observation)\\n',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 2].set(\n",
    "    title='c) Inference times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='d) Inference vs training times (seconds per observation)\\n',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 1].set(\n",
    "    title='e) Inference vs training times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 2].set(\n",
    "    title='f) Inference vs training times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_trn_times_per_obs.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473064",
   "metadata": {},
   "source": [
    "## Inference time vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_ylim((-0.001, 0.011))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['val.pred_time_per_obs'] < 0.0001)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    ")\n",
    "plt.tight_layout()\n",
    "axs[0].set_xlim((-0.05, 1.05))\n",
    "axs[1].set_xlim((-0.05, 1.05))\n",
    "axs[0].set_xlabel('$F_1$-score')\n",
    "axs[1].set_xlabel('$F_1$-score')\n",
    "axs[0].set_ylabel('Inference time per observation (s)')\n",
    "axs[1].set_ylabel('Inference time per observation (s)')\n",
    "axs[0].set_title('Inference time per observation against $F_1$ score\\n')\n",
    "axs[1].set_title('Inference time per observation against $F_1$ score\\n(0 to 0.0001s)')\n",
    "\n",
    "axs[0].legend().set_title(\"Model Type\")\n",
    "axs[1].legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inference_time_per_obs_vs_f1.pdf', \n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0978408",
   "metadata": {},
   "source": [
    "## Confusion Matrices of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngestures = sorted(df['preprocessing.num_gesture_classes'].unique())\n",
    "model_types = sorted(df['model_type'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(ngestures),\n",
    "    len(model_types),\n",
    "    figsize=(len(model_types)*6, len(ngestures)*6),\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "for i, ngesture in enumerate(ngestures):\n",
    "    for j, model_type in enumerate(model_types):\n",
    "        best = df[\n",
    "            (df['preprocessing.num_gesture_classes'] == ngesture) &\n",
    "            (df['model_type'] == model_type)\n",
    "        ].sort_values('val.macro avg.f1-score', ascending=False)\n",
    "        if len(best) == 0:\n",
    "            axs[i,j].axis('off')\n",
    "            continue\n",
    "        best = best.iloc[0]\n",
    "        print(ngesture, model_type, best['model_dir'])\n",
    "        try:\n",
    "            show_conf_mat_from_model(f\"../{best['model_dir']}\", axs[i, j])\n",
    "        except FileNotFoundError:\n",
    "            show_conf_mat_from_model(f\"./{best['model_dir']}\", axs[i, j])\n",
    "        axs[i, j].set(\n",
    "            title=f\"Best {model_type}: {ngesture} gestures\\n($F_1=${np.round(best['val.macro avg.f1-score'], 4)})\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d88e74",
   "metadata": {},
   "source": [
    "## Mean Confidence Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a95bef",
   "metadata": {},
   "source": [
    "### 5 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '5'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat[-1, -1] = 0\n",
    "#     conf_mat /= conf_mat_totals[hpar_item]\n",
    "    conf_mat /= conf_mat.max()\n",
    "    print(conf_mat_totals[hpar_item])\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9bbf3",
   "metadata": {},
   "source": [
    "### 50 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '50'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196fd7f",
   "metadata": {},
   "source": [
    "### 51 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '51'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    try:\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    except FileNotFoundError:\n",
    "        y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ', flush=True)\n",
    "        \n",
    "fig, axs = plt.subplots(\n",
    "    2, 3,\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "axs[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ad9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nclasses = '51'\n",
    "model_type = 'FFNN'\n",
    "for model_type in ('FFNN', 'SVM', 'HFFNN', 'CuSUM', 'HMM'):\n",
    "    data = df[\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "\n",
    "    hpar = 'preprocessing.num_gesture_classes'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "    print(model_type, flush=True)\n",
    "\n",
    "    for i, row in data.sort_values(hpar).iterrows():\n",
    "        try:\n",
    "            y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        except FileNotFoundError:\n",
    "            y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        f1_score = sklearn.metrics.f1_score(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] += f1_score\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] = f1_score\n",
    "        if i % 100 == 0:\n",
    "            print(i, end=' ', flush=True)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, len(conf_mats.keys()),\n",
    "        figsize=(4*len(conf_mats.keys()), 4),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "        if conf_mat.shape[0] == 51:\n",
    "            conf_mat[-1, -1] = 0\n",
    "        conf_mat /= conf_mat.max()\n",
    "        vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "        axs[i].set_title(\n",
    "            f'{model_type} {hpar_item}-class Confusion Matrices\\n(weighted mean)'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_mean_conf_mat_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1fc7b",
   "metadata": {},
   "source": [
    "## Regularization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gesture_classes = (\n",
    "    '5',\n",
    "    '50',\n",
    "    '51',\n",
    ")\n",
    "fig, axs = plt.subplots(len(n_gesture_classes), 2, figsize=(6, len(n_gesture_classes)*3))\n",
    "\n",
    "for i, ngestures in enumerate(n_gesture_classes):\n",
    "    data = df[df['preprocessing.num_gesture_classes'] == ngestures]\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.l2_coefficient',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 0]\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 1]\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{ngestures} gestures')\n",
    "    axs[i, 1].set_title(f'{ngestures} gestures')\n",
    "\n",
    "plt.suptitle(\"$F_1$-ratio against regularisation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3fa2",
   "metadata": {},
   "source": [
    "## Ratio $F_1$ scores vs actual $F_1$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "axs[0, 0].set_xlim((-0.05, 1.05))\n",
    "axs[0, 0].set_ylim((-0.05, 1.05))\n",
    "axs[0, 0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 0].set_title(\"a) Training vs Validation $F_1$ score\\n\")\n",
    "axs[0, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 0].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 0].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "axs[0, 1].set_xlim((0.5, 1.05))\n",
    "axs[0, 1].set_ylim((0.5, 1.05))\n",
    "axs[0, 1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 1].set_title(\"b) Training vs Validation $F_1$ score\\n(magnified)\")\n",
    "axs[0, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 1].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 1].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "axs[1, 0].set_xlim((-0.05, 1.05))\n",
    "axs[1, 0].set_title(\"c) $F_1$-ratio vs $F_1$-score\\n\")\n",
    "axs[1, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 0].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 0].legend().set_title('Model Type')\n",
    "axs[1, 0].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['val.macro avg.f1-score'] >= 0.5)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "axs[1, 1].set_xlim((0.5, 1.05))\n",
    "axs[1, 1].set_title(\"d) $F_1$-ratio vs $F_1$-score\\n(magnified)\")\n",
    "axs[1, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 1].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 1].legend().set_title('Model Type')\n",
    "axs[1, 1].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_f1_vs_f1_ratio.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501fb68",
   "metadata": {},
   "source": [
    "## Training/validation loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss',\n",
    "    x='trn.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].assign(**{\n",
    "        'ratio.loss': lambda x: x['trn.loss'] / x['val.loss']\n",
    "    }),\n",
    "    x='ratio.loss',\n",
    "    y='val.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "\n",
    "axs[0].set_ylim((-0.05, 3.6))\n",
    "axs[1].set_ylim((-0.05, 3.6))\n",
    "\n",
    "axs[1].plot([1, 1], [0, axs[1].get_ylim()[1]], color='black', alpha=.1)\n",
    "\n",
    "min_max = min(axs[0].get_xlim()[1], axs[0].get_ylim()[1] )\n",
    "axs[0].plot([0, min_max], [0, min_max], color='black', alpha=.1)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation loss vs training loss\\n(FFNN only)',\n",
    "    xlabel='Training Loss',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Validation loss vs loss ratio\\n(FFNN only)',\n",
    "    xlabel=r'Loss ratio ($\\frac{Training}{Validation}$)',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_val_trn_loss_ratios.pdf'\n",
    ")\n",
    "\n",
    "print(\"TODO: The training and validation loss aren't comparable because the training loss is weighed but validation loss is not.\")\n",
    "print(\"TODO: also not comparable because of dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e23cda",
   "metadata": {},
   "source": [
    "## Precision vs Recall plots for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, color in model_colours.items():\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "    print(f\"{p_min=}, {p_max=}, {r_min=}, {r_max=}, \")\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    print(f1_score.min())\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            10\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    ax.set(\n",
    "        title=f\"Precision vs Recall For {model_type} models\\n($F_1$ contours in grey)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_{model_type.lower()}_p_vs_r.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5349d1",
   "metadata": {},
   "source": [
    "## In depth FFNN plots\n",
    "\n",
    "- Clusters in the recall of different models\n",
    "- Hyperparameters vs f1 score/recall/precision\n",
    "- No correlation with the inference time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f3489",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = (\n",
    "    'f1-score',\n",
    "    'precision',\n",
    "    'recall',\n",
    ")\n",
    "\n",
    "metric_labels = (\n",
    "    '$F_1$',\n",
    "    'Precision',\n",
    "    'Recall',\n",
    ")\n",
    "\n",
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "df[[\n",
    "#     'ffnn.dropout_rate.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "]] = np.log10(df[[\n",
    "#     'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]])\n",
    "xlabels = (\n",
    "    'Dropout Rate',\n",
    "    'L2 Coefficient ($\\log_{10}$)',\n",
    "    'Batch Size ($\\log_{10}$)',\n",
    "    'Learning Rate ($\\log_{10}$)',\n",
    "    'Nodes in Layer 1',\n",
    "    'Nodes in Layer 2',\n",
    "    'Nodes in Layer 3',\n",
    ")\n",
    "\n",
    "max_log10_val_loss = -0.25\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "    & (df['val.loss.log10'] <= max_log10_val_loss)\n",
    "]\n",
    "\n",
    "\n",
    "for metric, metric_label in zip(metrics, metric_labels):\n",
    "    fig, axs = plt.subplots(\n",
    "        4, 2,\n",
    "        figsize=(12, 24),\n",
    "        dpi=100,\n",
    "    )\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y=f'val.macro avg.{metric}',\n",
    "            hue='val.loss.log10',\n",
    "            palette=palette,\n",
    "            s=20,\n",
    "            ax=ax,\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'{metric_label} vs {title_xlabel}\\n'\n",
    "                  f'$\\log_{{10}}($ Validation loss $) < {max_log10_val_loss}$',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel=metric_label,\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "        ax.legend().set_title('Validation Loss\\n($\\log_{10}$)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_ffnn_hpars_vs_{metric}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b30315",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for hpar, ax in zip(hyperpars, axs.flatten()):\n",
    "    sns.scatterplot(\n",
    "        data=df[\n",
    "            (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "            (df['model_type'] == 'FFNN')\n",
    "        ],\n",
    "        x=hpar,\n",
    "        y='val.loss.log10',\n",
    "        hue='trn.loss.log10',\n",
    "        ax=ax,\n",
    "        palette='Spectral',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.legend().set_title('Training Loss\\n($\\log_{10}$)')\n",
    "# plt.show()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss.log10',\n",
    "    x='trn.loss.log10',\n",
    "    ax=axs[-1, -1],\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11ffca",
   "metadata": {},
   "source": [
    "## In depth HFFNN plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e014f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error \n",
    "# This cell isn't used\n",
    "\n",
    "maj_min = (\n",
    "    'majority',\n",
    "    'minority',\n",
    ")\n",
    "for submodel in maj_min:\n",
    "    hyperpars = (\n",
    "        f'hffnn.{submodel}.ffnn.dropout_rate',\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.1',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.2',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.3',\n",
    "    )\n",
    "    df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "    ]] = np.log10(df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient',\n",
    "        f'hffnn.{submodel}.nn.batch_size',\n",
    "        f'hffnn.{submodel}.nn.learning_rate',\n",
    "    ]])\n",
    "    xlabels = (\n",
    "        f'{submodel.title()} Dropout Rate',\n",
    "        f'{submodel.title()} L2 Coefficient ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Batch Size ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Learning Rate ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Nodes in Layer 1',\n",
    "        f'{submodel.title()} Nodes in Layer 2',\n",
    "        f'{submodel.title()} Nodes in Layer 3',\n",
    "    )\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'HFFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        3, 3,\n",
    "        figsize=(8, 8)\n",
    "    )\n",
    "    print(axs.shape)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y='val.macro avg.f1-score',\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "            color='tab:orange',\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'$F_1$ score vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel='$F_1$ score',\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hffnn_{submodel}_hpars.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ec275",
   "metadata": {},
   "source": [
    "## In depth CuSUM plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca465fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'CuSUM')\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10,\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='cusum.thresh',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x='cusum.thresh',\n",
    "    y='val.macro avg.f1-score',\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    "    ax=axs[1],\n",
    "    jitter=0.5,\n",
    "    color=model_colours['CuSUM'],\n",
    "    native_scale=True,\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "axs[0].set(\n",
    "    title=f\"a) Precision vs Recall for CuSUM models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "axs[0].legend().set_title('Threshold')\n",
    "\n",
    "axs[1].set(\n",
    "    title='b) CuSUM Threshold vs $F_1$ score',\n",
    "    xlabel='CuSUM Threshold',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_cusum_p_vs_r_thresh.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e89a9",
   "metadata": {},
   "source": [
    "## In depth SVM plots\n",
    "\n",
    "- Correlation with the training time per observation\n",
    "- Correlation with the precision/recall/f1\n",
    "- clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='$\\log_{10}(C)$',\n",
    "    style='Class Weight',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='$\\log_{10}(C)$',\n",
    "    y='val.macro avg.f1-score',\n",
    "    style='Class Weight',\n",
    "    alpha=0.75,\n",
    "    s=20,\n",
    "    ax=axs[1],\n",
    "    color='tab:purple',\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title=f\"Precision vs Recall for SVMs\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    ")\n",
    "axs[1].set(\n",
    "    title=f\"SVM Regularization parameter vs $F_1$ score\",\n",
    "    xlabel='SVM Regularization parameter C ($\\log_{10}$)',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_svm_p_vs_r_class_weight_C.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'svm.class_weight'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(conf_mats), \n",
    "    figsize=(4*len(conf_mats), 4)\n",
    ")\n",
    "\n",
    "\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat_totals[hpar_item]\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} SVMs\\n(Mean of {int(conf_mat_totals[hpar_item])} Confusion Matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_svm_conf_mats_unbalanced.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177737f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "    s=10,\n",
    "    alpha=0.75,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='SVM hyperparameters against fit time',\n",
    "    ylabel='Fit time (seconds per observation)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_svm_hpars_vs_fit_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47109a",
   "metadata": {},
   "source": [
    "## In depth HMM plots\n",
    "\n",
    "- Clusters in recall-precision space\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385f533",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_type = 'HMM'\n",
    "color='tab:red'\n",
    "    \n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == model_type)\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='hmm.covariance_type',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=ax,\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "ax.set(\n",
    "    title=f\"Precision vs Recall for {model_type} models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "ax.legend().set_title('Covariance Type')\n",
    "\n",
    "# plt.savefig(\n",
    "#     f'../../report/src/imgs/graphs/05_in_depth_hmm_p_vs_r_covar_type.pdf',\n",
    "#     bbox_inches='tight',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title('Covariance Type')\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference time on the Training and Validation sets\\n',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference time on the Training and Validation sets\\n($< 0.02$s)',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='c) Inference and Fitting times\\n',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 1].set(\n",
    "    title='d) Inference and Fitting times\\n($< 0.02$s)',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_inf_trn_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0997de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "f1_scores = {}\n",
    "y_preds_dict = {}\n",
    "y_true_dict = {}\n",
    "reports_dict = {}\n",
    "\n",
    "hpar = 'hmm.covariance_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "#         average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "        precisions[hpar_item] += precision\n",
    "        recalls[hpar_item] += recall\n",
    "        f1_scores[hpar_item] += f1_score\n",
    "        y_preds_dict[hpar_item] = np.concatenate((y_preds_dict[hpar_item], y_pred.flatten()))\n",
    "        y_true_dict[hpar_item] = np.concatenate((y_true_dict[hpar_item], y_true.flatten()))\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "        precisions[hpar_item] = precision\n",
    "        recalls[hpar_item] = recall\n",
    "        f1_scores[hpar_item] = f1_score\n",
    "        y_preds_dict[hpar_item] = np.copy(y_pred.flatten())\n",
    "        y_true_dict[hpar_item] = np.copy(y_true.flatten())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 8),\n",
    "    squeeze=False,\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.conf_mat(conf_mat / conf_mat.max(), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} HMMs\\n'\n",
    "        f'(Mean of {int(conf_mat_totals[hpar_item])} confusion matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_conf_mats_cov_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 2),\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.precision_recall_f1(\n",
    "        precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        ax=axs[i],\n",
    "    )\n",
    "    axs[i].set_title(hpar_item)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_prf1_plots_conv_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127c75f",
   "metadata": {},
   "source": [
    "## FFNN Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763743c",
   "metadata": {},
   "source": [
    "### Heatmap-based pairplot of FFNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cf8f8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') &\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "]\n",
    "\n",
    "hpars_scale = [\n",
    "    ('nn.learning_rate',       'log10'),\n",
    "    ('ffnn.nodes_per_layer.1', 'log10'),\n",
    "    ('ffnn.l2_coefficient',    'log10'),\n",
    "    ('ffnn.dropout_rate',      'linear'),\n",
    "]\n",
    "# x_var_idx = 0\n",
    "# y_var_idx = 1\n",
    "def contour_nicely(x, y, z, xlabel, ylabel, xscale, yscale, fig, ax, levels=8):\n",
    "\n",
    "    ax.tricontour(x, y, z, levels=levels, linewidths=0.25, colors='k')\n",
    "    cntr2 = ax.tricontourf(x, y, z, levels=levels, cmap=palette)\n",
    "\n",
    "    fig.colorbar(cntr2, ax=ax)\n",
    "    ax.scatter(x, y, color='white', s=1)\n",
    "\n",
    "    ax.set_xlabel(f'{xlabel} ({xscale})')\n",
    "    if xscale == 'log10':\n",
    "        ax.set_xticks(ax.get_xticks())\n",
    "        ax.set_xticklabels([f'{np.power(10, t):.3g}' for t in ax.get_xticks()])\n",
    "\n",
    "    ax.set_ylabel(f'{ylabel} ({yscale})')\n",
    "    if yscale == 'log10':\n",
    "        ax.set_yticks(ax.get_yticks())\n",
    "        ax.set_yticklabels([f'{np.power(10, t):.3g}' for t in ax.get_yticks()])\n",
    "\n",
    "    ax.set_title(f'{xlabel} vs {ylabel}')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(\n",
    "    len(hpars_scale), \n",
    "    len(hpars_scale), \n",
    "    dpi=200, \n",
    "    squeeze=False,\n",
    "    figsize=(20,20)\n",
    ")\n",
    "z = data['val.macro avg.f1-score'].values\n",
    "for x_var_idx in range(len(hpars_scale)):\n",
    "    for y_var_idx in range(x_var_idx+1, len(hpars_scale)):\n",
    "    \n",
    "        x = data[hpars_scale[x_var_idx][0]].values\n",
    "        if hpars_scale[x_var_idx][1] == 'log10':\n",
    "            x = np.log10(x)\n",
    "        elif hpars_scale[x_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[x_var_idx][0]} is not implemented\")\n",
    "        y = data[hpars_scale[y_var_idx][0]].values\n",
    "        if hpars_scale[y_var_idx][1] == 'log10':\n",
    "            y = np.log10(y)\n",
    "        elif hpars_scale[y_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[y_var_idx][0]} is not implemented\")\n",
    "            \n",
    "        contour_nicely(\n",
    "            y, x, z,\n",
    "            hpars_scale[y_var_idx][0],\n",
    "            hpars_scale[x_var_idx][0],\n",
    "            hpars_scale[y_var_idx][1],\n",
    "            hpars_scale[x_var_idx][1],\n",
    "            fig, axs[x_var_idx, y_var_idx]\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d59541",
   "metadata": {},
   "source": [
    "## Plot inference/training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e10eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'fit_time_per_obs': lambda x: x['fit_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='fit_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'trn.pred_time_per_obs': lambda x: x['trn.pred_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'val.pred_time_per_obs': lambda x: x['val.pred_time'] / x['val.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='val.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5945658",
   "metadata": {},
   "source": [
    "## Inference times vs num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58de27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "model_types = [m for m in model_colours.keys() if m != 'HFFNN']\n",
    "for ax, model_type in zip(axs, model_types):\n",
    "    sns.stripplot(\n",
    "        data=df[\n",
    "            df['model_type'] == model_type\n",
    "        ].sort_values('preprocessing.num_gesture_classes'),\n",
    "        x='preprocessing.num_gesture_classes',\n",
    "        y='val.pred_time_per_obs',\n",
    "        hue='model_type',\n",
    "#         dodge=True,\n",
    "        s=2,\n",
    "        legend=False,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(model_type)\n",
    "\n",
    "# sns.stripplot(\n",
    "#     data=df[\n",
    "#         df['val.pred_time_per_obs'] < 0.02\n",
    "#     ].sort_values('preprocessing.num_gesture_classes'),\n",
    "#     hue='preprocessing.num_gesture_classes',\n",
    "#     x='model_type',\n",
    "#     y='val.pred_time_per_obs',\n",
    "#     dodge=True,\n",
    "#     s=2,\n",
    "# #     hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "#     ax=axs[1]\n",
    "# )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181109be",
   "metadata": {},
   "source": [
    "## Example Confusion Matrices from baseline models\n",
    "\n",
    "TODO: Also include models with perfect precision / perfect recall / perfect precision for non-g255 gestures / perfect precision for g255 / perfect recall for non-g255 gestures / perfect recall for g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d36d37",
   "metadata": {},
   "source": [
    "### Plot a model that only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81fc63",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A function for plotting precision-recall + confusion matrices\n",
    "def plt_pr_conf_mat(y_true, y_preds):\n",
    "    \"\"\"Given true and predicted labels, \n",
    "    create a confusion matrix and a precision-recall plot.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "    if len(y_preds.shape) == 1:\n",
    "        y_preds = np.array([y_preds])\n",
    "    # Confusion matrix\n",
    "    # Get the median confusion matrix\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    cm_sum = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for y_pred in y_preds:\n",
    "        cm_sum += tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "    cm = cm_sum / len(y_preds)\n",
    "    vis.conf_mat(cm, ax=axs[1])\n",
    "    \n",
    "    f1_sum = 0\n",
    "    for y_pred in y_preds:\n",
    "        f1_sum += sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_sum / len(y_preds)\n",
    "\n",
    "    # Precision-recall plot\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(0, 1, 100), \n",
    "        np.linspace(0, 1, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    ps = []\n",
    "    rs = []\n",
    "    for y_pred in y_preds:\n",
    "        ps.append(sklearn.metrics.precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "        rs.append(sklearn.metrics.recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    p = np.mean(ps)\n",
    "    r = np.mean(rs)\n",
    "\n",
    "    axs[0].scatter(\n",
    "        ps, rs,\n",
    "        color='black',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    axs[0].set_xlabel('Precision')\n",
    "    axs[0].set_ylabel('Recall')\n",
    "    axs[0].set_xlim((-0.01, 1.01))\n",
    "    axs[0].set_ylim((-0.01, 1.01))\n",
    "    axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "#     axs[0].set_title(f'Precision-Recall Graph\\n(contours indicate the $F_1$-score)')\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff657758",
   "metadata": {},
   "source": [
    "#### Only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da06a2f",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Only predicts 50\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_only_50.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa4bba",
   "metadata": {},
   "source": [
    "#### Completely random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts randomly\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_random_preds.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894af3ed",
   "metadata": {},
   "source": [
    "#### Wrong orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong orientation\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn_repeated + 10*np.random.randint(\n",
    "        -(y_trn_repeated // 10), \n",
    "        +(5 - y_trn_repeated // 10), \n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_orientation.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78100f19",
   "metadata": {},
   "source": [
    "#### Wrong finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong finger\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 10), \n",
    "        +(10 - np.mod(y_trn_repeated, 10)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba12ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong finger (but correct hand)\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 5), \n",
    "        +(5 - np.mod(y_trn_repeated, 5)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger_correct_hand.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072cb6",
   "metadata": {},
   "source": [
    "#### Predict 50 as a random gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_no_gesture_50.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32086956",
   "metadata": {},
   "source": [
    "#### High recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74628a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 51, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_recall.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801984",
   "metadata": {},
   "source": [
    "#### High precision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88419278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 5, axis=0)\n",
    "y_preds = np.where(\n",
    "    y_trn_repeated == 50,\n",
    "    y_trn_repeated,\n",
    "    50,\n",
    ")\n",
    "\n",
    "# np.clip(np.random.randint(-1, 1, size=y_trn_repeated.shape) + y_trn_repeated, 0, 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_precision.pdf', bbox_inches='tight')\n",
    "\n",
    "# f1_scores = []\n",
    "# for y_pred in y_preds:\n",
    "#     f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "# f1_scores = np.array(f1_scores)\n",
    "# print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f508a",
   "metadata": {},
   "source": [
    "### Finally, plot all confusion matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Random model:\n",
    "y_pred = np.random.randint(0, 51, y_trn.shape)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[0])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[0].set_title(f\"Random model\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Only predicts 50\n",
    "y_pred = np.full(y_trn.shape, 50)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[1])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[1].set_title(f\"Only predicts 50\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random orientation:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn + 10*np.random.randint(\n",
    "        -(y_trn // 10), \n",
    "        +(5 - y_trn // 10), \n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[2])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[2].set_title(f\"Perfect,\\nbut random orientation\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 10), \n",
    "        +(10 - np.mod(y_trn, 10)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[3])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[3].set_title(f\"Perfect,\\nbut random finger\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger (same hand):\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 5), \n",
    "        +(5 - np.mod(y_trn, 5)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[4])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[4].set_title(f\"Perfect,\\nbut random finger on the correct hand\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Never predicts 50\n",
    "y_pred = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn.shape), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(\n",
    "    y_trn, \n",
    "    y_pred,\n",
    ").numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[5])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[5].set_title(f\"Perfect,\\nbut predicts 50 as a random gesture\\n$F_1$={f1:.4}\")\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_example_conf_mats.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e588714",
   "metadata": {},
   "source": [
    "## PCA Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fa9de",
   "metadata": {},
   "source": [
    "### PCA decomposition only including the gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43526c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(\n",
    "    n_components=2,\n",
    "    learning_rate='auto',\n",
    "    init='random',\n",
    "    perplexity=3,\n",
    "    verbose=True\n",
    ").fit_transform(X_trn[y_trn != 50].reshape((X_trn[y_trn != 50].shape[0], 600)))\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10), dpi=200)\n",
    "argsort = np.argsort(y_trn[y_trn != 50])\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_embedded[:, 0][argsort],\n",
    "    y=X_embedded[:, 1][argsort],\n",
    "    hue=hues[(y_trn[y_trn != 50][argsort] // 10)],\n",
    "    style=styles[(y_trn[y_trn != 50][argsort] % 10)],\n",
    "    s=10,\n",
    "    alpha=0.5\n",
    "#     ax=axs[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "\n",
    "argsort = np.argsort(y_trn[y_trn != 50])\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=300)\n",
    "sns.scatterplot(\n",
    "    x=X_tfrm[:, 0][argsort],\n",
    "    y=X_tfrm[:, 1][argsort],\n",
    "    hue=hues[(y_trn[y_trn != 50][argsort] // 10)],\n",
    "    style=styles[(y_trn[y_trn != 50][argsort] % 10)],\n",
    "    s=10,\n",
    "    ax=axs[0]\n",
    ")\n",
    "axs[0].set_title(\"PCA plot of the training data\\nExcluding class 50\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=300)\n",
    "mask = (y_trn == 50)\n",
    "axs[1].scatter(\n",
    "    X_tfrm[:, 0][mask],\n",
    "    X_tfrm[:, 1][mask],\n",
    "    color='black',\n",
    "    alpha=0.1,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "axs[1].scatter(\n",
    "    X_tfrm[:, 0][~mask],\n",
    "    X_tfrm[:, 1][~mask],\n",
    "    color=colours[(y_trn[~mask] // 10)],\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "axs[1].set_title('PCA plot of the training data\\n(class 50 in black)')\n",
    "\n",
    "axs[0].set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    ")\n",
    "axs[1].set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_pca_plot.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4231b",
   "metadata": {},
   "source": [
    "### PCA plot showing just an interesting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec25ed",
   "metadata": {
    "code_folding": [
     2,
     8
    ]
   },
   "outputs": [],
   "source": [
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "@interact(\n",
    "    x_start=(-1500, 1500, 50),\n",
    "    y_start=(-1500, 1500, 50),\n",
    "    x_length=(-1500, 1500, 50),\n",
    "    y_length=(-1500, 1500, 50),\n",
    ")\n",
    "def fn(x_start=-150, y_start=1000, x_length=500, y_length=500):\n",
    "    x_finsh = x_start + x_length\n",
    "    y_finsh = y_start + y_length\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "\n",
    "    selection_mask = (\n",
    "        (x_start <= X_tfrm[:, 0]) & (X_tfrm[:, 0] <= x_finsh) &\n",
    "        (y_start <= X_tfrm[:, 1]) & (X_tfrm[:, 1] <= y_finsh)\n",
    "    )\n",
    "    X_subset = X_tfrm[selection_mask]\n",
    "    y_subset = y_trn[selection_mask]\n",
    "#     ax.scatter(\n",
    "#         X_subset[:, 0],\n",
    "#         X_subset[:, 1],\n",
    "#         c='black',\n",
    "#         alpha=0.1,\n",
    "#     )\n",
    "    \n",
    "    y_mask = (y_trn == 50)\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset == 50],\n",
    "        X_subset[:, 1][y_subset == 50],\n",
    "        color='black',\n",
    "        alpha=0.1,\n",
    "        s=20,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset != 50],\n",
    "        X_subset[:, 1][y_subset != 50],\n",
    "        color=colours[(y_subset[y_subset != 50] // 10)],\n",
    "        alpha=0.75,\n",
    "#         s=5,\n",
    "        edgecolor='none',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d3579",
   "metadata": {},
   "source": [
    "### PCA plot that connects sequential datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "order = np.argsort(dt_trn)\n",
    "X_tfrm = X_tfrm[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "limit = 1000\n",
    "@interact(start=(0, len(X_tfrm), 25), length=(0, len(X_tfrm), 50))\n",
    "def fn(start=0, length=500):\n",
    "    finsh = min(start + length, len(X_tfrm))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "    ax.plot(\n",
    "        X_tfrm[:, 0][start:finsh],\n",
    "        X_tfrm[:, 1][start:finsh],\n",
    "        zorder=0,\n",
    "        c='black',\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_tfrm[:, 0][start:finsh],\n",
    "        y=X_tfrm[:, 1][start:finsh],\n",
    "        hue=dt_trn[order][start:finsh],\n",
    "        legend=False,\n",
    "        s=(10 + 90*(y_trn != 50)[order][start:finsh]),\n",
    "        edgecolor=np.where((y_trn != 50)[order][start:finsh], 'black', 'none'),\n",
    "        linewidth=.5,\n",
    "    )\n",
    "    \n",
    "    idxs = np.nonzero(y_trn[order][start:finsh] != 50)[0]\n",
    "    for idx in idxs:\n",
    "        ax.text(\n",
    "            X_tfrm[start:finsh][idx, 0],\n",
    "            X_tfrm[start:finsh][idx, 1],\n",
    "            y_trn[order][start:finsh][idx],\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "#     ax.set_xlim((\n",
    "#         X_tfrm[:, 0].min() / 1.1,\n",
    "#         X_tfrm[:, 0].max() * 1.1,\n",
    "#     ))\n",
    "#     ax.set_ylim((\n",
    "#         X_tfrm[:, 1].min() / 1.1,\n",
    "#         X_tfrm[:, 1].max() * 1.1,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e39f0",
   "metadata": {},
   "source": [
    "### PCA plot with ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed514b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "y_tfrm = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "?Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4bc98",
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensional dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse(\n",
    "        (0, 0), \n",
    "        width=ell_radius_x * 2, \n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor, \n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Calculating the standard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the standard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "    \n",
    "#     print(f\"{scale_x=}, {scale_y=}\\n{mean_x=}, {mean_y=}\")\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    \n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58901b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# gidx = 14\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "markers = ['o', 's', 'D', '^', 'v', '>', '<', 'p', 'H', '+']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "for gidx in range(50):\n",
    "    ax.scatter(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        color=colors[gidx // 10],\n",
    "        marker=markers[gidx % 10],\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        label=gidx\n",
    "    )\n",
    "    confidence_ellipse(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        ax,\n",
    "        n_std=2,\n",
    "        edgecolor=colors[gidx // 10],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5233e5",
   "metadata": {},
   "source": [
    "## Visualise mis-predictions\n",
    "\n",
    "1. Load in a continuous dataset\n",
    "2. Load in a classifier\n",
    "3. Use the classifier to make predictions on the dataset\n",
    "4. Visualise the mispredictions, but *with context*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8970",
   "metadata": {},
   "source": [
    "### Load in a model for which to evaluate the mis-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "clf = models.load_tf('../src/saved_models/ffnn_2023-09-18T14:05:16.363404')\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce0a33",
   "metadata": {},
   "source": [
    "### Visualise True and Mispredicted gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61f5b4",
   "metadata": {},
   "source": [
    "Plot all the observations which have the ground truth being gesture 255 but the model is not predicting g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a359ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "for gidx in np.unique(y_val):\n",
    "    if gidx == 50: continue\n",
    "    pred_indxs = np.nonzero((y_val == 50) & (y_pred == gidx))[0]\n",
    "    true_indxs = np.nonzero(y_val == gidx)[0]\n",
    "    axs = vis.cmp_ts(\n",
    "        X_val[true_indxs],\n",
    "    )\n",
    "    vis.cmp_ts(\n",
    "        X_val[pred_indxs],\n",
    "        color='tab:red',\n",
    "        axs=axs,\n",
    "    )\n",
    "\n",
    "#     distances = np.abs(true_indxs[:, np.newaxis] - pred_indxs).min(axis=0)\n",
    "\n",
    "    plt.suptitle(f'Model predicted {gidx}, ground truth: 50 \\\n",
    "                 \\nGesture {gidx} in grey, mispredicted in red ({len(pred_indxs)} observations) \\\n",
    "                 \\nindices: {pred_indxs}')\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'../src/notebooks/pred_{gidx:0>2}_truth_50.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     if gidx > 5:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1601b8",
   "metadata": {},
   "source": [
    "# Interactive plot to see data at a certain time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "#     constants_path='../src/constants.yaml',\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "\n",
    "@interact(dt='2022-10-08T20:23:46.665276000')\n",
    "def fn(dt='2022-10-08T20:23:46.665276000'):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    mask = df['datetime'].between(\n",
    "        dt - pd.to_timedelta(1, 'second'),\n",
    "        dt + pd.to_timedelta(1, 'second')\n",
    "    )\n",
    "    \n",
    "    vis.cmp_ts(\n",
    "        [df.loc[mask, sensor_names].values]\n",
    "    )\n",
    "#     ax.plot(\n",
    "#         df.loc[mask, sensor_names].values\n",
    "#     )\n",
    "#     dt_labels = df.loc[mask, 'datetime']\n",
    "#     gidx_labels = df.loc[mask, 'gidx']\n",
    "#     ax.set_xticks(range(len(dt_labels)))\n",
    "#     ax.set_xticklabels([\n",
    "#         f'{gidx_label} {str(dt_label)[5:-3]}'\n",
    "#         for dt_label, gidx_label\n",
    "#         in zip(dt_labels, gidx_labels)\n",
    "#     ], rotation=90)\n",
    "# 2022-10-08T20:23:46.665276000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc213ce7",
   "metadata": {},
   "source": [
    "# Plot a CSV file + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ellipses = calculate_prediction_ellipse(\n",
    "    X_tfrm[y_tfrm == 0, 0],\n",
    "    X_tfrm[y_tfrm == 0, 1],\n",
    ")\n",
    "ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../gesture_data/saved_from_cli_alphabet.csv'\n",
    "model_dir = '../src/saved_models/ffnn_2023-10-04T12:02:09.749144'\n",
    "\n",
    "sensors = list(common.read_constants('./constants.yaml')[\"sensors\"].values())\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    names=[\"datetime\", \"gesture\"] + sensors,\n",
    "    parse_dates=[\"datetime\"],\n",
    "    date_format='ISO8601',\n",
    ")\n",
    "df['file'] = csv_path\n",
    "X, y, dt = common.make_windows(\n",
    "    df,\n",
    "    20,\n",
    "    constants_path='../src/constants.yaml',\n",
    "    pbar=tqdm.tqdm(total=len(df), desc=\"Making windows\"),\n",
    ")\n",
    "clf = models.load_tf(model_dir)\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f0d02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clf=None\n",
    "@interact(start=(0, len(df), 20), duration=(0, len(df), 20))\n",
    "def fn(start=0, duration=4000):\n",
    "    \n",
    "    fig, axs = plt.subplots(3 if clf is not None else 2, 1, figsize=(10, 5))\n",
    "    for i in range(X.shape[-1]):\n",
    "        axs[0].plot(\n",
    "            X[start:start+duration, 0, i],\n",
    "            alpha=0.5,\n",
    "            c=['tab:red', 'tab:green', 'tab:blue'][i%3],\n",
    "            lw=1,\n",
    "        )\n",
    "    sns.heatmap(\n",
    "        X[start:start+duration, 0, :].T,\n",
    "        cmap='jet',\n",
    "        ax=axs[1],\n",
    "        cbar=False,\n",
    "        vmin=290,\n",
    "        vmax=910,\n",
    "    )\n",
    "\n",
    "    if clf is not None:\n",
    "        sns.heatmap(\n",
    "            y_pred_probs[start-10:start+duration-10, :].T,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            ax=axs[2],\n",
    "            cbar=False,\n",
    "        )\n",
    "        axs[2].set(\n",
    "            ylabel='Predicted\\ngesture',\n",
    "        )\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "    \n",
    "    axs[0].set(\n",
    "        ylabel='Sensor value',\n",
    "        xticks=[],\n",
    "        ylim=(250, 950)\n",
    "    )\n",
    "    axs[1].set(\n",
    "        ylabel='Sensor number',\n",
    "        xticks=[],\n",
    "    )\n",
    "    axs[0].margins(0)\n",
    "    with_clf =' and model predictions' if clf is not None else ''\n",
    "    axs[0].set_title(f'Sensor values{with_clf} over time at {np.round(start/40, 2)}s\\n(duration: {np.round(duration/40, 2)} seconds')\n",
    "#     plt.savefig(\n",
    "#         f'sensors_over_time_{start}_{duration}.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61445582",
   "metadata": {},
   "source": [
    "# Misc Research Chapter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f431f5",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100164fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml'\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14010753",
   "metadata": {},
   "source": [
    "## Correlations between the different gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0\n",
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())\n",
    "X_data = X_trn[y_trn != 50][:, timestep, :]\n",
    "y_data = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    5, 10,\n",
    "    figsize=(40, 20),\n",
    "    dpi=200,\n",
    ")\n",
    "for i in range(5):\n",
    "    print(f'gesture {i}_', flush=True)\n",
    "    for j in range(10):\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(X_data[y_data == (i * 10 + j)]).corr(),\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            ax=axs[i, j],\n",
    "            xticklabels=[s.upper() for s in sensor_names],\n",
    "            yticklabels=[s.upper() for s in sensor_names],\n",
    "            square=True,\n",
    "        )\n",
    "        axs[i, j].set_title(f'Gesture {i * 10 + j}')\n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    pd.DataFrame(X_data).corr(),\n",
    "    vmin=-1, \n",
    "    vmax=1,\n",
    "    center=0,\n",
    "#     cbar=False,\n",
    "    xticklabels=[s.upper() for s in sensor_names],\n",
    "    yticklabels=[s.upper() for s in sensor_names],\n",
    "    square=True,\n",
    ")\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Sensor')\n",
    "plt.title('Correlations between sensors\\n(over all training data)')\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_correlations.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc84849",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axis = ['X', 'Y', 'Z']\n",
    "for i in range(3):\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(X_data[:, i::3]).corr(),\n",
    "        vmin=-1, \n",
    "        vmax=1,\n",
    "        center=0,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        ax=axs[i]\n",
    "    )\n",
    "    axs[i].set_title(f'Correlations between {axis[i]}-axis sensors\\n(over all training data)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f86",
   "metadata": {},
   "source": [
    "## Time-series heatmap + line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_subset(s, f):\n",
    "    df = read.read_data(\n",
    "        '../gesture_data/train/', \n",
    "        constants_path='../src/constants.yaml'\n",
    "    )\n",
    "    df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "    const = common.read_constants('../src/constants.yaml')\n",
    "    sensor_names = list(const['sensors'].values())\n",
    "    data = df[sensor_names].values[s:f]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        data.T,\n",
    "        ax=axs[0],\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    axs[1].plot(\n",
    "        data,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    plt.margins(0)\n",
    "    plt.show()\n",
    "# plt_subset(91_000, 95_000)\n",
    "plt_subset(93_000, 93_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46355c0e",
   "metadata": {},
   "source": [
    "## Histogram of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gidx'].hist()\n",
    "plt.show()\n",
    "df.loc[df['gidx'] != 50, 'gidx'].hist()\n",
    "df['gidx'].value_counts() / len(df['gidx']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da38f",
   "metadata": {},
   "source": [
    "## All observations of one gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de297a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gidx = 0\n",
    "before = 10\n",
    "after = 10\n",
    "idxs = np.nonzero(df['gidx'] == gidx)[0][:, np.newaxis] + np.arange(-before, after+1)\n",
    "\n",
    "vis.cmp_ts(df[sensor_names].values[idxs + 10]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20810d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-before, after+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01077c33",
   "metadata": {},
   "source": [
    "## 3D plot of the raw acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c84cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vals = df[['l5x', 'l5y', 'l5z']].values[:10000]\n",
    "ax.plot(\n",
    "    vals[:, 0], \n",
    "    vals[:, 1], \n",
    "    vals[:, 2], \n",
    "    label='3D Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97194d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6face1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo-venv",
   "language": "python",
   "name": "ergo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
