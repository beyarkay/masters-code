{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69b0d03",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139088",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a2aca",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change directory to keep paths consistent\n",
    "%cd /Users/brk/projects/masters/SU/ergo/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22165a6e",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d078368",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import vis\n",
    "import common\n",
    "import read\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import tqdm\n",
    "import logging as l\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size' : 9,                   # Set font size to 11pt\n",
    "    'axes.labelsize': 9,               # -> axis labels\n",
    "    'legend.fontsize': 9,              # -> legends\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': (            # LaTeX preamble\n",
    "        r'\\usepackage{lmodern}'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbd3fa",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1411",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "def prettify_col_name(x):\n",
    "    return x.split('.')[-1].replace('_', ' ').title()\n",
    "\n",
    "def calculate_prediction_ellipse(x, y, alpha=0.95):\n",
    "    \"\"\"Given some x and y data, calculate the (1-alpha) confidence ellipse.\"\"\"\n",
    "    data = np.column_stack((x, y)) # Combine x and y into a single data array\n",
    "    num_dimensions = data.shape[1]\n",
    "    num_data_points = data.shape[0]\n",
    "    # Estimate the sample covariance matrix\n",
    "    sample_covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Calculate the sample mean for each dimension\n",
    "    sample_mean = np.mean(data, axis=0)\n",
    "    # Generate angles for the ellipse\n",
    "    theta = np.linspace(0, 2*np.pi, num=100)\n",
    "    # Calculate the radius of the ellipse. `f.ppf` is the inverse of the CDF\n",
    "    radius = np.sqrt(\n",
    "        num_dimensions * (num_data_points - 1) / (num_data_points - num_dimensions) *\n",
    "        (1 + 1/num_data_points) * f.ppf(1 - alpha, num_dimensions, num_data_points - num_dimensions)\n",
    "    )\n",
    "#     print(sample_covariance_matrix)\n",
    "    # Compute the Cholesky decomposition of the covariance matrix\n",
    "    chol_cov_matrix = np.linalg.cholesky(sample_covariance_matrix)\n",
    "    # Generate ellipse offset based on Cholesky decomposition\n",
    "    ellipse_offset = np.outer(np.cos(theta), chol_cov_matrix[0, :]) + np.outer(np.sin(theta), chol_cov_matrix[1, :])\n",
    "    # Calculate the points of the prediction interval ellipse\n",
    "    prediction_ellipse_points = sample_mean + radius * ellipse_offset\n",
    "    return prediction_ellipse_points\n",
    "\n",
    "def get_npz_data_from_model(model_dir):\n",
    "    \"\"\"Given a directory of a model, return it's y_pred and y_true.\"\"\"\n",
    "    data = np.load(f'{model_dir}/y_val_true_y_val_pred.npz')\n",
    "    y_true = data['y_true']\n",
    "    y_pred = data['y_pred']\n",
    "    return y_true, y_pred\n",
    "\n",
    "def show_conf_mat_from_model(model_dir, ax=None):\n",
    "    \"\"\"Given a directory of a model, plot its confidence matrix\"\"\"\n",
    "    y_true, y_pred = get_npz_data_from_model(model_dir)\n",
    "    cm_val = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    p = vis.conf_mat(cm_val / cm_val.sum(axis=0), ax=ax)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46788",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab12f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data from hpar optimisation\n",
    "paths = sorted(glob.glob('../saved_models/results_*_optuna.jsonl'))\n",
    "print(f'Reading data from\\n', \"\\n\".join(paths))\n",
    "dfs = map(\n",
    "    lambda path: pd.read_json(path, lines=True),\n",
    "    paths\n",
    ")\n",
    "# Concat the dataframes together, and then do a \n",
    "# copy to avoid a dataframe fragmentation warning\n",
    "# Reset the index to avoid a seaborn error https://github.com/mwaskom/seaborn/issues/3291\n",
    "df = pd.concat(dfs).reset_index(drop=True).copy()\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].fillna('51')\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].astype(int).astype(str)\n",
    "\n",
    "# 50-class HFFNNs don't make sense, remove them\n",
    "df = df[~(\n",
    "    (df['model_type'] == 'HFFNN')\n",
    "    & (df['preprocessing.num_gesture_classes'] == '50')\n",
    ")]\n",
    "\n",
    "df.groupby(['model_type', 'preprocessing.num_gesture_classes']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7801a6",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colours = {\n",
    "    'FFNN': 'tab:blue',\n",
    "    'HFFNN': 'tab:orange',\n",
    "    'CuSUM': 'tab:green',\n",
    "    'HMM': 'tab:red',\n",
    "    'SVM': 'tab:purple',\n",
    "}\n",
    "palette = 'Spectral'\n",
    "other_colours = [\n",
    "    'tab:brown',\n",
    "    'tab:pink',\n",
    "    'tab:grey',\n",
    "    'tab:olive',\n",
    "    'tab:cyan',\n",
    "]\n",
    "WIDTH = 5.5\n",
    "\n",
    "rename_hpars = {\n",
    "    'ffnn.dropout_rate'            : 'Dropout Rate',\n",
    "    'ffnn.l2_coefficient.log10'    : 'L2 ($\\log_{10}$)',\n",
    "    'nn.batch_size.log10'          : 'Batch Size ($\\log_{10}$)',\n",
    "    'nn.learning_rate.log10'       : 'LR ($\\log_{10}$)',\n",
    "    'ffnn.l2_coefficient'          : 'L2 Coef.',\n",
    "    'nn.batch_size'                : 'Batch Size',\n",
    "    'nn.learning_rate'             : 'LR',\n",
    "    'ffnn.num_layers'              : '\\#Layers',\n",
    "    'ffnn.nodes_per_layer.1'       : '\\#Nodes (layer 1)',\n",
    "    'ffnn.nodes_per_layer.2'       : '\\#Nodes (layer 2)',\n",
    "    'ffnn.nodes_per_layer.3'       : '\\#Nodes (layer 3)',\n",
    "    'ffnn.nodes_per_layer.-1'      : '\\#Nodes (last layer)',\n",
    "    'ffnn.nodes_per_layer.1.log10' : '\\#Nodes (layer 1, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.2.log10' : '\\#Nodes (layer 2, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.3.log10' : '\\#Nodes (layer 3, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.-1.log10': '\\#Nodes (last layer, $\\log_{10}$)',\n",
    "    'val.macro avg.f1-score'       : '$F_1$-score',\n",
    "    'val.macro avg.recall'         : 'Recall',\n",
    "    'val.macro avg.precision'      : 'Precision',\n",
    "    'val.loss.log10'               : 'Val. Loss ($\\log_{10}$)',\n",
    "    'trn.loss.log10'               : 'Trn. Loss ($\\log_{10}$)',\n",
    "    'val.loss'                     : 'Val. Loss',\n",
    "    'trn.loss'                     : 'Trn. Loss',\n",
    "}\n",
    "# Add rename cols for the HFFNNs\n",
    "rename_hpars |= {\n",
    "    f'hffnn.majority.{k}': f'Maj. {v}' for k, v in rename_hpars.items() if 'nn.' in k\n",
    "} | {\n",
    "    f'hffnn.minority.{k}': f'Min. {v}' for k, v in rename_hpars.items() if 'nn.' in k\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1f85",
   "metadata": {},
   "source": [
    "## Calculate some auxillary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18c065",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data a little bit, and get a list of dependant variables\n",
    "# Preprocess the df a bit to get some nice-to-use columns\n",
    "\n",
    "# Convert nodes_per_layer into nodes_per_layer.1, .2, .3\n",
    "prefixes = (\n",
    "    'ffnn.nodes_per_layer',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer',\n",
    ")\n",
    "for prefix in prefixes:\n",
    "    for i in (1, 2, 3):\n",
    "        df[f'{prefix}.{i}'] = df[prefix].apply(\n",
    "            lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else None\n",
    "        )\n",
    "    df[f'{prefix}.-1'] = df[prefix].apply(\n",
    "        lambda x: x[-1] if isinstance(x, list) and len(x) >= 1 else None\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate ratios\n",
    "avgs = ('macro avg', 'weighted avg')\n",
    "metrics = ('f1-score', 'precision', 'recall')\n",
    "\n",
    "for avg in avgs:\n",
    "    for metric in metrics:\n",
    "        df[f'ratio.{avg}.{metric}'] = df[f'trn.{avg}.{metric}'] / df[f'val.{avg}.{metric}']\n",
    "        df[f'ratio.{avg}.{metric}'] = np.where(\n",
    "            np.isfinite(df[f'ratio.{avg}.{metric}']),\n",
    "            df[f'ratio.{avg}.{metric}'],\n",
    "            np.nan\n",
    "        )\n",
    "df['ratio.loss'] = df['trn.loss'] / df['val.loss']\n",
    "\n",
    "# Print out a list of dependant variables\n",
    "# dep_vars = sorted([\n",
    "#     c for c in df.columns \n",
    "#     if 'val' not in c and 'trn' not in c and 'ratio' not in c and c not in (\n",
    "#         'saved_at', 'fit_time', 'preprocessing.gesture_allowlist', \n",
    "# )], key=lambda c: str(c))\n",
    "# print(f\"Dependant variables: {dep_vars}\")\n",
    "# print(\"\\nVariables which change:\")\n",
    "# max_len = max(map(lambda x: len(x), dep_vars))\n",
    "# Print out all dependant variables that change\n",
    "# for var in dep_vars:\n",
    "#     uniq = df[var].apply(lambda x: str(x) if isinstance(x, list) else x).unique()\n",
    "#     if len(uniq) > 1:\n",
    "#         print(f\"{var: <{max_len}} {uniq}\")\n",
    "        \n",
    "df['ffnn.dropout_rate'] = np.round(df['ffnn.dropout_rate'], 6)\n",
    "\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['trn.pred_time_per_obs'] = df['trn.pred_time'] / df['trn.num_observations']\n",
    "df['fit_time_per_obs'] = df['fit_time'] / df['trn.num_observations']\n",
    "\n",
    "\n",
    "# Add some log10 columns\n",
    "log10_cols = [\n",
    "    'val.loss',\n",
    "    'trn.loss',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    "    'ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.majority.ffnn.l2_coefficient',\n",
    "    'hffnn.minority.ffnn.l2_coefficient',\n",
    "    'hffnn.majority.nn.batch_size',\n",
    "    'hffnn.minority.nn.batch_size',\n",
    "    'hffnn.majority.nn.learning_rate',\n",
    "    'hffnn.minority.nn.learning_rate',\n",
    "]\n",
    "\n",
    "df[[f'{c}.log10' for c in log10_cols]] = np.log10(df[log10_cols])\n",
    "# df[[f'{c}.log10' for c in log10_cols]] = df[[f'{c}.log10' for c in log10_cols]].fillna(0)\n",
    "\n",
    "for c in log10_cols:\n",
    "    if df[f'{c}.log10'].isna().any():\n",
    "        print(f\"{df[f'{c}.log10'].isna().sum()} NaNs in {c}.log10\")\n",
    "\n",
    "# There are a *lot* of columns. Here's a more-useful subset\n",
    "subset_cols = [\n",
    "    c for c in df.columns\n",
    "    if (not re.search(r'((trn|val)\\.\\d+\\.)|weighted avg', c)) and \n",
    "        (c not in [\n",
    "            'hmm', 'lstm', 'ffnn', 'nn', 'hffnn', 'cusum', 'svm',\n",
    "            'preprocessing.n_timesteps',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "        ])\n",
    "]\n",
    "\n",
    "df['ffnn.num_layers'] = df['ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")\n",
    "df['hffnn.majority.ffnn.num_layers'] = df['hffnn.majority.ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")\n",
    "df['hffnn.minority.ffnn.num_layers'] = df['hffnn.minority.ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df['model_type'] == \"FFNN\")\n",
    "    & (df['preprocessing.num_gesture_classes'] == '51')\n",
    "].groupby('ffnn.num_layers').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5643dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "fig, axs = plt.subplots(3, 1, figsize=(WIDTH, WIDTH))\n",
    "ngestures = ('51', '50', '5')\n",
    "xmin = None\n",
    "xmax = None\n",
    "for ax, ngesture in zip(axs, ngestures):\n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == ngesture],\n",
    "        x='saved_at',\n",
    "        y='preprocessing.seed',\n",
    "        hue='model_type',\n",
    "        s=10,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "    #     alpha=0.1,\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    ax.set_title(f'{ngesture} gestures')\n",
    "#     if xmin is None: xmin = ax.get_xlim()[0]\n",
    "#     if xmax is None: xmax = ax.get_xlim()[1]\n",
    "#     xmin = min(xmin, ax.get_xlim()[0])\n",
    "#     xmax = min(xmax, ax.get_xlim()[1])\n",
    "# for ax in axs:\n",
    "#     ax.set_xlim((xmin, xmax))\n",
    "plt.tight_layout()\n",
    "\n",
    "print(df.shape)\n",
    "df = df[\n",
    "    (df['model_type'] != 'HFFNN')\n",
    "    | (df['saved_at'] > pd.to_datetime('2023-10-01T11:00:00'))\n",
    "]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eeb4a",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a664e",
   "metadata": {},
   "source": [
    "## Bar plot of number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f504e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "counts = pd.Series(y_trn).value_counts()\n",
    "axs[0].bar(counts.index, counts)\n",
    "\n",
    "\n",
    "counts = pd.Series(y_trn[y_trn != 50]).value_counts()\n",
    "axs[1].bar(counts.index, counts)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Number of classes\\n',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Number of classes\\n(excluding class 50)',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_class_imbalance.pdf',\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c94d8c",
   "metadata": {},
   "source": [
    "## Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4427f33",
   "metadata": {},
   "source": [
    "### 51 classes, Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.1, 1, 10), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    "    edgecolor=None,\n",
    "    legend=False,\n",
    ")\n",
    "axs[0].set_xlim((-0.1, 1.1))\n",
    "axs[0].set_ylim((-0.1, 1.1))\n",
    "axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0].set_title(f'Precision vs Recall\\n51-classes')\n",
    "axs[0].set_xlabel(f'Precision')\n",
    "axs[0].set_ylabel(f'Recall')\n",
    "# axs[0].legend().set_title(\"Model \")\n",
    "\n",
    "\n",
    "order = ['FFNN', 'SVM', 'HFFNN', 'HMM', 'CuSUM']\n",
    "sns.stripplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='model_type',\n",
    "    s=2,\n",
    "    alpha=0.5,\n",
    "#     order=list(model_colours.keys()),\n",
    "    order=order,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     hue_order=order,\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "axs[1].set_title(f'$F_1$-score\\n51-classes')\n",
    "axs[1].set_xlabel(f'Model Type')\n",
    "axs[1].set_ylabel(f'$F_1$-score')\n",
    "axs[1].set_ylim((-0.1, 1.1))\n",
    "axs[1].grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_51_classes.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "data = df.loc[\n",
    "    df['preprocessing.num_gesture_classes'] == '51',\n",
    "    ['model_type', 'val.macro avg.recall', 'val.macro avg.precision']\n",
    "].melt(\n",
    "    id_vars=['model_type'], \n",
    "    var_name='metric', \n",
    "    value_name='value'\n",
    ")\n",
    "data['metric'] = data['metric'].replace({\n",
    "    'val.macro avg.recall': 'Recall',\n",
    "    'val.macro avg.precision': 'Precision',\n",
    "})\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x=\"model_type\", \n",
    "    y=\"value\", \n",
    "    hue=\"metric\",\n",
    "    order=list(model_colours.keys()),\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    alpha=0.75,\n",
    "    size=2,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "\n",
    "ax.set_title(f'Precision and recall for all model types')\n",
    "ax.set_xlabel(f'Model Type')\n",
    "ax.set_ylabel(f'Metric Value')\n",
    "ax.legend().set_title(\"Metric\")\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "ax.set_yticklabels(np.round(np.arange(0, 1.1, .1), 1))\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_stripplot.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1b84",
   "metadata": {},
   "source": [
    "### Precision vs Recall for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760213ee",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3.))\n",
    "n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for ax, n_classes in zip(axs, n_gesture_classes):\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 5), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == n_classes],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=2.5,\n",
    "        alpha=0.5,\n",
    "        hue='model_type',\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    ax.set_xlim((-0.1, 1.1))\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{n_classes} gesture classes')\n",
    "#     ax.legend().set_title('Model Type')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "# n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for model_type in model_colours.keys():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "    \n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['model_type'] == model_type],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=10,\n",
    "#         alpha=0.5,\n",
    "        hue='preprocessing.num_gesture_classes',\n",
    "        style='preprocessing.num_gesture_classes',\n",
    "        hue_order=['5', '50', '51'],\n",
    "        style_order=['5', '50', '51'],\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    ax.set_xlim((-0.05, 1.05))\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{model_type} $F_1$-score by number of classes')\n",
    "    ax.legend().set_title('Number of classes')\n",
    "    \n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_f1_by_num_gesture_classes_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77f603",
   "metadata": {},
   "source": [
    "## Best model by highest lower 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109bfea",
   "metadata": {
    "code_folding": [
     14
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight'],\n",
    "}\n",
    "\n",
    "def tenth_conf_interval(series):\n",
    "    mean = np.mean(series)\n",
    "    sem = stats.sem(series)\n",
    "    if sem == 0:\n",
    "        return mean\n",
    "    confidence_interval = stats.t.interval(\n",
    "        0.90, \n",
    "        len(series) - 1, \n",
    "        loc=mean, \n",
    "        scale=sem\n",
    "    )\n",
    "#     print(mean, sem, confidence_interval)\n",
    "    return confidence_interval[0]\n",
    "\n",
    "\n",
    "all_hpars = ['model_type'] + [\n",
    "    item \n",
    "    for sublist in list(type_to_hpars.values()) \n",
    "    for item in sublist\n",
    "]\n",
    "\n",
    "subset = df[(df['preprocessing.num_gesture_classes'] == '51')]\n",
    "# print(subset.shape)\n",
    "gb = subset.groupby(all_hpars, dropna=False)\n",
    "subset['val.macro avg.f1-score.count'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "subset = subset[\n",
    "    subset['val.macro avg.f1-score.count'].between(5, 100)\n",
    "]\n",
    "\n",
    "subset['val.macro avg.f1-score.tenth_conf_interval'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform(tenth_conf_interval)\n",
    ")\n",
    "subset['val.macro avg.f1-score.mean']  = gb['val.macro avg.f1-score'].transform('mean')\n",
    "subset['val.macro avg.f1-score.min']   = gb['val.macro avg.f1-score'].transform('min')\n",
    "subset['val.macro avg.f1-score.max']   = gb['val.macro avg.f1-score'].transform('max')\n",
    "subset['val.macro avg.f1-score.std']   = gb['val.macro avg.f1-score'].transform('std')\n",
    "subset['val.macro avg.f1-score.count'] = gb['val.macro avg.f1-score'].transform('count')\n",
    "\n",
    "subset['group_idx'] = gb.ngroup()\n",
    "subset = subset.sort_values('val.macro avg.f1-score.tenth_conf_interval')\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccbc02",
   "metadata": {},
   "source": [
    "### Plot models grouped by hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH/5.))\n",
    "\n",
    "order = subset.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval'\n",
    ")['group_idx'].unique()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=subset,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "    order=order,\n",
    "    size=5,\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=subset, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=5, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='$F_1$ score for each set of hyperparameters, by model type',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    "    ylim=((-0.05, 1.05))\n",
    ")\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(\n",
    "    order,\n",
    "    rotation=90,\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.add_artist(plt.legend(handles[:-5], labels[:-5], title=\"Model Type\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "# data = subset[subset['val.macro avg.f1-score.tenth_conf_interval'] > 0.7]\n",
    "data = subset.sort_values('val.macro avg.f1-score.tenth_conf_interval').tail(250)\n",
    "\n",
    "order = data.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval'\n",
    ")['group_idx'].unique()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "    order=order,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    size=5,\n",
    "    jitter=False,\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=data, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=5, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title=f'$F_1$ score for top {len(order)} hyperparameters',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    ")\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(\n",
    "    order,\n",
    "    rotation=90,\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.add_artist(plt.legend(handles[:5], labels[:5], title=\"Model Type\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_best_hpar_comparison.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c67d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best model:\")\n",
    "from pprint import pprint\n",
    "pprint(\n",
    "    subset\n",
    "    .sort_values('val.macro avg.f1-score.tenth_conf_interval', ascending=False)\n",
    "    .groupby('group_idx')\n",
    "    .tail(1)\n",
    "#     [type_to_hpars['FFNN']]\n",
    "    .head(1)\n",
    "    .squeeze()\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea557ab",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "model_type = 'FFNN'\n",
    "\n",
    "def prettify_col(col):\n",
    "    return {\n",
    "        'val.macro avg.f1-score.mean': '$F_1$-score Mean',\n",
    "        'val.macro avg.f1-score.std': '$F_1$-score Std.Dev.',\n",
    "        'group_idx': 'Index',\n",
    "        'cusum.thresh': 'Threshold',\n",
    "        'ffnn.dropout_rate': 'Dropout Rate',\n",
    "        'ffnn.l2_coefficient': 'L2 Coefficient',\n",
    "        'ffnn.l2_coefficient.log10': '$\\log_{10}(\\text{L2 Coefficient})$',\n",
    "        'ffnn.nodes_per_layer.1': 'Nodes (layer 1)',\n",
    "        'ffnn.nodes_per_layer.2': 'Nodes (layer 2)',\n",
    "        'ffnn.nodes_per_layer.3': 'Nodes (layer 3)',\n",
    "        'hffnn.majority.ffnn.dropout_rate': 'Majority: Dropout Rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient': 'Majority: L2 Coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1': 'Majority: Nodes (layer 1)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2': 'Majority: Nodes (layer 2)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3': 'Majority: Nodes (layer 3)',\n",
    "        'hffnn.majority.nn.batch_size': 'Majority: Batch Size',\n",
    "        'hffnn.majority.nn.epochs': 'Majority: Epochs',\n",
    "        'hffnn.majority.nn.learning_rate': 'Majority: Learning Rate',\n",
    "        'hffnn.majority.nn.optimizer': 'Majority: Optimizer',\n",
    "        'hffnn.minority.ffnn.dropout_rate': 'Minority: Dropout Rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient': 'Minority: L2 Coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1': 'Minority: Nodes (layer 1)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2': 'Minority: Nodes (layer 2)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3': 'Minority: Nodes (layer 3)',\n",
    "        'hffnn.minority.nn.batch_size': 'Minority: Batch Size',\n",
    "        'hffnn.minority.nn.epochs': 'Minority: Epochs',\n",
    "        'hffnn.minority.nn.learning_rate': 'Minority: Learning Rate',\n",
    "        'hffnn.minority.nn.optimizer': 'Minority: Optimizer',\n",
    "        'hmm.covariance_type': 'Covariance Type',\n",
    "        'nn.batch_size': 'Batch Size',\n",
    "        'nn.batch_size.log10': '$\\log_{10}(\\text{Batch Size})$',\n",
    "        'nn.epochs': 'Epochs',\n",
    "        'nn.learning_rate': 'Learning Rate',\n",
    "        'nn.learning_rate.log10': '$\\log_{10}(\\text{Learning Rate})$',\n",
    "        'nn.optimizer': 'Optimizer',\n",
    "        'svm.c': 'C',\n",
    "        'svm.class_weight': 'Class Weight',\n",
    "    }.get(col, col)\n",
    "\n",
    "def df_to_latex(df, model_type):\n",
    "    path = f'../../report/src/tables/05_best_{model_type.lower().replace(\" \", \"_\")}_hpars.generated.tex'\n",
    "    print('DONT FORGET TO UPDATE LaTeX tables: ', path)\n",
    "    df.to_latex(\n",
    "        path,\n",
    "        caption=f'Top {len(df)} performing {model_type} hyperparameter combinations, ordered by '\n",
    "                f'the lower bound of the 90 percent confidence interval for $F_1$-score.',\n",
    "        label=f'tab:05_best_{model_type.lower().replace(\" \", \"_\")}_hpars',\n",
    "        index=False,\n",
    "        float_format=lambda x: '%.3e' % x,\n",
    "        na_rep='-'\n",
    "    )\n",
    "\n",
    "for model_type in type_to_hpars.keys():\n",
    "    latex_df = (\n",
    "        subset[\n",
    "            subset['model_type'] == model_type\n",
    "        ]\n",
    "        .sort_values('val.macro avg.f1-score.tenth_conf_interval', ascending=False)\n",
    "        .groupby('group_idx')\n",
    "        .tail(1)\n",
    "        [\n",
    "            ['group_idx', 'val.macro avg.f1-score.mean', 'val.macro avg.f1-score.std'] \n",
    "            + type_to_hpars[model_type]\n",
    "        ]\n",
    "        .head(10)\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns=prettify_col)\n",
    "        .replace({\n",
    "            'tied': 'Tied',\n",
    "            'spherical': 'Spherical',\n",
    "            'diag': 'Diagonal',\n",
    "            'full': 'Full',\n",
    "            'balanced': 'Balanced',\n",
    "        } | {} if model_type != 'SVM' else {\n",
    "            np.nan: 'Unbalanced',\n",
    "        } | {} if model_type not in ('HFFNN', 'FFNN') else {\n",
    "            np.nan: 'None',\n",
    "        })\n",
    "    )\n",
    "    display(latex_df)\n",
    "    \n",
    "    if model_type == 'HFFNN':\n",
    "        majority = latex_df[[c for c in latex_df.columns if 'Minority' not in c]]\n",
    "        minority = latex_df[[c for c in latex_df.columns if 'Majority' not in c]]\n",
    "        majority.columns = [c.replace(\"Majority: \", \"\") for c in majority.columns]\n",
    "        minority.columns = [c.replace(\"Minority: \", \"\") for c in minority.columns]\n",
    "        df_to_latex(majority, 'Majority HFFNN')\n",
    "        df_to_latex(minority, 'Minority HFFNN')\n",
    "    else:\n",
    "        df_to_latex(latex_df, model_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416b3d4",
   "metadata": {},
   "source": [
    "### Model types grouped by hpar index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2534f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "fig = plt.figure(figsize=(WIDTH, WIDTH))\n",
    "gs = GridSpec(4, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "ax3 = fig.add_subplot(gs[2, :])\n",
    "ax4 = fig.add_subplot(gs[3, 0])\n",
    "ax5 = fig.add_subplot(gs[3, 1])\n",
    "\n",
    "model_axs = {\n",
    "    'FFNN':  ax1,\n",
    "    'HFFNN': ax2,\n",
    "    'SVM':   ax3,\n",
    "    'HMM':   ax4,\n",
    "    'CuSUM': ax5,\n",
    "}\n",
    "\n",
    "for model_type, color in model_colours.items():\n",
    "    ax = model_axs[model_type]\n",
    "    data = subset[subset['model_type'] == model_type]\n",
    "    \n",
    "    order = data.sort_values(\n",
    "        'val.macro avg.f1-score.tenth_conf_interval'\n",
    "    )['group_idx'].unique()\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='group_idx',\n",
    "#         hue='model_type',\n",
    "        color=color,\n",
    "        order=order,\n",
    "        size=5,\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "        jitter=False,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    sns.pointplot(\n",
    "        data=data, \n",
    "        x=\"group_idx\", \n",
    "        y=\"val.macro avg.f1-score\", \n",
    "        hue=\"model_type\",\n",
    "        linestyle=\"none\", \n",
    "        errorbar=None,\n",
    "        marker=\"_\", \n",
    "        markersize=5, \n",
    "        palette='dark:black',\n",
    "        markeredgewidth=1,\n",
    "        zorder=10,\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "    )\n",
    "    \n",
    "    ax.set(\n",
    "        title=f'$F_1$-score for each set of {model_type} hyperparameters',\n",
    "        xlabel='Hyperparameter index',\n",
    "        ylabel='$F_1$-score',\n",
    "        ylim=((-0.05, 1.05)),\n",
    "    )\n",
    "    ax.yaxis.grid(True)\n",
    "#     ax.set_xticks(ax.get_xticks())\n",
    "#     ax.set_xticklabels(order, rotation=90)\n",
    "\n",
    "    xticks = ax.get_xticks()\n",
    "    if len(xticks) > 10:\n",
    "        ax.set_xticks([xticks[i] for i in range(len(xticks)) if i % 4 == 0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_hpar_comparison_per_model_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102c42e",
   "metadata": {},
   "source": [
    "## Get statistics for each hyperparameter combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') & \n",
    "    (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "    (df['preprocessing.seed'] == 42.0)\n",
    "]\n",
    "\n",
    "data[[c for c in subset_cols if 'ffnn.' in c or 'nn.' in c]].head(31)\n",
    "data[subset_cols].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713a7c1",
   "metadata": {},
   "source": [
    "## ECDF for all model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "for model_type, color in model_colours.items():\n",
    "    scores = df.loc[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type),\n",
    "        'val.macro avg.f1-score'\n",
    "    ]\n",
    "    sorted_scores = np.sort(scores)\n",
    "    ecdf = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "    ax.plot(sorted_scores, ecdf, color=color, label=model_type)\n",
    "plt.legend()\n",
    "ax.set(\n",
    "    title='ECDF for all model types',\n",
    "    xlabel='$F_1$-score',\n",
    "    ylabel='Cumulative Probability',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ec2db",
   "metadata": {},
   "source": [
    "## Training vs Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ba735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'])\n",
    "df['trn.pred_time_per_obs.log10'] = np.log10(df['trn.pred_time_per_obs'])\n",
    "df['fit_time_per_obs.log10'] = np.log10(df['fit_time_per_obs'])\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs.log10',\n",
    "    y='trn.pred_time_per_obs.log10',\n",
    "    s=10,\n",
    "#     alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    x='fit_time_per_obs.log10',\n",
    "    y='trn.pred_time_per_obs.log10',\n",
    "    s=10,\n",
    "#     alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation vs training inference time',\n",
    "    xlabel='Validation inference time\\n($\\log_{10}$ seconds/observation)',\n",
    "    ylabel='Training inference time\\n($\\log_{10}$ seconds/observation)',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Fitting vs inference time',\n",
    "    xlabel='Fitting time\\n($\\log_{10}$ seconds/observation)',\n",
    "    ylabel='Inference Time\\n($\\log_{10}$ seconds/observation)',\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_trn_times_per_obs.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473064",
   "metadata": {},
   "source": [
    "## Inference time vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=ax,\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "ax.set_ylabel('$F_1$-score')\n",
    "ax.set_xlabel('Inference time\\n($\\log_{10}$ seconds/observation)')\n",
    "ax.set_title('Inference time per observation against $F_1$ score')\n",
    "ax.legend().set_title(\"Model Type\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inference_time_per_obs_vs_f1.pdf', \n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0978408",
   "metadata": {},
   "source": [
    "## Confusion Matrices of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngestures = sorted(df['preprocessing.num_gesture_classes'].unique())\n",
    "model_types = sorted(df['model_type'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(ngestures),\n",
    "    len(model_types),\n",
    "    # TODO this ratio might need to be swapped\n",
    "    figsize=(WIDTH, WIDTH * len(model_types) / len(ngestures)),\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "for i, ngesture in enumerate(ngestures):\n",
    "    for j, model_type in enumerate(model_types):\n",
    "        best = df[\n",
    "            (df['preprocessing.num_gesture_classes'] == ngesture) &\n",
    "            (df['model_type'] == model_type)\n",
    "        ].sort_values('val.macro avg.f1-score', ascending=False)\n",
    "        if len(best) == 0:\n",
    "            axs[i,j].axis('off')\n",
    "            continue\n",
    "        best = best.iloc[0]\n",
    "        print(ngesture, model_type, best['model_dir'])\n",
    "        try:\n",
    "            show_conf_mat_from_model(f\"../{best['model_dir']}\", axs[i, j])\n",
    "        except FileNotFoundError:\n",
    "            show_conf_mat_from_model(f\"./{best['model_dir']}\", axs[i, j])\n",
    "        axs[i, j].set(\n",
    "            title=f\"Best {model_type}: {ngesture} gestures\\n($F_1=${np.round(best['val.macro avg.f1-score'], 4)})\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55659bd",
   "metadata": {},
   "source": [
    "## Mean Confidence Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b53dd5",
   "metadata": {},
   "source": [
    "### 5 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '5'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat[-1, -1] = 0\n",
    "#     conf_mat /= conf_mat_totals[hpar_item]\n",
    "#     conf_mat /= conf_mat.max()\n",
    "#     print(conf_mat_totals[hpar_item])\n",
    "    # Normalize the matrix manually to get nicer annotations\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57977c1",
   "metadata": {},
   "source": [
    "### 50 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1706876",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '50'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "#     vis.conf_mat(conf_mat, ax=axs[i])\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbdd51",
   "metadata": {},
   "source": [
    "### 51 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da56ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = '51'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    try:\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    except FileNotFoundError:\n",
    "        y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90935c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    3, 2,\n",
    "    figsize=(WIDTH, WIDTH*3/2)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "axs[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73941aa8",
   "metadata": {},
   "source": [
    "## Conf Mats for each num-gesture-class with precision-recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score_grid = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "\n",
    "for model_type in ('FFNN', 'HFFNN', 'SVM', 'CuSUM', 'HMM'):\n",
    "    data = df[\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "\n",
    "    hpar = 'preprocessing.num_gesture_classes'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "    print(model_type, flush=True)\n",
    "\n",
    "    for i, row in data.sort_values(hpar).iterrows():\n",
    "        try:\n",
    "            y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        except FileNotFoundError:\n",
    "            y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        f1_score = sklearn.metrics.f1_score(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] += f1_score\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] = f1_score\n",
    "        if i % 100 == 0:\n",
    "            print(i, end=' ', flush=True)\n",
    "\n",
    "    if model_type == 'HFFNN':\n",
    "        fig, axs = plt.subplots(\n",
    "            1, 2,\n",
    "            figsize=(WIDTH, WIDTH*.5),\n",
    "            squeeze=False,\n",
    "        )\n",
    "    else:\n",
    "        fig, axs = plt.subplots(\n",
    "            2, 2,\n",
    "            figsize=(WIDTH, WIDTH),\n",
    "            squeeze=False,\n",
    "        )\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "        cmat = conf_mat / conf_mat_totals[hpar_item]\n",
    "        vis.conf_mat(cmat, ax=axs[i])\n",
    "        axs[i].set_title(\n",
    "            f'Weighted Confusion Matrix\\n'\n",
    "            f'{model_type} {hpar_item}-class'\n",
    "        )\n",
    "\n",
    "    contours = axs[-1].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score_grid, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[-1].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['model_type'] == model_type],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        hue='preprocessing.num_gesture_classes',\n",
    "        style='preprocessing.num_gesture_classes',\n",
    "        hue_order=['5', '50', '51'],\n",
    "        style_order=['5', '50', '51'],\n",
    "        ax=axs[-1],\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    axs[-1].set(\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        title=f'{model_type} $F_1$-score by number of classes',\n",
    "    )\n",
    "    axs[-1].plot([0,1], [0,1], color='black', alpha=.25)\n",
    "    axs[-1].legend().set_title('Classes')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_mean_conf_mat_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1fc7b",
   "metadata": {},
   "source": [
    "## Regularization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gesture_classes = (\n",
    "    '5',\n",
    "    '50',\n",
    "    '51',\n",
    ")\n",
    "# TODO this ratio might need to be changed\n",
    "fig, axs = plt.subplots(\n",
    "    3, 2, \n",
    "    figsize=(WIDTH, WIDTH/3.)\n",
    ")\n",
    "\n",
    "for i, ngestures in enumerate(n_gesture_classes):\n",
    "    data = df[df['preprocessing.num_gesture_classes'] == ngestures]\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.l2_coefficient',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 0]\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 1]\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{ngestures} gestures')\n",
    "    axs[i, 1].set_title(f'{ngestures} gestures')\n",
    "\n",
    "plt.suptitle(\"$F_1$-ratio against regularisation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3fa2",
   "metadata": {},
   "source": [
    "## Ratio $F_1$ scores vs actual $F_1$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "axs[0, 0].set_xlim((-0.05, 1.05))\n",
    "axs[0, 0].set_ylim((-0.05, 1.05))\n",
    "axs[0, 0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 0].set_title(\"a) Training vs Validation $F_1$ score\\n\")\n",
    "axs[0, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 0].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 0].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "axs[0, 1].set_xlim((0.5, 1.05))\n",
    "axs[0, 1].set_ylim((0.5, 1.05))\n",
    "axs[0, 1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 1].set_title(\"b) Training vs Validation $F_1$ score\\n(magnified)\")\n",
    "axs[0, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 1].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 1].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "axs[1, 0].set_xlim((-0.05, 1.05))\n",
    "axs[1, 0].set_title(\"c) $F_1$-ratio vs $F_1$-score\\n\")\n",
    "axs[1, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 0].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 0].legend().set_title('Model Type')\n",
    "axs[1, 0].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['val.macro avg.f1-score'] >= 0.5)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "axs[1, 1].set_xlim((0.5, 1.05))\n",
    "axs[1, 1].set_title(\"d) $F_1$-ratio vs $F_1$-score\\n(magnified)\")\n",
    "axs[1, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 1].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 1].legend().set_title('Model Type')\n",
    "axs[1, 1].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_f1_vs_f1_ratio.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcf2e4",
   "metadata": {},
   "source": [
    "## Training/validation loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss',\n",
    "    x='trn.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].assign(**{\n",
    "        'ratio.loss': lambda x: x['trn.loss'] / x['val.loss']\n",
    "    }),\n",
    "    x='ratio.loss',\n",
    "    y='val.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "\n",
    "axs[0].set_ylim((-0.05, 3.6))\n",
    "axs[1].set_ylim((-0.05, 3.6))\n",
    "\n",
    "axs[1].plot([1, 1], [0, axs[1].get_ylim()[1]], color='black', alpha=.1)\n",
    "\n",
    "min_max = min(axs[0].get_xlim()[1], axs[0].get_ylim()[1] )\n",
    "axs[0].plot([0, min_max], [0, min_max], color='black', alpha=.1)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation loss vs training loss\\n(FFNN only)',\n",
    "    xlabel='Training Loss',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Validation loss vs loss ratio\\n(FFNN only)',\n",
    "    xlabel=r'Loss ratio ($\\frac{Training}{Validation}$)',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_val_trn_loss_ratios.pdf'\n",
    ")\n",
    "\n",
    "print(\"TODO: The training and validation loss aren't comparable because the training loss is weighed but validation loss is not.\")\n",
    "print(\"TODO: also not comparable because of dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f5df8",
   "metadata": {},
   "source": [
    "## Precision vs Recall plots for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, color in model_colours.items():\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "    print(f\"{p_min=}, {p_max=}, {r_min=}, {r_max=}, \")\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    print(f1_score.min())\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            10\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    ax.set(\n",
    "        title=f\"Precision vs Recall For {model_type} models\\n($F_1$ contours in grey)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_{model_type.lower()}_p_vs_r.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6c5d8",
   "metadata": {},
   "source": [
    "## In depth FFNN plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "]\n",
    "hyperpars = [\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "    'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "data['Recall $>$ 0.7'] = data['val.macro avg.recall'] > 0.7\n",
    "\n",
    "data['ffnn.nodes_per_layer.1.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.2.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.3.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.-1.log10'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831940f",
   "metadata": {},
   "source": [
    "### x=precision y=recall hue=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b69770",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    hue='ffnn.num_layers',\n",
    "    s=10,\n",
    "    edgecolor='black',\n",
    "#     alpha=0.75,\n",
    "    legend=False,\n",
    "    palette=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    ax=axs[1]\n",
    ")\n",
    "# vis.fmt_legend(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "axs[1].set(\n",
    "    xticks=np.arange(0, 1.01, 0.2),\n",
    "    yticks=np.arange(0, 1.01, 0.2),\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='ffnn.num_layers',\n",
    "    hue='ffnn.num_layers',\n",
    "    palette=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    legend=False,\n",
    "    s=2.5,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    "    native_scale=True,\n",
    "    edgecolor='black',\n",
    ")\n",
    "axs[0].set(\n",
    "    xlim=(0, 4),\n",
    "    xticks=[1, 2, 3],\n",
    "    yticks=np.arange(0, 1.01, 0.2),\n",
    ")\n",
    "vis.add_grid(axs[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac82fd",
   "metadata": {},
   "source": [
    "### x=hpar y=recall, all hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8f588",
   "metadata": {
    "code_folding": [
     2,
     3,
     28
    ]
   },
   "outputs": [],
   "source": [
    "aspect=2\n",
    "g = sns.catplot(\n",
    "    data=vis.add_jitter(data, hyperpars).melt( \n",
    "#         data=data[data['ffnn.num_layers'] == nlayers].melt( \n",
    "        id_vars=['Recall $>$ 0.7'], \n",
    "        value_vars=hyperpars,\n",
    "    ), \n",
    "    x=\"value\", \n",
    "    col=\"variable\",\n",
    "    col_wrap=2,\n",
    "    hue=\"Recall $>$ 0.7\",\n",
    "    kind=\"violin\",\n",
    "    sharex=False,\n",
    "    \n",
    "    dodge=True,\n",
    "    inner='stick',\n",
    "    linewidth=1,\n",
    "    split=True,\n",
    "    \n",
    "#     size=2.5,\n",
    "#     jitter=0.25,\n",
    "#     alpha=0.5,\n",
    "    height=WIDTH*0.5 / aspect,\n",
    "    legend=False,\n",
    "    aspect=aspect,\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    hpar = ax.get_title().split(' = ')[1]\n",
    "    ax.set_title(f'{rename_hpars[hpar]}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,c=hpar,x=hpar,y=recall>70.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb84331",
   "metadata": {},
   "source": [
    "### x=LR y=Nodes layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a934c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Nodes layer 1 vs LR has something happening\n",
    "fig, ax = plt.subplots(1, 1, figsize=(0.5*WIDTH, 0.5*WIDTH))\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars),\n",
    "    y='ffnn.nodes_per_layer.1.log10',\n",
    "    x='nn.learning_rate.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "    edgecolor='black',\n",
    "    palette='Spectral',\n",
    ")\n",
    "plt.gca().set(\n",
    "    xticks=np.arange(-6, -1, 1),\n",
    "    yticks=np.arange(0.5, 3, 0.5),\n",
    ")\n",
    "vis.add_grid()\n",
    "vis.fmt_legend()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn_x=lr,y=npl1,h=f1.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eddb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.05, clamp=False),\n",
    "    x='ffnn.dropout_rate',\n",
    "    y='ffnn.num_layers',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "#     alpha=0.75,\n",
    "    edgecolor='black',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a93a04",
   "metadata": {},
   "source": [
    "### N-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51851e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data\n",
    "    .groupby(['ffnn.num_layers'])\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'mean', 'median', 'min', 'max'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9637862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(\n",
    "    data['val.macro avg.f1-score']\n",
    "    .sort_values()\n",
    "    .tail(50)\n",
    "    .round(3)\n",
    "    .unique()\n",
    ")[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f42a05",
   "metadata": {},
   "source": [
    "#### x=hpar y=recall, all hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c84080",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nlayers in [1, 2, 3]:\n",
    "    aspect=2\n",
    "    subset_hpars = [\n",
    "        hpar for hpar in hyperpars\n",
    "        if data.loc[data['ffnn.num_layers'] == nlayers, hpar].nunique() > 1\n",
    "    ]\n",
    "    print([data.loc[data['ffnn.num_layers'] == nlayers, hpar].nunique() for hpar in hyperpars])\n",
    "    print(subset_hpars)\n",
    "    g = sns.catplot(\n",
    "        data=vis.add_jitter(\n",
    "            data[data['ffnn.num_layers'] == nlayers], subset_hpars\n",
    "        ).melt( \n",
    "            id_vars=['Recall $>$ 0.7'], \n",
    "            value_vars=subset_hpars,\n",
    "        ), \n",
    "        x=\"value\", \n",
    "        col=\"variable\",\n",
    "        col_wrap=2,\n",
    "        hue=\"Recall $>$ 0.7\",\n",
    "        kind=\"violin\",\n",
    "        sharex=False,\n",
    "\n",
    "        dodge=True,\n",
    "        inner='stick',\n",
    "        linewidth=1,\n",
    "        split=True,\n",
    "\n",
    "    #     size=2.5,\n",
    "    #     jitter=0.25,\n",
    "    #     alpha=0.5,\n",
    "        height=WIDTH*0.5 / aspect,\n",
    "        legend=False,\n",
    "        aspect=aspect,\n",
    "    )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        hpar = ax.get_title().split(' = ')[1]\n",
    "        ax.set_title(f'{rename_hpars[hpar]}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc4c8e",
   "metadata": {},
   "source": [
    "#### Precision recall histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(2*WIDTH,2*WIDTH*.3))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.histplot(\n",
    "        data=data[data['ffnn.num_layers'] == nlayers],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        bins=(15, 15),\n",
    "#         edgecolor='black',\n",
    "#         s=10,\n",
    "        cmap='Spectral',\n",
    "        vmin=0,\n",
    "        vmax=160,\n",
    "        ax=ax,\n",
    "        cbar=nlayers == 3,\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "#     if nlayers == 3:\n",
    "#         vis.add_cbar(\n",
    "#             fig, ax,\n",
    "#             data=\n",
    "#             vmin=0, vmax=1,\n",
    "#         )\n",
    "    ax.set(\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        ylabel=None if nlayers != 1 else rename_hpars[ax.get_ylabel()],\n",
    "        xlabel=rename_hpars[ax.get_xlabel()],\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,c=nlayers,histplot.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57004e5",
   "metadata": {},
   "source": [
    "#### x=p,y=r,h=lr,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090e218",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Three clusters in top right of precision-recall plots \n",
    "# -> caused by learning rate which needs to be _just_ right.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue='nn.learning_rate.log10',\n",
    "        edgecolor='black',\n",
    "    #     legend=False,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    vis.fmt_legend(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=lr,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7997b1e",
   "metadata": {},
   "source": [
    "#### x=lr y=f1,h=lr,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45400c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three clusters in top right of precision-recall plots \n",
    "# -> caused by learning rate which needs to be _just_ right.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(\n",
    "            data[data['ffnn.num_layers'] == nlayers], \n",
    "            hyperpars, \n",
    "            amount=0\n",
    "        ),\n",
    "        x='nn.learning_rate.log10',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='nn.learning_rate.log10',\n",
    "        edgecolor='black',\n",
    "#         legend=False,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "#         xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(-6, -1, .5)\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    vis.fmt_legend(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=f1,h=lr,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5583",
   "metadata": {},
   "source": [
    "#### x=lr,y=f1,h=npl-1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a27f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last layer of the FFNNs have a big impact on the overall performance\n",
    "# Generally the best-performing FFNNs have many nodes in the last layer, \n",
    "# and reducing the number of nodes reduces the performance\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0),\n",
    "        x='nn.learning_rate.log10',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='ffnn.nodes_per_layer.-1.log10',\n",
    "        edgecolor='black',\n",
    "#         legend=False,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "#         xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(-6, -1, 1)\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    vis.fmt_legend(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=f1,h=npl-1,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c547e4c",
   "metadata": {},
   "source": [
    "#### x=lr,y=npl-1,h=f1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c05361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes in last layer vs learning rate and F_1\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3), dpi=300)\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='nn.learning_rate.log10',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "        edgecolor='black',\n",
    "        legend=nlayers == 1,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    if nlayers == 1:\n",
    "        vis.fmt_legend(ax, title='$F_1$')\n",
    "        \n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\\n(last layer)\",\n",
    "#         xlim=(-0.05, 1.05),\n",
    "#         ylim=(-0.05, 1.05),\n",
    "#         xticks=np.arange(-6, -1, 1)\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=npl-1,h=f1,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0c0a5",
   "metadata": {},
   "source": [
    "#### x=npl1,y=npl2,h=f1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442021b",
   "metadata": {
    "code_folding": [
     4,
     21,
     36,
     51,
     66
    ]
   },
   "outputs": [],
   "source": [
    "# More nodes generally means they do better\n",
    "fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "sns.stripplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 1], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=3,\n",
    "    edgecolor='black',\n",
    "    linewidth=.25,\n",
    "#     legend=False,\n",
    "    jitter=.125,\n",
    "    palette='Spectral',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "vis.fmt_legend(axs[0, 0], title='$F_1$', loc='upper left')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 2], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "    edgecolor='black',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 3], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "    edgecolor='black',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 3], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    x='ffnn.nodes_per_layer.3.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    s=10,\n",
    "    edgecolor='black',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "for ax, nlayers in zip(axs.flatten(), [1, 2, 3, 3]):\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        xlabel=rename_hpars.get(ax.get_xlabel(), None),\n",
    "        ylabel=rename_hpars.get(ax.get_ylabel(), None),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=npl1,y=npl2,h=f1,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd7582",
   "metadata": {},
   "source": [
    "#### x=npl1,y=npl2,z=npl3,h=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e3b3b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 3D plot of npl1 vs npl2 vs npl3 for 3-layer FFNNs\n",
    "fig = plt.figure(dpi=200, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "data_ = vis.add_jitter(\n",
    "    data.loc[data['ffnn.num_layers'] == 3],\n",
    "    ['ffnn.nodes_per_layer.1.log10', 'ffnn.nodes_per_layer.2.log10', 'ffnn.nodes_per_layer.3.log10'],\n",
    "    amount=0.075\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    data_['ffnn.nodes_per_layer.1.log10'],\n",
    "    data_['ffnn.nodes_per_layer.2.log10'],\n",
    "    data_['ffnn.nodes_per_layer.3.log10'],\n",
    "    c=data_['val.macro avg.f1-score'],\n",
    "    s=1,\n",
    "    alpha=1,\n",
    "    cmap='Spectral'\n",
    ")\n",
    "ax.set(\n",
    "    xlabel='\\#Nodes (layer 1, $\\log_{10}$)',\n",
    "    ylabel='\\#Nodes (layer 2, $\\log_{10}$)',\n",
    "    zlabel='\\#Nodes (layer 3, $\\log_{10}$)',\n",
    "    xlim=(0.4, 2.75),\n",
    "    ylim=(0.4, 2.75),\n",
    "    zlim=(0.4, 2.75),\n",
    ")\n",
    "\n",
    "ax.view_init(35, -45)\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=npl1,y=npl2,z=npl3,h=f1.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "# ax.set_box_aspect(None, zoom=0.9)\n",
    "# fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='Name [units]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac90ca8",
   "metadata": {},
   "source": [
    "#### x=dropout,y=npl-1,h=npl1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80669f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(2*WIDTH,2*WIDTH*.3))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "        s=20,\n",
    "        edgecolor='black',\n",
    "    #     legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs\\n'\n",
    "              f'(coloured by {rename_hpars[\"val.macro avg.f1-score\"]})',\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51fffnn,x=dropout,y=npl-1,h=npl1,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbaebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cb.outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87f313",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Not for publication -- too big.\n",
    "# x=dropout\n",
    "# y=nodes per layer\n",
    "# cols = nlayers\n",
    "# rows = layer index\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10,10))\n",
    "\n",
    "for i, nlayers in enumerate([1,2,3]):\n",
    "    for j, layer_idx in enumerate([1,2,3]):\n",
    "        ax = axs[i, j]\n",
    "        if layer_idx > nlayers:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        data_ = data[data['ffnn.num_layers'] == nlayers]\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=vis.add_jitter(data_, hyperpars, amount=0.05),\n",
    "            x='ffnn.dropout_rate',\n",
    "            hue='val.macro avg.f1-score',\n",
    "            y=f'ffnn.nodes_per_layer.{layer_idx}.log10',\n",
    "            s=20,\n",
    "            legend=False,\n",
    "            edgecolor='black',\n",
    "            palette='Spectral',\n",
    "            ax=ax,\n",
    "            hue_norm=(0, 1),\n",
    "#             vmin=0,\n",
    "#             vmax=1,\n",
    "        )\n",
    "        \n",
    "        ax.set(\n",
    "            title=f'{nlayers}-layer FFNNs, layer {layer_idx}',\n",
    "            xlabel=None if nlayers != 3 else ax.get_xlabel(),\n",
    "#             xticks=np.round(ax.get_xticks(), 2),\n",
    "#             xticklabels=[] if nlayers != 3 else np.round(ax.get_xticks(), 2),\n",
    "            ylabel=None if layer_idx != 1 else ax.get_ylabel(),\n",
    "#             yticks=np.round(ax.get_yticks(), 2),\n",
    "#             yticklabels=[] if layer_idx != 1 else np.round(ax.get_yticks(), 2),\n",
    "        )\n",
    "#         vis.fmt_legend(ax)\n",
    "        vis.add_grid(ax)\n",
    "        vis.add_cbar(\n",
    "            fig, ax, data['val.macro avg.f1-score'], \n",
    "            label='$F_1$', vmin=0, vmax=1,\n",
    "        )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0c410",
   "metadata": {},
   "source": [
    "#### x=dropout,y=f1,h=l2,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d13e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(2*WIDTH,2*WIDTH*.3))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='ffnn.l2_coefficient.log10',\n",
    "        edgecolor='black',\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "#         legend=False\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs\\n(coloured by {rename_hpars[\"ffnn.l2_coefficient.log10\"]})',\n",
    "        ylabel=None if nlayers != 1 else ax.get_ylabel(),\n",
    "        yticks=ax.get_yticks(),\n",
    "        yticklabels=[] if nlayers != 1 else np.round(ax.get_yticks(), 1),\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=dropout,y=f1,h=l2,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef492a18",
   "metadata": {},
   "source": [
    "#### loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711163c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "# for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "#     data=data[data['ffnn.num_layers'] == nlayers],\n",
    "    x=np.log10(data['trn.loss']),\n",
    "    y=np.log10(data['val.loss']),\n",
    "    edgecolor='black',\n",
    "    hue='ffnn.num_layers',\n",
    "#         style='ffnn.num_layers',\n",
    "    palette='tab10',\n",
    "    s=10,\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].plot(\n",
    "    [-1.25, 0.5],\n",
    "    [-1.25, 0.5],\n",
    "    c='black',\n",
    "    alpha=0.5,\n",
    "    linewidth=1,\n",
    ")\n",
    "vis.add_grid(axs[0])\n",
    "vis.fmt_legend(axs[0], title='\\#Layers')\n",
    "axs[0].set(\n",
    "    xlabel='Training Loss ($\\\\log_{10}$)',\n",
    "    ylabel='Validation Loss ($\\\\log_{10}$)',\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "#     data=data[data['ffnn.num_layers'] == nlayers],\n",
    "    y=(data['ratio.loss']),\n",
    "    x=np.log10(data['trn.loss']),\n",
    "    edgecolor='black',\n",
    "    hue='ffnn.num_layers',\n",
    "#         style='ffnn.num_layers',\n",
    "    palette='tab10',\n",
    "    s=10,\n",
    "    ax=axs[1],\n",
    ")\n",
    "vis.add_grid(axs[1])\n",
    "vis.fmt_legend(axs[1], title='\\#Layers')\n",
    "axs[1].plot(\n",
    "    [-1.25, 1.0],\n",
    "    [1, 1],\n",
    "    c='black',\n",
    "    alpha=0.5,\n",
    "    linewidth=1,\n",
    ")\n",
    "axs[1].set(\n",
    "    ylabel='$\\\\frac{Training}{Validation}$ Loss',\n",
    "    xlabel='Training Loss ($\\\\log_{10}$)',\n",
    ")\n",
    "plt.suptitle(\n",
    "    f'Training and Validation loss'\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=trnloss,y=valloss,h=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "# ratio = training / validation\n",
    "# low ratio -> training lower than validation -> overfitting (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28837e7c",
   "metadata": {},
   "source": [
    "#### 1-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[data['ffnn.num_layers'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa52676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall plots for 1-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(2, 4, figsize=(8,4))\n",
    "axs = axs.flatten()\n",
    "for hpar, ax in zip(hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data1, hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(rename_hpars[hpar])\n",
    "    vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bec1fa",
   "metadata": {},
   "source": [
    "#### 2-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2440cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['ffnn.num_layers'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a08ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall plots for 2-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8,8))\n",
    "axs = axs.flatten()\n",
    "for hpar, ax in zip(hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data2, hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        s=10,\n",
    "        edgecolor='black',\n",
    "#         legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    ax.set_title(rename_hpars[hpar])\n",
    "    vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c39cc",
   "metadata": {},
   "source": [
    "#### 3-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ad13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data[data['ffnn.num_layers'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall plots for 3-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(2, 4, figsize=(8,4))\n",
    "axs = axs.flatten()\n",
    "for hpar, ax in zip(hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data3, hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(rename_hpars[hpar])\n",
    "    vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72b600",
   "metadata": {},
   "source": [
    "## Old in-depth FFNN plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.loc[(df['model_type'] == 'FFNN')]\n",
    "    .groupby(['preprocessing.num_gesture_classes'])\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'median', 'mean', 'min', 'max', 'std'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "]\n",
    "data['Recall $>$ 0.7'] = data['val.macro avg.recall'] > 0.7\n",
    "\n",
    "hyperpars = [\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3b3b4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "]\n",
    "\n",
    "data['ffnn.nodes_per_layer.2'] = data['ffnn.nodes_per_layer.2'].fillna(0)\n",
    "data['ffnn.nodes_per_layer.2.log10'] = data['ffnn.nodes_per_layer.2.log10'].fillna(0)\n",
    "data['ffnn.nodes_per_layer.3'] = data['ffnn.nodes_per_layer.3'].fillna(0)\n",
    "data['ffnn.nodes_per_layer.3.log10'] = data['ffnn.nodes_per_layer.3.log10'].fillna(0)\n",
    "# data['recall gt 0.7'] = (data['val.macro avg.recall'] >= 0.7)\n",
    "\n",
    "true = (data['val.macro avg.recall'] >= 0.7)\n",
    "# Not easily seperable\n",
    "# data['ffnn.nodes_per_layer.1.log10'].between(1.079181, 1.230449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf2696",
   "metadata": {
    "code_folding": [
     1,
     93,
     103,
     127,
     133,
     149,
     162,
     177
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Split base on the manually found clusters\n",
    "# clusters = [\n",
    "#     [\n",
    "#         {\n",
    "#             'var': 'ffnn.nodes_per_layer.1',\n",
    "#             'between': (12, 17),\n",
    "#         }, {\n",
    "#             'var': 'nn.learning_rate.log10',\n",
    "#             'between': (-3.8, -2.95),\n",
    "#         }, {\n",
    "#             'var': 'ffnn.dropout_rate',\n",
    "#             'between': (None, 0.4),\n",
    "#         }\n",
    "#     ], [\n",
    "#         {\n",
    "#             'var': 'ffnn.nodes_per_layer.1',\n",
    "#             'between': (30, 100),\n",
    "#         }, {\n",
    "#             'var': 'ffnn.num_layers',\n",
    "#             'between': (0.95, 1.05),\n",
    "#         }, {\n",
    "#             'var': 'nn.learning_rate.log10',\n",
    "#             'between': (-5, -3),\n",
    "#         }\n",
    "#     ], [\n",
    "#         {\n",
    "#             'var': 'ffnn.nodes_per_layer.1',\n",
    "#             'between': (160, 220),\n",
    "#         }, {\n",
    "#             'var': 'nn.learning_rate.log10',\n",
    "#             'between': (-5.25, -2.5),\n",
    "#         }, {\n",
    "#             'var': 'ffnn.nodes_per_layer.3',\n",
    "#             'between': (10, None),\n",
    "#         }, {\n",
    "#             'var': 'ffnn.nodes_per_layer.3',\n",
    "#             'between': (None, 3),\n",
    "#         },\n",
    "#     ], [\n",
    "#         {\n",
    "#             'var': 'ffnn.nodes_per_layer.1',\n",
    "#             'between': (280, None),\n",
    "#         }, {\n",
    "#             'var': 'ffnn.num_layers',\n",
    "#             'between': (0.95, 2.05),\n",
    "#         }, {\n",
    "#             'var': 'nn.batch_size.log10',\n",
    "#             'between': (None, 2.25),\n",
    "#         }\n",
    "#     ]\n",
    "# ]\n",
    "predictions = 'alt-manual'\n",
    "\n",
    "if predictions == 'manual':\n",
    "\n",
    "    mask_1st_layer_1_cluster = (\n",
    "          (data['ffnn.nodes_per_layer.1'].between(12, 17))\n",
    "        & (data['nn.learning_rate.log10'].between(-3.8, -2.95))\n",
    "        & (data['ffnn.dropout_rate'] < 0.4)\n",
    "    )\n",
    "    mask_2nd_layer_1_cluster = (\n",
    "          (data['ffnn.nodes_per_layer.1'].between(30, 100))\n",
    "        & (data['nn.learning_rate.log10'].between(-5, -3))\n",
    "        & (data['ffnn.num_layers'] == 1)\n",
    "    )\n",
    "    mask_3rd_layer_1_cluster = (\n",
    "          (data['ffnn.nodes_per_layer.1'].between(160, 220))   \n",
    "        & (data['nn.learning_rate.log10'].between(-5.25, -2.5))\n",
    "        & (~data['ffnn.nodes_per_layer.3'].between(3, 10))\n",
    "    )\n",
    "    mask_4th_layer_1_cluster = (\n",
    "          (data['ffnn.nodes_per_layer.1'] > 280)\n",
    "        & (data['nn.batch_size.log10'] < 2.25)\n",
    "        & (data['ffnn.num_layers'] != 3)\n",
    "    )\n",
    "    mask_layer_1_clusters = (\n",
    "        (np.full(true.shape, False))\n",
    "        | mask_1st_layer_1_cluster\n",
    "        | mask_2nd_layer_1_cluster\n",
    "        | mask_3rd_layer_1_cluster\n",
    "        | mask_4th_layer_1_cluster\n",
    "    )\n",
    "    pred = (\n",
    "        mask_layer_1_clusters\n",
    "    )\n",
    "elif predictions == 'alt-manual':\n",
    "    pred = (\n",
    "        (np.full(true.shape, False))\n",
    "#         | (data['nn.learning_rate.log10'].between(-4.25, -2.5))\n",
    "#         & (data['ffnn.num_layers'] == 1)\n",
    "#         & (data['nn.learning_rate.log10'].between(-4, -2))\n",
    "\n",
    "    )\n",
    "elif predictions == 'svm':\n",
    "    # Make predictions with a SVM classifier\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    clf = make_pipeline(StandardScaler(), svm.LinearSVC())\n",
    "    clf = clf.fit(\n",
    "        data[hyperpars].fillna(0),\n",
    "        (data['val.macro avg.recall'] >= 0.7),\n",
    "    )\n",
    "    pred = clf.predict(data[hyperpars])\n",
    "elif predictions == 'tree':\n",
    "    from sklearn import tree\n",
    "\n",
    "    dtree = tree.DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "#         min_samples_split=2,\n",
    "#         min_samples_leaf=None,\n",
    "        max_leaf_nodes=5,\n",
    "        max_depth=4,\n",
    "        random_state=42,\n",
    "    )\n",
    "    clf = dtree.fit(\n",
    "        data[hyperpars], \n",
    "        (data['val.macro avg.recall'] >= 0.7)\n",
    "    )\n",
    "    pred = clf.predict(data[hyperpars])\n",
    "\n",
    "hue = np.empty_like(true, dtype=object)\n",
    "hue[ true &  pred] = 'TP'\n",
    "hue[~true & ~pred] = 'TN'\n",
    "hue[~true &  pred] = 'FP'\n",
    "hue[ true & ~pred] = 'FN'\n",
    "\n",
    "data['conf_quad'] = hue\n",
    "molten_data = data.melt(\n",
    "    id_vars=['conf_quad'], \n",
    "    value_vars=hyperpars,\n",
    ")\n",
    "\n",
    "# Plot each hyperparameter and it's TN/FN/TP/FP options\n",
    "g = sns.catplot(\n",
    "    data=molten_data, \n",
    "    x=\"value\", \n",
    "    row=\"variable\", \n",
    "    hue=\"conf_quad\",\n",
    "    hue_order=['FN', 'FP', 'TN', 'TP'],\n",
    "    palette=['#d81d04', '#d86b04', '#79d804', '#04d895'],\n",
    "    kind=\"strip\",\n",
    "    sharex=False,\n",
    "    dodge=True,\n",
    "    size=2.5,\n",
    "    alpha=0.5,\n",
    "    jitter=0.25,\n",
    "    height=1.5,\n",
    "    aspect=4,\n",
    ")\n",
    "for ax in g.axes.flatten():\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticks(np.round(np.linspace(\n",
    "        xticks[0],\n",
    "        xticks[-1],\n",
    "        15,\n",
    "    ), 2))\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(true, pred))\n",
    "if (hue == 'FP').sum() == 0: print(\"SUCCESS\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200)\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    edgecolor=None,\n",
    "    hue=\"conf_quad\",\n",
    "    hue_order=['FN', 'FP', 'TN', 'TP'],\n",
    "    palette=['#d81d04', '#d86b04', '#79d804', '#04d895'],\n",
    "    s=5,\n",
    "#     alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_yticks(np.arange(0, 1, 0.1))\n",
    "ax.set_xticks(np.arange(0, 1, 0.1))\n",
    "ax.grid(axis='both')\n",
    "ax.set(\n",
    "    xlim=(-0.05, 1.05),\n",
    "    ylim=(-0.05, 1.05),\n",
    "    xlabel=\"Precision\",\n",
    "    ylabel=\"Recall\",\n",
    ")\n",
    "\n",
    "f1 = sklearn.metrics.f1_score(true, pred)\n",
    "ax.set_title(f'{predictions.title()} Classifier f1={f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6ef83",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363983ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "#     max_depth=3,\n",
    ")\n",
    "distributions = dict(\n",
    "    min_samples_split=[2, 4, 8, 16, 32, 64, 128],\n",
    "    min_samples_leaf=[1, 2, 4, 8, 16, 32, 64, 128],\n",
    "    max_leaf_nodes=[2, 3, 4, 5], # 10, 20, 40],\n",
    "    max_depth=[2, 3, 4, 5,], # 8, 16, 32, 64],\n",
    ")\n",
    "clf = GridSearchCV(\n",
    "    dtree, \n",
    "    distributions, \n",
    "#     random_state=42, \n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    error_score='raise',\n",
    "#     n_iter=10000,\n",
    ")\n",
    "\n",
    "search = clf.fit(\n",
    "    data[hyperpars], \n",
    "    (data['val.macro avg.recall'] >= 0.7)\n",
    ")\n",
    "search.best_score_, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28724c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "tree.plot_tree(clf.best_estimator_, feature_names=hyperpars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712f629",
   "metadata": {},
   "source": [
    "### Pairplot with recall highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpars = [\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "]\n",
    "\n",
    "data=df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "]\n",
    "data['recall $>=$ 0.7'] = (data['val.macro avg.recall'] >= 0.7)\n",
    "\n",
    "\n",
    "\n",
    "g = sns.pairplot(\n",
    "    data=data.rename(columns=rename_hpars),\n",
    "    vars=[rename_hpars[hpar] for hpar in hyperpars],\n",
    "#     data=data,\n",
    "#     vars=hyperpars,\n",
    "#     + ['val.macro avg.recall', 'val.macro avg.precision', 'val.macro avg.f1-score'],\n",
    "    hue='recall $>=$ 0.7',\n",
    "    height=3,\n",
    "#     palette='Spectral',\n",
    "#     diag_kind='hist',\n",
    "    plot_kws={\n",
    "        's': 10,\n",
    "        'alpha': 0.5,\n",
    "        'edgecolor': None,\n",
    "    },\n",
    "#     diag_kws={'hue': None, 'palette': None}\n",
    ")\n",
    "\n",
    "# for i, hpar_y in enumerate(hyperpars):\n",
    "#     min_y = data[hpar_y].min()\n",
    "#     max_y = data[hpar_y].max()\n",
    "#     for j, hpar_x in enumerate(hyperpars):\n",
    "#         if i == j: continue\n",
    "# #         print(i, j, g.axes[i, j].get_xlabel(), hpar_y, hpar_x, g.axes[i, j].get_ylabel())\n",
    "#         ax = g.axes[i, j]\n",
    "#         min_x = data[hpar_x].min()\n",
    "#         max_x = data[hpar_x].max()\n",
    "#         for cluster in clusters:\n",
    "#             for condition in cluster:\n",
    "#                 if condition['var'] == hpar_x:\n",
    "#                     lower = min_x if condition['between'][0] is None else condition['between'][0]\n",
    "#                     upper = max_x if condition['between'][1] is None else condition['between'][1]\n",
    "#                     ax.fill_betweenx(\n",
    "#                         (min_y, max_y),\n",
    "#                         lower,\n",
    "#                         upper,\n",
    "#                         color='tab:green',\n",
    "#                         alpha=0.5,\n",
    "#                     )\n",
    "# #                     print('  performing condition for x', condition)\n",
    "#                 if condition['var'] == hpar_y:\n",
    "#                     lower = min_y if condition['between'][0] is None else condition['between'][0]\n",
    "#                     upper = max_y if condition['between'][1] is None else condition['between'][1]\n",
    "#                     ax.fill_between(\n",
    "#                         (min_x, max_x),\n",
    "#                         lower,\n",
    "#                         upper,\n",
    "#                         color='tab:green',\n",
    "#                         alpha=0.5,\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8439bf",
   "metadata": {},
   "source": [
    "### Conf mats of recall plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484b579",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "nclasses = '51'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "#     & (data['val.macro avg.precision'] >= 0.5)\n",
    "]\n",
    "data['highlight'] = (\n",
    "    (data['val.macro avg.recall'] >= 0.7)\n",
    ")\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "true_class_dists = {}\n",
    "true_class_dists = {}\n",
    "\n",
    "hpar = 'highlight'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    try:\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    except:\n",
    "        y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "        \n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plots\n",
    "fig, axs = plt.subplots(\n",
    "    1,2,\n",
    "    figsize=(WIDTH, WIDTH*0.5)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat[-1, -1] = 0\n",
    "#     conf_mat /= conf_mat_totals[hpar_item]\n",
    "#     conf_mat /= conf_mat.max()\n",
    "#     print(conf_mat_totals[hpar_item])\n",
    "    # Normalize the matrix manually to get nicer annotations\n",
    "    vis.conf_mat(\n",
    "        conf_mat\n",
    "        / conf_mat.sum(axis=0), \n",
    "        ax=axs[i], \n",
    "        norm=None\n",
    "    )\n",
    "#     axs[i].set_title(\n",
    "#         f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "#     )\n",
    "# axs[0].set_title(r'Recall $>=$ 0.7')\n",
    "# axs[1].set_title(r'Recall $<$ 0.7')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Precision $>$ 0.5\")\n",
    "axs[0].set_title(\"Recall $>$ 0.7\")\n",
    "axs[1].set_title(\"Recall $<$ 0.7)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c58f32",
   "metadata": {},
   "source": [
    "### X-class FFNN learning rate vs f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc230e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5','50','51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='nn.learning_rate.log10',\n",
    "        hue='val.loss.log10',\n",
    "        palette='Spectral_r',\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        ax=axs[0],\n",
    "    #     alpha=0.5,\n",
    "    )\n",
    "    print(axs[0].get_xlim())\n",
    "    axs[0].set(\n",
    "        title=f'Learning Rate vs $F_1$-score\\n{nclasses}-class FFNN',\n",
    "        xlabel='Learning Rate ($\\log_{10}$)',\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xlim=(axs[0].get_xlim()[0] - 3, axs[0].get_xlim()[1]),\n",
    "    )\n",
    "    print(axs[0].get_xlim())\n",
    "    axs[0].legend().set_title('Loss ($\\log_{10}$)')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        hue='val.macro avg.f1-score',\n",
    "        x='nn.learning_rate.log10',\n",
    "        y='val.loss.log10',\n",
    "        palette='Spectral',\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        ax=axs[1],\n",
    "    #     alpha=0.5,\n",
    "    )\n",
    "    axs[1].legend().set_title('$F_1$')\n",
    "    axs[1].set(\n",
    "        title=f'Learning Rate vs Validation Loss\\n{nclasses}-class FFNN',\n",
    "        xlabel='Learning Rate ($\\log_{10}$)',\n",
    "        ylabel=rename_hpars['val.loss.log10'],\n",
    "        xlim=(axs[1].get_xlim()[0] - 3, axs[1].get_xlim()[1]),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_hpar_analysis_ffnn_classes{nclasses}_lr.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f583a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best learning rate for 51-class FFNNs to get the lowest validation loss\n",
    "(\n",
    "    df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') \n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].sort_values('val.loss')\n",
    "    [['nn.learning_rate.log10', 'val.loss.log10', 'val.macro avg.f1-score']]\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529cd23",
   "metadata": {},
   "source": [
    "#### 50&51-class FFNN Num layers vs f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd394d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nclasses_list = ('50','51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='ffnn.num_layers',\n",
    "        hue='val.loss.log10',\n",
    "        palette='Spectral_r',\n",
    "        jitter=0.25,\n",
    "        s=3,\n",
    "        ax=axs[0],\n",
    "#         alpha=0.5,\n",
    "    )\n",
    "    axs[0].set(\n",
    "        title=f'\\#Layers vs $F_1$-score\\n{nclasses}-class FFNN',\n",
    "        xlabel='Number of Layers',\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xlim=(-2.5, 2.5),\n",
    "    )\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    axs[0].legend(\n",
    "        handles=handles[0::2], \n",
    "        labels=labels[0::2],\n",
    "        loc='center left',\n",
    "        title='Loss ($\\log_{10}$)',\n",
    "    )\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        hue='val.macro avg.f1-score',\n",
    "        x='ffnn.num_layers',\n",
    "        y='val.loss.log10',\n",
    "        palette='Spectral',\n",
    "        jitter=0.25,\n",
    "        s=3,\n",
    "        ax=axs[1],\n",
    "#         alpha=0.5,\n",
    "    )\n",
    "\n",
    "    handles, labels = axs[1].get_legend_handles_labels()\n",
    "    axs[1].legend(\n",
    "        handles=handles[0::2], \n",
    "        labels=labels[0::2],\n",
    "        title='$F_1$',\n",
    "        loc='center left'\n",
    "    )\n",
    "\n",
    "    \n",
    "    axs[1].set(\n",
    "        title=f'\\#Layers vs Validation Loss\\n{nclasses}-class FFNN',\n",
    "        xlabel='Number of Layers',\n",
    "        ylabel=rename_hpars['val.loss.log10'],\n",
    "        xlim=(-2, 2.5),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_hpar_analysis_ffnn_classes{nclasses}_nlayers.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1060f3d",
   "metadata": {},
   "source": [
    "#### 51-class Num nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c20ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_num_weights(list_of_nodes, nclasses=51):\n",
    "    l = list_of_nodes[:]\n",
    "#     if len(list_of_nodes) == 1: return list_of_nodes[0]\n",
    "    l.insert(0, 20*30)\n",
    "    l.append(nclasses)\n",
    "    result = 0\n",
    "    for i in range(len(l)-1):\n",
    "        result += l[i] * l[i+1]\n",
    "    return result\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "xmin = np.inf\n",
    "xmax = -np.inf\n",
    "nclasses = '51'\n",
    "\n",
    "hue_col = df.loc[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "    & (df['ffnn.num_layers'].isin([1, 2, 3]))\n",
    "    & (df['model_type'] == 'FFNN'),\n",
    "    'val.loss.log10',\n",
    "]\n",
    "\n",
    "for layer_num in (1, 2, 3):\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "        & (df['model_type'] == 'FFNN')\n",
    "        & (df['ffnn.num_layers'] == layer_num)\n",
    "    ]\n",
    "\n",
    "    data['num_weights'] = data['ffnn.nodes_per_layer'].apply(calc_num_weights)\n",
    "#     data['weight_prod'] = data['ffnn.nodes_per_layer'].apply(\n",
    "#         lambda x: 600 * np.prod(x) * 51\n",
    "#     )\n",
    "#     data['weight_sum'] =  data['ffnn.nodes_per_layer'].apply(\n",
    "#         lambda x: 600 + np.sum(x) + 51\n",
    "#     )\n",
    "#     data['weight_prod.log10'] = data['weight_prod'].apply(np.log10)\n",
    "#     data['weight_sum.log10'] = data['weight_sum'].apply(np.log10)\n",
    "\n",
    "    custom_norm = mpl.colors.Normalize(\n",
    "        vmin=-1.5,\n",
    "        vmax=-0.4,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='num_weights',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='val.loss.log10',\n",
    "        hue_norm=custom_norm,\n",
    "        palette='Spectral_r',\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        ax=axs.flat[layer_num-1],\n",
    "        legend=layer_num == 1,\n",
    "#         legend=False,\n",
    "    )\n",
    "    xmin = min(xmin, axs.flat[layer_num-1].get_xlim()[0])\n",
    "    xmax = max(xmax, axs.flat[layer_num-1].get_xlim()[1])\n",
    "    \n",
    "#     display(\n",
    "#         data.loc[\n",
    "#             data['val.macro avg.f1-score'] > 0.7,\n",
    "#             ['num_weights', 'ffnn.nodes_per_layer']\n",
    "#         ].sort_values('num_weights').head(20)\n",
    "#     )\n",
    "\n",
    "for i, ax in enumerate(axs.flat[:-1]):\n",
    "    layer_s = 'layer' if i+1 == 1 else 'layers'\n",
    "    ax.set(\n",
    "        ylim=(-0.05, 1.05),\n",
    "#         xlim=(ax.get_xlim()[0], ax.get_xlim()[1]*1.5),\n",
    "        xlabel='\\#Weights',\n",
    "        ylabel='$F_1$-score',\n",
    "        title=f'Number of Weights vs $F_1$-score\\n51-class FFNNs, {i+1} {layer_s}',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "axs.flat[-1].axis('off')\n",
    "move_legend(axs.flat[0], axs.flat[-1], title='Val. Loss ($\\log_{10}$)')\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_hpar_analysis_ffnn_classes51_nweights.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16603914",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'FFNN'\n",
    "metrics = (\n",
    "    'f1-score',\n",
    "    'precision',\n",
    "    'recall',\n",
    ")\n",
    "\n",
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "val_loss_maxs = (\n",
    "    .5,\n",
    "    10,\n",
    "    -0.25,\n",
    ")\n",
    "\n",
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses, val_loss_max in zip(nclasses_list, val_loss_maxs):\n",
    "    print(f\"{nclasses} classes\")\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses) \n",
    "        & (df['model_type'] == model_type)\n",
    "        & (df['val.loss.log10'] <= val_loss_max)\n",
    "#         & (df['val.macro avg.f1-score'] >= 0.9)\n",
    "    ]\n",
    "    for metric in metrics:\n",
    "        print(f\"  {metric}\")\n",
    "        \n",
    "        nrows = 3\n",
    "        ncols = 3\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows, ncols,\n",
    "            figsize=(WIDTH, WIDTH),\n",
    "        )\n",
    "        handles = None\n",
    "        labels = None\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            if len(hyperpars) <= i:\n",
    "                if handles is not None and len(hyperpars) == i:\n",
    "                    ax.legend(\n",
    "                        handles=handles, \n",
    "                        labels=labels,\n",
    "                        title=rename_hpars[common_kwargs['hue']],\n",
    "                        loc='center',\n",
    "                    )\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            common_kwargs = {\n",
    "                'data': data.sort_values(f'val.macro avg.{metric}', ascending=True),\n",
    "                'x': hyperpars[i],\n",
    "                'y': f'val.macro avg.{metric}',\n",
    "                'hue': 'val.loss.log10',\n",
    "                'palette': 'Spectral',\n",
    "                'ax': ax,\n",
    "            }\n",
    "            \n",
    "            if data[common_kwargs['x']].nunique() > 5:\n",
    "                sns.scatterplot(\n",
    "                    edgecolor=None,\n",
    "                    s=5,\n",
    "                    **common_kwargs,\n",
    "                )\n",
    "            else:\n",
    "                sns.stripplot(\n",
    "                    s=2.5,\n",
    "                    jitter=.25,\n",
    "                    **common_kwargs,\n",
    "                )\n",
    "            ax.set(\n",
    "                title=(\n",
    "                    f\"{rename_hpars[common_kwargs['y']]} vs {rename_hpars[common_kwargs['x']]}\"\n",
    "                    .replace(\" ($\\\\log_{10}$)\", \"\")\n",
    "                    .replace(\"Val. \", \"\")\n",
    "                    .replace(\"-score\", \"\")\n",
    "                ),\n",
    "                ylabel=rename_hpars[common_kwargs['y']],\n",
    "                xlabel=rename_hpars[common_kwargs['x']],\n",
    "            )\n",
    "            if i % ncols != 0:\n",
    "                ax.set(\n",
    "                    ylabel=None,\n",
    "                    yticks=[],\n",
    "                )\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend().remove()\n",
    "        plt.tight_layout()\n",
    "        path = f'../../report/src/imgs/graphs/' + (\n",
    "            f'05_hpar_analysis_{model_type.lower()}_classes{nclasses}_'\n",
    "            f'y{common_kwargs[\"y\"]}_hue{common_kwargs[\"hue\"]}'\n",
    "        ).replace(\".\", \"_\").replace(\"-\", '_').replace(\" \", '_') + '.pdf'\n",
    "        print(f'    {path}')\n",
    "        plt.savefig(path, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f15e9e",
   "metadata": {},
   "source": [
    "### Pairplot of FFNN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    data=vis.add_jitter(data, hyperpars).rename(columns=rename_hpars),\n",
    "    hue=rename_hpars['val.macro avg.f1-score'],\n",
    "    vars=[rename_hpars[hpar] for hpar in list(hyperpars)] + [rename_hpars['val.macro avg.f1-score']],\n",
    "    height=1,\n",
    "    palette='Spectral',\n",
    "    diag_kind='hist',\n",
    "    plot_kws={\n",
    "        's': 2.5,\n",
    "        'alpha': 0.5,\n",
    "        'edgecolor': None,\n",
    "    },\n",
    "    diag_kws={'hue': None, 'palette': None}\n",
    ")\n",
    "\n",
    "# plt.savefig(\n",
    "#     '../../report/src/imgs/graphs/05_hpar_analysis_ffnn_pairplot.png',\n",
    "#     bbox_inches='tight'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aeea1c",
   "metadata": {},
   "source": [
    "### Hpars of interest for 51 classes FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hyperparameters of interest for 51 FFNN classes\")\n",
    "hpars = (\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    ")\n",
    "legend_titles = (\n",
    "    'LR ($\\log_{10}$)',\n",
    "    '\\#Layers',\n",
    "    'Nodes (layer 1)',\n",
    "    'L2 Coef ($\\log_{10}$)',\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, (hpar, legend_title) in enumerate(zip(hpars, legend_titles)):\n",
    "    sns.scatterplot(\n",
    "        data=df[\n",
    "            (df['preprocessing.num_gesture_classes'] == '51') \n",
    "            & (df['model_type'] == 'FFNN')\n",
    "            & (df['val.loss.log10'] <= max_log10_val_loss)\n",
    "        ],\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.loss.log10',\n",
    "#         hue=hpar,\n",
    "        hue='ffnn.nodes_per_layer.1',\n",
    "        palette='viridis',\n",
    "        s=10,\n",
    "        edgecolor=None,\n",
    "        ax=axs[i]\n",
    "    )\n",
    "#     axs[i].set(\n",
    "#         xlabel='Validation Loss ($\\log_{10}$)',\n",
    "#         ylabel='Recall',\n",
    "#         title=f'{legend_title}\\n(Recall vs Validation Loss)',\n",
    "#         ylim=(-0.05, 1.05),\n",
    "#     )\n",
    "#     axs[i].legend().set_title(legend_title)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84298488",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "for hpar, ax in zip(hyperpars, axs.flatten()):\n",
    "    sns.scatterplot(\n",
    "        data=df[\n",
    "            (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "            (df['model_type'] == 'FFNN')\n",
    "        ],\n",
    "        x=hpar,\n",
    "        y='val.loss.log10',\n",
    "        hue='trn.loss.log10',\n",
    "        ax=ax,\n",
    "        palette='Spectral',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    ax.legend().set_title('Training Loss\\n($\\log_{10}$)')\n",
    "# plt.show()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss.log10',\n",
    "    x='trn.loss.log10',\n",
    "    ax=axs[-1, -1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1fef3",
   "metadata": {},
   "source": [
    "## In depth HFFNN plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fbd4c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "maj_min_hyperpars = [\n",
    "    'hffnn.{}.ffnn.dropout_rate',\n",
    "    'hffnn.{}.ffnn.l2_coefficient.log10',\n",
    "    'hffnn.{}.nn.batch_size.log10',\n",
    "    'hffnn.{}.nn.learning_rate.log10',\n",
    "    'hffnn.{}.ffnn.num_layers',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.1.log10',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.2.log10',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.3.log10',\n",
    "]\n",
    "\n",
    "hyperpars = [\n",
    "    hpar.format(subtype) \n",
    "    for subtype in ['majority', 'minority'] \n",
    "    for hpar in maj_min_hyperpars\n",
    "]\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'HFFNN')\n",
    "    & (df['hffnn.majority.ffnn.dropout_rate'].notna())\n",
    "]\n",
    "data['$F_1 >$ 0.5'] = data['val.macro avg.f1-score'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect=2\n",
    "g = sns.catplot(\n",
    "    data=data.melt( \n",
    "        id_vars=['$F_1 >$ 0.5'], \n",
    "        value_vars=hyperpars,\n",
    "    ), \n",
    "    x=\"value\", \n",
    "    col=\"variable\",\n",
    "    col_wrap=2,\n",
    "    hue=\"$F_1 >$ 0.5\",\n",
    "#     hue_order=[True, False],\n",
    "#     palette=['#d81d04', '#d86b04', '#79d804', '#04d895'],\n",
    "    kind=\"violin\",\n",
    "    sharex=False,\n",
    "    inner='stick',\n",
    "#     dodge=True,\n",
    "#     size=2.5,\n",
    "#     alpha=0.5,\n",
    "#     jitter=0.25,\n",
    "    split=True,\n",
    "    height=WIDTH*0.5 / aspect,\n",
    "    aspect=aspect,\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    hpar = ax.get_title().split(' = ')[1]\n",
    "    ax.set_title(f'{rename_hpars[hpar]}')\n",
    "plt.tight_layout()\n",
    "\n",
    "# sns.move_legend(g, (0.7, 0.09))\n",
    "\n",
    "# plt.savefig(\n",
    "#     '../../report/src/imgs/graphs/05_hpar_analysis_hffnn_p_lt_0_05.pdf',\n",
    "#     bbox_inches='tight',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4773bb7",
   "metadata": {},
   "source": [
    "### Distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537228a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    np.full(len(data), True)\n",
    "#     data['hffnn.minority.nn.learning_rate.log10'].between(-4, -1.5)\n",
    "#     & data['hffnn.majority.nn.learning_rate.log10'].between(-4.5, -1.85)\n",
    "#     & data['hffnn.minority.ffnn.nodes_per_layer.1.log10'].between(.85, 10)\n",
    ")\n",
    "\n",
    "of_interest = [\n",
    "    'hffnn.majority.nn.learning_rate.log10',\n",
    "    'hffnn.minority.nn.learning_rate.log10',\n",
    "    'hffnn.majority.ffnn.num_layers',\n",
    "    \n",
    "    \n",
    "]\n",
    "fig, axs = plt.subplots(5, 2, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i >= len(of_interest):\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    sns.scatterplot(\n",
    "        data=data[mask],\n",
    "        y='val.macro avg.f1-score',\n",
    "        x=of_interest[i],\n",
    "        hue='$F_1 >$ 0.5',\n",
    "        s=5,\n",
    "        edgecolor=None,\n",
    "        alpha=0.75,\n",
    "        ax=ax,\n",
    "#         legend=i == 0,\n",
    "        legend=False,\n",
    "    )\n",
    "    p = ks_test_df.loc[\n",
    "        ks_test_df['hpar'] == of_interest[i],\n",
    "        'p_value'\n",
    "    ].values[0]\n",
    "    ax.set(\n",
    "        ylim=(-0.05, 1.05),\n",
    "        ylabel='$F_1$-score',\n",
    "        xlabel=rename_hpars[of_interest[i]],\n",
    "        title=(\n",
    "            rename_hpars[of_interest[i]].replace(r' ($\\log_{10}$)', '').replace(r', $\\log_{10}$', '') \n",
    "            + f' (p={p:.1e})'\n",
    "        )\n",
    "    )\n",
    "#     if i % 2 != 0:\n",
    "#         ax.set_ylabel(None)\n",
    "#         ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "# sns.move_legend(axs.flat[0], (1.45, -6.5))\n",
    "\n",
    "# plt.savefig(\n",
    "#     '../../report/src/imgs/graphs/05_hpar_analysis_hffnn_hpars.pdf',\n",
    "#     bbox_inches='tight',\n",
    "# )\n",
    "\n",
    "plt.show()\n",
    "sns.jointplot(\n",
    "    data=data[data['hffnn.minority.nn.learning_rate.log10'].notna()],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    hue=mask,\n",
    "    s=5,\n",
    "    edgecolor=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_min = (\n",
    "    'majority',\n",
    "    'minority',\n",
    ")\n",
    "for submodel in maj_min:\n",
    "    hyperpars = (\n",
    "        f'hffnn.{submodel}.ffnn.dropout_rate',\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.1',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.2',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.3',\n",
    "    )\n",
    "    df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "    ]] = np.log10(df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient',\n",
    "        f'hffnn.{submodel}.nn.batch_size',\n",
    "        f'hffnn.{submodel}.nn.learning_rate',\n",
    "    ]])\n",
    "    xlabels = (\n",
    "        f'Dropout Rate\\n({submodel.title()} Classifier)',\n",
    "        f'L2 Coefficient ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Batch Size ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Learning Rate ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 1\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 2\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 3\\n({submodel.title()} Classifier)',\n",
    "    )\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'HFFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        3, 3,\n",
    "        figsize=(WIDTH, WIDTH)\n",
    "    )\n",
    "    print(axs.shape)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y='val.macro avg.f1-score',\n",
    "            s=10,\n",
    "            alpha=0.5,\n",
    "            ax=ax,\n",
    "            color='tab:orange',\n",
    "            edgecolor=None,\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'$F_1$ score vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel='$F_1$ score',\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_in_depth_hffnn_{submodel}_hpars.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12504b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "?sns.move_legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d79be",
   "metadata": {},
   "source": [
    "## In depth CuSUM plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'CuSUM')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "    p_min = max(-0.05, data['val.macro avg.precision'].min() / 1.10)\n",
    "    p_max = min( 1.05, data['val.macro avg.precision'].max() * 1.10)\n",
    "    r_min = max(-0.05, data['val.macro avg.recall'].min()    / 1.10)\n",
    "    r_max = min( 1.05, data['val.macro avg.recall'].max()    * 1.10)\n",
    "\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            10,\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        hue='cusum.thresh',\n",
    "        alpha=0.75,\n",
    "        s=10,\n",
    "        ax=axs[0],\n",
    "        palette=palette,\n",
    "        edgecolor=None\n",
    "    )\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        x='cusum.thresh',\n",
    "        y='val.macro avg.f1-score',\n",
    "        alpha=0.5,\n",
    "        s=2.5,\n",
    "        ax=axs[1],\n",
    "        jitter=0.5,\n",
    "        color=model_colours['CuSUM'],\n",
    "        native_scale=True,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs recall\\n{nclasses}-class CuSUM models\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "\n",
    "    axs[0].legend().set_title('Threshold')\n",
    "\n",
    "    axs[1].set(\n",
    "        title=f'Threshold vs $F_1$ score\\n{nclasses}-class CuSUM models',\n",
    "        xlabel='CuSUM Threshold',\n",
    "        ylabel='$F_1$ score',\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_hpar_analysis_cusum_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e083f",
   "metadata": {},
   "source": [
    "## In depth SVM plots\n",
    "\n",
    "- Correlation with the training time per observation\n",
    "- Correlation with the precision/recall/f1\n",
    "- clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368145d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some summary stats\n",
    "(\n",
    "    df.loc[(df['model_type'] == 'SVM')]\n",
    "    .groupby(['preprocessing.num_gesture_classes'], dropna=False)\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'median', 'mean', 'min', 'max', 'std'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = ('5', '50', '51')\n",
    "for num_gesture_classes in n_classes:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == num_gesture_classes)\n",
    "        & (df['model_type'] == 'SVM')\n",
    "    ]\n",
    "\n",
    "    data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "    data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "    data = data.rename(columns={\n",
    "        'svm.c.log10': '$\\log_{10}(C)$', \n",
    "        'svm.class_weight': 'Class Weight'\n",
    "    })\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "    axs = axs.flatten()\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.05\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.05\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.05\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.05\n",
    "\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            5\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        hue='$\\log_{10}(C)$',\n",
    "        style='Class Weight',\n",
    "        alpha=0.8,\n",
    "        s=10,\n",
    "        ax=axs[0],\n",
    "        palette=palette,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs Recall\"\n",
    "        f\"\\n({num_gesture_classes}-class SVM)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='$\\log_{10}(C)$',\n",
    "        y='val.macro avg.f1-score',\n",
    "        style='Class Weight',\n",
    "        alpha=0.8,\n",
    "        s=10,\n",
    "        ax=axs[1],\n",
    "        color='tab:purple',\n",
    "        legend=False,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "    axs[1].set(\n",
    "        title=f\"$F_1$-score vs C\\n\"\n",
    "        f\"({num_gesture_classes}-class SVM)\",\n",
    "        xlabel='C ($\\log_{10}$)',\n",
    "        ylabel='$F_1$ score',\n",
    "    )\n",
    "    \n",
    "    move_legend(axs[0], axs[-1])\n",
    "    axs[-2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_svm_classes{num_gesture_classes}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'SVM')\n",
    "    ]\n",
    "\n",
    "    data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    hpar = 'svm.class_weight'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            zero_division=0,\n",
    "        )\n",
    "\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] += 1.0\n",
    "            precisions[hpar_item] += precision\n",
    "            recalls[hpar_item] += recall\n",
    "            f1_scores[hpar_item] += f1_score\n",
    "\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] = 1.0\n",
    "            precisions[hpar_item] = precision\n",
    "            recalls[hpar_item] = recall\n",
    "            f1_scores[hpar_item] = f1_score\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, len(conf_mats), \n",
    "        figsize=(WIDTH, WIDTH/len(conf_mats))\n",
    "    )\n",
    "\n",
    "\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    #     conf_mat[-1, -1] = 0\n",
    "        conf_mat /= conf_mat_totals[hpar_item]\n",
    "        vis.conf_mat(conf_mat, ax=axs[i])\n",
    "        axs[i].set_title(\n",
    "            f'{hpar_item.title()} SVMs'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_svm_conf_mats_unbalanced_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(WIDTH, WIDTH*.2),\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "        axs[i].set_aspect(3)\n",
    "        vis.precision_recall_f1(\n",
    "            precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            ax=axs[i],\n",
    "        )\n",
    "        axs[i].set_title(hpar_item.title() + \" SVMs\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_svm_prf1_plots_unbalanced_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in df.columns if 'time' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e40b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=axs[0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='trn.pred_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=axs[1],\n",
    "    edgecolor=None,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title='Fit time vs C\\n51-class SVM',\n",
    "    ylabel='Fit time (s/obs.)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Inference time vs C\\n51-class SVM',\n",
    "    ylabel='Inference time (s/obs.)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_svm_hpars_vs_fit_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3871e02",
   "metadata": {},
   "source": [
    "## In depth HMM plots\n",
    "\n",
    "- Clusters in recall-precision space\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3904031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some summary stats\n",
    "hue_order = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "(\n",
    "    df.loc[(df['model_type'] == 'HMM')]\n",
    "    .groupby(['preprocessing.num_gesture_classes', 'hmm.covariance_type'])\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'median', 'mean', 'min', 'max', 'std'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b6b5b",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_type = 'HMM'\n",
    "color='tab:red'\n",
    "n_classes = ('5', '50', '51',)\n",
    "for num_gesture_classes in n_classes:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == num_gesture_classes)\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "    p_min = data['val.macro avg.precision'].min() # / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() # * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    # / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    # * 1.10\n",
    "\n",
    "    precision_grid, recall_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 50), \n",
    "        np.linspace(r_min, r_max, 50),\n",
    "    )\n",
    "\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "#     contours = axs[0].contour(\n",
    "#         precision_grid,\n",
    "#         recall_grid, \n",
    "#         f1_score,\n",
    "#         levels=np.linspace(\n",
    "#             f1_score.min(),\n",
    "#             f1_score.max(),\n",
    "#             10,\n",
    "#         ), \n",
    "#         colors='black',\n",
    "#         alpha=0.25\n",
    "#     )\n",
    "#     axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "#         hue='val.macro avg.f1-score',\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "        alpha=0.5,\n",
    "        s=10,\n",
    "        ax=axs[0],\n",
    "        palette=other_colours,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs Recall\"\n",
    "        f\"\\n({num_gesture_classes}-class {model_type}s)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "#         xlim=(0, .05),\n",
    "#         ylim=(0, 1),\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "    axs[0].legend().set_title('Covariance')\n",
    "    \n",
    "    \n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='hmm.covariance_type',\n",
    "        order=hue_order,\n",
    "        size=3,\n",
    "        alpha=0.5,\n",
    "        ax=axs[1],\n",
    "        palette=other_colours,\n",
    "#         hue='val.macro avg.f1-score',\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "\n",
    "    )\n",
    "    axs[1].set(\n",
    "        title=f\"$F_1$-score vs Covariance Type\"\n",
    "        f\"\\n({num_gesture_classes}-class {model_type}s)\",\n",
    "        xlabel='Covariance Type',\n",
    "        ylabel='$F_1$-score',\n",
    "#         xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "#         ylim=(-0.05, 1.05),\n",
    "    )\n",
    "    axs[0].legend().set_title('Covariance Type')\n",
    "    plt.tight_layout()\n",
    "\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_in_depth_hmm_{num_gesture_classes}_p_vs_r_covar_type.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b276149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=df.assign(**{\n",
    "        'calc_f1-score': lambda ddf: 2 * (ddf['val.macro avg.precision'] * ddf['val.macro avg.precision']) / (ddf['val.macro avg.recall'] + ddf['val.macro avg.recall'])\n",
    "    }),\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='calc_f1-score',\n",
    "    hue='preprocessing.num_gesture_classes',\n",
    "    size=.5,\n",
    "    alpha=0.5,\n",
    "    edgecolor=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371abd2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'HMM')\n",
    "    ]\n",
    "\n",
    "    data['val.pred_time_per_obs.log10'] = np.log10(data['val.pred_time_per_obs'])\n",
    "    data['trn.pred_time_per_obs.log10'] = np.log10(data['trn.pred_time_per_obs'])\n",
    "    data['fit_time_per_obs.log10'] = np.log10(data['fit_time_per_obs'])\n",
    "\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='fit_time_per_obs.log10',\n",
    "        y='trn.pred_time_per_obs.log10',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "        ax=ax,\n",
    "        palette=other_colours,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "    ax.legend().set_title('Covariance Type')\n",
    "\n",
    "    ax.set(\n",
    "        title=f'Fitting time vs inference time\\n({nclasses}-class HMMs)',\n",
    "        xlabel=r'Fit time ($\\log_{10}(s/obs)$)',\n",
    "        ylabel='Inference time ($\\log_{10}(s/obs)$)',\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_inf_trn_time_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c0aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'HMM')\n",
    "    ]\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    f1_scores = {}\n",
    "    y_preds_dict = {}\n",
    "    y_true_dict = {}\n",
    "    reports_dict = {}\n",
    "\n",
    "    hpar = 'hmm.covariance_type'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "    #         average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] += 1.0\n",
    "            precisions[hpar_item] += precision\n",
    "            recalls[hpar_item] += recall\n",
    "            f1_scores[hpar_item] += f1_score\n",
    "            y_preds_dict[hpar_item] = np.concatenate((y_preds_dict[hpar_item], y_pred.flatten()))\n",
    "            y_true_dict[hpar_item] = np.concatenate((y_true_dict[hpar_item], y_true.flatten()))\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] = 1.0\n",
    "            precisions[hpar_item] = precision\n",
    "            recalls[hpar_item] = recall\n",
    "            f1_scores[hpar_item] = f1_score\n",
    "            y_preds_dict[hpar_item] = np.copy(y_pred.flatten())\n",
    "            y_true_dict[hpar_item] = np.copy(y_true.flatten())\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 2,\n",
    "        figsize=(WIDTH, WIDTH),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    hpar_items = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "    for i, hpar_item in enumerate(hpar_items):\n",
    "        conf_mat = conf_mats[hpar_item]\n",
    "        vis.conf_mat(conf_mat, ax=axs[i])\n",
    "    #     vis.conf_mat(conf_mat / conf_mat.max(), ax=axs[i], norm=None)\n",
    "        axs[i].set_title(\n",
    "            f'{hpar_item.title()} {nclasses}-class HMMs'\n",
    "    #         f'(Mean of {int(conf_mat_totals[hpar_item])} confusion matrices)'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_conf_mats_cov_type_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 2,\n",
    "        figsize=(WIDTH, WIDTH*.4),\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    hpar_items = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "    for i, hpar_item in enumerate(hpar_items):\n",
    "        conf_mat = conf_mats[hpar_item]\n",
    "    #     axs[i].set_aspect(1)\n",
    "        vis.precision_recall_f1(\n",
    "            precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "            ax=axs[i],\n",
    "        )\n",
    "        axs[i].set_title(f'{hpar_item} {nclasses}-class HMMs')\n",
    "        if i % 2 != 0:\n",
    "            axs[i].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_prf1_plots_conv_type_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127c75f",
   "metadata": {},
   "source": [
    "## FFNN Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763743c",
   "metadata": {},
   "source": [
    "### Heatmap-based pairplot of FFNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cf8f8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') &\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "]\n",
    "\n",
    "hpars_scale = [\n",
    "    ('nn.learning_rate',       'log10'),\n",
    "    ('ffnn.nodes_per_layer.1', 'log10'),\n",
    "    ('ffnn.l2_coefficient',    'log10'),\n",
    "    ('ffnn.dropout_rate',      'linear'),\n",
    "]\n",
    "# x_var_idx = 0\n",
    "# y_var_idx = 1\n",
    "def contour_nicely(x, y, z, xlabel, ylabel, xscale, yscale, fig, ax, levels=8):\n",
    "\n",
    "    ax.tricontour(x, y, z, levels=levels, linewidths=0.25, colors='k')\n",
    "    cntr2 = ax.tricontourf(x, y, z, levels=levels, cmap=palette)\n",
    "\n",
    "    fig.colorbar(cntr2, ax=ax)\n",
    "    ax.scatter(x, y, color='white', s=1)\n",
    "\n",
    "    ax.set_xlabel(f'{xlabel} ({xscale})')\n",
    "    if xscale == 'log10':\n",
    "        ax.set_xticks(ax.get_xticks())\n",
    "        ax.set_xticklabels([f'{np.power(10, t):.3g}' for t in ax.get_xticks()])\n",
    "\n",
    "    ax.set_ylabel(f'{ylabel} ({yscale})')\n",
    "    if yscale == 'log10':\n",
    "        ax.set_yticks(ax.get_yticks())\n",
    "        ax.set_yticklabels([f'{np.power(10, t):.3g}' for t in ax.get_yticks()])\n",
    "\n",
    "    ax.set_title(f'{xlabel} vs {ylabel}')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(\n",
    "    len(hpars_scale), \n",
    "    len(hpars_scale), \n",
    "    dpi=200, \n",
    "    squeeze=False,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "z = data['val.macro avg.f1-score'].values\n",
    "for x_var_idx in range(len(hpars_scale)):\n",
    "    for y_var_idx in range(x_var_idx+1, len(hpars_scale)):\n",
    "    \n",
    "        x = data[hpars_scale[x_var_idx][0]].values\n",
    "        if hpars_scale[x_var_idx][1] == 'log10':\n",
    "            x = np.log10(x)\n",
    "        elif hpars_scale[x_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[x_var_idx][0]} is not implemented\")\n",
    "        y = data[hpars_scale[y_var_idx][0]].values\n",
    "        if hpars_scale[y_var_idx][1] == 'log10':\n",
    "            y = np.log10(y)\n",
    "        elif hpars_scale[y_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[y_var_idx][0]} is not implemented\")\n",
    "            \n",
    "        contour_nicely(\n",
    "            y, x, z,\n",
    "            hpars_scale[y_var_idx][0],\n",
    "            hpars_scale[x_var_idx][0],\n",
    "            hpars_scale[y_var_idx][1],\n",
    "            hpars_scale[x_var_idx][1],\n",
    "            fig, axs[x_var_idx, y_var_idx]\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb27c46",
   "metadata": {},
   "source": [
    "## Inference times vs num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "axs = axs.flatten()\n",
    "model_types = [m for m in model_colours.keys() if m != 'HFFNN']\n",
    "for ax, model_type in zip(axs, sorted(model_types)):\n",
    "    sns.stripplot(\n",
    "        data=df[\n",
    "            df['model_type'] == model_type\n",
    "        ].sort_values('preprocessing.num_gesture_classes'),\n",
    "        x='preprocessing.num_gesture_classes',\n",
    "        y='val.pred_time_per_obs',\n",
    "        hue='model_type',\n",
    "#         dodge=True,\n",
    "        s=2,\n",
    "        legend=False,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f'{model_type} inference time vs number of classes',\n",
    "        xlabel='Number of Classes',\n",
    "        ylabel='Inference time (seconds/observation)',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_time_vs_num_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181109be",
   "metadata": {},
   "source": [
    "## Example Confusion Matrices from baseline models\n",
    "\n",
    "TODO: Also include models with perfect precision / perfect recall / perfect precision for non-g255 gestures / perfect precision for g255 / perfect recall for non-g255 gestures / perfect recall for g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d36d37",
   "metadata": {},
   "source": [
    "### Plot a model that only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81fc63",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# A function for plotting precision-recall + confusion matrices\n",
    "def plt_pr_conf_mat(y_true, y_preds):\n",
    "    \"\"\"Given true and predicted labels, \n",
    "    create a confusion matrix and a precision-recall plot.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "    if len(y_preds.shape) == 1:\n",
    "        y_preds = np.array([y_preds])\n",
    "    # Confusion matrix\n",
    "    # Get the median confusion matrix\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    cm_sum = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for y_pred in y_preds:\n",
    "        cm_sum += tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "    cm = cm_sum / len(y_preds)\n",
    "    vis.conf_mat(cm, ax=axs[1])\n",
    "    \n",
    "    f1_sum = 0\n",
    "    for y_pred in y_preds:\n",
    "        f1_sum += sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_sum / len(y_preds)\n",
    "\n",
    "    # Precision-recall plot\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(0, 1, 100), \n",
    "        np.linspace(0, 1, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    ps = []\n",
    "    rs = []\n",
    "    for y_pred in y_preds:\n",
    "        ps.append(sklearn.metrics.precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "        rs.append(sklearn.metrics.recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    p = np.mean(ps)\n",
    "    r = np.mean(rs)\n",
    "\n",
    "    axs[0].scatter(\n",
    "        ps, rs,\n",
    "        color='black',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    axs[0].set_xlabel('Precision')\n",
    "    axs[0].set_ylabel('Recall')\n",
    "    axs[0].set_xlim((-0.01, 1.01))\n",
    "    axs[0].set_ylim((-0.01, 1.01))\n",
    "    axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    plt.tight_layout()\n",
    "#     axs[0].set_title(f'Precision-Recall Graph\\n(contours indicate the $F_1$-score)')\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff657758",
   "metadata": {},
   "source": [
    "#### Only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da06a2f",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Only predicts 50\n",
    "y_preds = np.full((30, y_trn.shape[0]), 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_only_50.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa4bba",
   "metadata": {},
   "source": [
    "#### Completely random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts randomly\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_random_preds.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894af3ed",
   "metadata": {},
   "source": [
    "#### Wrong orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong orientation\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn_repeated + 10*np.random.randint(\n",
    "        -(y_trn_repeated // 10), \n",
    "        +(5 - y_trn_repeated // 10), \n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_orientation.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78100f19",
   "metadata": {},
   "source": [
    "#### Wrong finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong finger\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 10), \n",
    "        +(10 - np.mod(y_trn_repeated, 10)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba12ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts wrong finger (but correct hand)\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 5), \n",
    "        +(5 - np.mod(y_trn_repeated, 5)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger_correct_hand.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072cb6",
   "metadata": {},
   "source": [
    "#### Predict 50 as a random gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_no_gesture_50.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32086956",
   "metadata": {},
   "source": [
    "#### High recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74628a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 51, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_recall.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801984",
   "metadata": {},
   "source": [
    "#### High precision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88419278",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 5, axis=0)\n",
    "y_preds = np.where(\n",
    "    y_trn_repeated != 50,\n",
    "    50,\n",
    "    y_trn_repeated,\n",
    ")\n",
    "\n",
    "# np.clip(np.random.randint(-1, 1, size=y_trn_repeated.shape) + y_trn_repeated, 0, 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_precision.pdf', bbox_inches='tight')\n",
    "\n",
    "# f1_scores = []\n",
    "# for y_pred in y_preds:\n",
    "#     f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "# f1_scores = np.array(f1_scores)\n",
    "# print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f508a",
   "metadata": {},
   "source": [
    "### Finally, plot all confusion matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(WIDTH, WIDTH*2/3))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Random model:\n",
    "y_pred = np.random.randint(0, 51, y_trn.shape)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[0])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[0].set_title(f\"Random model\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Only predicts 50\n",
    "y_pred = np.full(y_trn.shape, 50)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[1])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[1].set_title(f\"Only predicts 50\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random orientation:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn + 10*np.random.randint(\n",
    "        -(y_trn // 10), \n",
    "        +(5 - y_trn // 10), \n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[2])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[2].set_title(f\"Perfect,\\nbut random orientation\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 10), \n",
    "        +(10 - np.mod(y_trn, 10)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[3])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[3].set_title(f\"Perfect,\\nbut random finger\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger (same hand):\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 5), \n",
    "        +(5 - np.mod(y_trn, 5)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[4])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[4].set_title(f\"Perfect,\\nbut random finger on the correct hand\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Never predicts 50\n",
    "y_pred = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn.shape), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(\n",
    "    y_trn, \n",
    "    y_pred,\n",
    ").numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[5])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[5].set_title(f\"Perfect,\\nbut predicts 50 as a random gesture\\n$F_1$={f1:.4}\")\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_example_conf_mats.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b251d46",
   "metadata": {},
   "source": [
    "## PCA Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fa9de",
   "metadata": {},
   "source": [
    "### PCA decomposition only including the gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f7ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "shape = (np.nonzero(y_trn != 50)[0].shape[0] * 5,)\n",
    "mask = np.concatenate((\n",
    "    np.random.choice(np.nonzero(y_trn == 50)[0], shape), \n",
    "    np.nonzero(y_trn != 50)[0]\n",
    "))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3), dpi=200)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 20), dpi=200)\n",
    "for i, perplexity in enumerate([35, 45, 55]):\n",
    "    print(f\"PERPLEXITY: {perplexity}\")\n",
    "    X_embedded = TSNE(\n",
    "        n_components=2,\n",
    "        n_iter=1500,\n",
    "        learning_rate='auto',\n",
    "        init='random',\n",
    "        perplexity=perplexity,\n",
    "        verbose=True\n",
    "    ).fit_transform(X_trn[mask].reshape((X_trn[mask].shape[0], 600)))\n",
    "\n",
    "    hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\", \"Non-gesture\"])\n",
    "    styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", \"Non-gesture\"])\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=200)\n",
    "    argsort = np.argsort(y_trn[mask])\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_embedded[:, 0][argsort],\n",
    "        y=X_embedded[:, 1][argsort],\n",
    "        hue=hues[(y_trn[mask][argsort] // 10)],\n",
    "        style=styles[(y_trn[mask][argsort] % 10)],\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        ax=axs.flatten()[i],\n",
    "        legend=False,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    axs.flatten()[i].set_title(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_legend(from_ax, to_ax, title=None):\n",
    "    # Fetch the current legend\n",
    "    handles, labels = from_ax.get_legend_handles_labels()\n",
    "    title = title if title is not None else from_ax.legend().get_title()\n",
    "    # Remove it from the ax\n",
    "    from_ax.legend().remove()\n",
    "    # Add it to the new ax with some styling\n",
    "    to_ax.legend(\n",
    "        handles=handles, \n",
    "        labels=labels,\n",
    "        loc='center',\n",
    "        fancybox=False, \n",
    "        edgecolor=\"black\",\n",
    "        title=title\n",
    "#         linewidth=0.5,\n",
    "    )\n",
    "    # Remove the axis of the ax\n",
    "    to_ax.axis('off')\n",
    "    return from_ax, to_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Executing PCA\")\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "print(\"PCA complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=200)\n",
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", 'k'])\n",
    "# markers = np.array(['o', 'x', 's', '+', 'D', 'p', '^', 'd', 'v', '*', 'x'])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=300)\n",
    "# mask = (y_trn == 50)\n",
    "# axs[1].scatter(\n",
    "#     X_tfrm[:, 0][mask],\n",
    "#     X_tfrm[:, 1][mask],\n",
    "#     color='black',\n",
    "#     alpha=0.1,\n",
    "#     s=5,\n",
    "#     edgecolor='none',\n",
    "# )\n",
    "for gidx in range(0, 51):\n",
    "    ax.scatter(\n",
    "        X_tfrm[:, 0][y_trn == gidx],\n",
    "        X_tfrm[:, 1][y_trn == gidx],\n",
    "        color=colours[gidx // 10],\n",
    "        marker=markers[gidx % 10],\n",
    "        alpha=0.75 if gidx != 50 else 0.1,\n",
    "        zorder=10 if gidx != 50 else 0,\n",
    "        s=10 if gidx != 50 else 5,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "ax.set_title('PCA plot of the training data\\n(class 50 in black)')\n",
    "\n",
    "ax.set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"TODO: Also add a legend here\")\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_pca_plot.png',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f29a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11\n",
    "markers = [\n",
    "    \"o\", \"X\", (4, 0, 45), \"P\", (4, 0, 0), (4, 1, 0), \"^\", (4, 1, 45), \"v\",\n",
    "]\n",
    "\n",
    "# Now generate more from regular polygons of increasing order\n",
    "s = 5\n",
    "while len(markers) < n:\n",
    "    a = 360 / (s + 1) / 2\n",
    "    markers.extend([(s + 1, 1, a), (s + 1, 0, a), (s, 1, 0), (s, 0, 0)])\n",
    "    s += 1\n",
    "\n",
    "markers = np.array([m for m in markers[:n]])\n",
    "markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4231b",
   "metadata": {},
   "source": [
    "### PCA plot showing just an interesting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec25ed",
   "metadata": {
    "code_folding": [
     2,
     8
    ]
   },
   "outputs": [],
   "source": [
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "@interact(\n",
    "    x_start=(-1500, 1500, 50),\n",
    "    y_start=(-1500, 1500, 50),\n",
    "    x_length=(-1500, 1500, 50),\n",
    "    y_length=(-1500, 1500, 50),\n",
    ")\n",
    "def fn(x_start=-150, y_start=1000, x_length=500, y_length=500):\n",
    "    x_finsh = x_start + x_length\n",
    "    y_finsh = y_start + y_length\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "\n",
    "    selection_mask = (\n",
    "        (x_start <= X_tfrm[:, 0]) & (X_tfrm[:, 0] <= x_finsh) &\n",
    "        (y_start <= X_tfrm[:, 1]) & (X_tfrm[:, 1] <= y_finsh)\n",
    "    )\n",
    "    X_subset = X_tfrm[selection_mask]\n",
    "    y_subset = y_trn[selection_mask]\n",
    "#     ax.scatter(\n",
    "#         X_subset[:, 0],\n",
    "#         X_subset[:, 1],\n",
    "#         c='black',\n",
    "#         alpha=0.1,\n",
    "#     )\n",
    "    \n",
    "    y_mask = (y_trn == 50)\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset == 50],\n",
    "        X_subset[:, 1][y_subset == 50],\n",
    "        color='black',\n",
    "        alpha=0.1,\n",
    "        s=20,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset != 50],\n",
    "        X_subset[:, 1][y_subset != 50],\n",
    "        color=colours[(y_subset[y_subset != 50] // 10)],\n",
    "        alpha=0.75,\n",
    "#         s=5,\n",
    "        edgecolor='none',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d3579",
   "metadata": {},
   "source": [
    "### PCA plot that connects sequential datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "order = np.argsort(dt_trn)\n",
    "X_tfrm = X_tfrm[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "limit = 1000\n",
    "@interact(start=(0, len(X_tfrm), 25), length=(0, len(X_tfrm), 50))\n",
    "def fn(start=0, length=500):\n",
    "    finsh = min(start + length, len(X_tfrm))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=100)\n",
    "    ax.plot(\n",
    "        X_tfrm[:, 0][start:finsh],\n",
    "        X_tfrm[:, 1][start:finsh],\n",
    "        zorder=0,\n",
    "        c='black',\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_tfrm[:, 0][start:finsh],\n",
    "        y=X_tfrm[:, 1][start:finsh],\n",
    "        hue=dt_trn[order][start:finsh],\n",
    "        legend=False,\n",
    "        s=(10 + 90*(y_trn != 50)[order][start:finsh]),\n",
    "        edgecolor=np.where((y_trn != 50)[order][start:finsh], 'black', 'none'),\n",
    "        linewidth=.5,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    \n",
    "    idxs = np.nonzero(y_trn[order][start:finsh] != 50)[0]\n",
    "    for idx in idxs:\n",
    "        ax.text(\n",
    "            X_tfrm[start:finsh][idx, 0],\n",
    "            X_tfrm[start:finsh][idx, 1],\n",
    "            y_trn[order][start:finsh][idx],\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "#     ax.set_xlim((\n",
    "#         X_tfrm[:, 0].min() / 1.1,\n",
    "#         X_tfrm[:, 0].max() * 1.1,\n",
    "#     ))\n",
    "#     ax.set_ylim((\n",
    "#         X_tfrm[:, 1].min() / 1.1,\n",
    "#         X_tfrm[:, 1].max() * 1.1,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e39f0",
   "metadata": {},
   "source": [
    "### PCA plot with ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a102cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "y_tfrm = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3cdfa",
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensional dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse(\n",
    "        (0, 0), \n",
    "        width=ell_radius_x * 2, \n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor, \n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Calculating the standard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the standard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "    \n",
    "#     print(f\"{scale_x=}, {scale_y=}\\n{mean_x=}, {mean_y=}\")\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    \n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da5944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "# gidx = 14\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "markers = ['o', 's', 'D', '^', 'v', '>', '<', 'p', 'H', '+']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "for gidx in range(50):\n",
    "    ax.scatter(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        color=colors[gidx // 10],\n",
    "        marker=markers[gidx % 10],\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        label=gidx\n",
    "    )\n",
    "    confidence_ellipse(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        ax,\n",
    "        n_std=2,\n",
    "        edgecolor=colors[gidx // 10],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5233e5",
   "metadata": {},
   "source": [
    "## Visualise mis-predictions\n",
    "\n",
    "1. Load in a continuous dataset\n",
    "2. Load in a classifier\n",
    "3. Use the classifier to make predictions on the dataset\n",
    "4. Visualise the mispredictions, but *with context*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8970",
   "metadata": {},
   "source": [
    "### Load in a model for which to evaluate the mis-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "clf = models.load_tf('../src/saved_models/ffnn_2023-09-18T14:05:16.363404')\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce0a33",
   "metadata": {},
   "source": [
    "### Visualise True and Mispredicted gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61f5b4",
   "metadata": {},
   "source": [
    "Plot all the observations which have the ground truth being gesture 255 but the model is not predicting g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a359ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "for gidx in np.unique(y_val):\n",
    "    if gidx == 50: continue\n",
    "    pred_indxs = np.nonzero((y_val == 50) & (y_pred == gidx))[0]\n",
    "    true_indxs = np.nonzero(y_val == gidx)[0]\n",
    "    axs = vis.cmp_ts(\n",
    "        X_val[true_indxs],\n",
    "    )\n",
    "    vis.cmp_ts(\n",
    "        X_val[pred_indxs],\n",
    "        color='tab:red',\n",
    "        axs=axs,\n",
    "    )\n",
    "\n",
    "#     distances = np.abs(true_indxs[:, np.newaxis] - pred_indxs).min(axis=0)\n",
    "\n",
    "    plt.suptitle(f'Model predicted {gidx}, ground truth: 50 \\\n",
    "                 \\nGesture {gidx} in grey, mispredicted in red ({len(pred_indxs)} observations) \\\n",
    "                 \\nindices: {pred_indxs}')\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'../src/notebooks/pred_{gidx:0>2}_truth_50.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     if gidx > 5:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ac5e1",
   "metadata": {},
   "source": [
    "## Eval model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../src/saved_models/ffnn_2023-10-08T14:47:07.901649'\n",
    "tst_data = np.load('../gesture_data/tst_20_10.npz')\n",
    "y_tst = tst_data['y_tst']\n",
    "X_tst = tst_data['X_tst']\n",
    "dt_tst = tst_data['dt_tst']\n",
    "clf = models.load_tf(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705b94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = clf.config['model_type']\n",
    "                                                                         \n",
    "y_pred = clf.predict(X_tst)\n",
    "clf_report_dict = sklearn.metrics.classification_report(\n",
    "    y_tst.astype(int),\n",
    "    y_pred.astype(int),\n",
    "    output_dict=True,\n",
    "    zero_division=0,\n",
    ")\n",
    "clf_report = pd.json_normalize(clf_report_dict)\n",
    "# print(sklearn.metrics.classification_report(\n",
    "#     y_tst.astype(int),\n",
    "#     y_pred.astype(int),\n",
    "#     output_dict=False,\n",
    "#     zero_division=0,\n",
    "# ))\n",
    "                            \n",
    "f1 = clf_report['macro avg.f1-score'].values[0]\n",
    "precision = clf_report['macro avg.precision'].values[0]\n",
    "recall = clf_report['macro avg.recall'].values[0]\n",
    "# print(\"val.macro avg.f1-score\", f1)\n",
    "# print(\"val.macro avg.precision\", precision)\n",
    "# print(\"val.macro avg.recall\", recall)\n",
    "# print (clf_report['macro avg.f1-score'].values[0])\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_tst, y_pred, num_classes=51).numpy()\n",
    "# cm[-1, -1] = 0\n",
    "fig, axs = plt.subplots(2, 1, figsize=(WIDTH, WIDTH))\n",
    "vis.conf_mat(\n",
    "    cm,\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_title(\n",
    "    f'Confusion Matrix (Test set)\\n'\n",
    "    f'$F_1$={np.round(f1, 3)}, Precision={np.round(precision, 3)}, Recall={np.round(recall, 3)}'\n",
    ")\n",
    "\n",
    "axs[1].set_aspect(2.5)\n",
    "vis.precision_recall_f1(\n",
    "    report=clf_report_dict,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_tst_set_conf_mat.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame()\n",
    "ddf['Recall'] = {\n",
    "    int(k): d['recall']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf['Precision'] = {\n",
    "    int(k): d['precision']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf['$F_1$-score'] = {\n",
    "    int(k): d['f1-score']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf = ddf.reset_index()\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158449ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\", 'Non-Gesture'])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", 'Non-Gesture'])\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.1, 1, 10), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "sns.scatterplot(\n",
    "    data=ddf,\n",
    "    x='Recall',\n",
    "    y='Precision',\n",
    "    hue=hues[ddf.index // 10],\n",
    "    style=styles[ddf.index % 10],\n",
    "    ax=ax,\n",
    "    edgecolor=None,\n",
    ")\n",
    "ax.set(\n",
    "    xlim=(-0.05, 1.05),\n",
    "    ylim=(-0.05, 1.05),\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='Precision and Recall for all gestures (best model)'\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_p_r_best_model.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1601b8",
   "metadata": {},
   "source": [
    "# Interactive plot to see data at a certain time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "#     constants_path='../src/constants.yaml',\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "\n",
    "@interact(dt='2022-10-08T20:23:46.665276000')\n",
    "def fn(dt='2022-10-08T20:23:46.665276000'):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "    mask = df['datetime'].between(\n",
    "        dt - pd.to_timedelta(1, 'second'),\n",
    "        dt + pd.to_timedelta(1, 'second')\n",
    "    )\n",
    "    \n",
    "    vis.cmp_ts(\n",
    "        [df.loc[mask, sensor_names].values]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d246d",
   "metadata": {},
   "source": [
    "# Plot a CSV file + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../gesture_data/saved_from_cli_2023-10-08T22:24:06.csv'\n",
    "model_dir = '../src/saved_models/ffnn_2023-10-08T14:14:07.933452'\n",
    "\n",
    "import yaml\n",
    "with open('../gesture_data/gesture_info.yaml', 'r') as f:\n",
    "    gesture_info = yaml.safe_load(f)['gestures']\n",
    "\n",
    "sensors = list(common.read_constants('./constants.yaml')[\"sensors\"].values())\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    names=[\"datetime\", \"gesture\"] + sensors,\n",
    "    parse_dates=[\"datetime\"],\n",
    "    date_format='ISO8601',\n",
    ")\n",
    "df['file'] = csv_path\n",
    "X, y, dt = common.make_windows(\n",
    "    df,\n",
    "    20,\n",
    "    constants_path='../src/constants.yaml',\n",
    "    pbar=tqdm.tqdm(total=len(df), desc=\"Making windows\"),\n",
    ")\n",
    "clf = models.load_tf(model_dir)\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a2d5e",
   "metadata": {},
   "source": [
    "## Plot data, predictions, keystrokes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454dc576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clf=None\n",
    "@interact(start=(0, len(df), 200), duration=(0, len(df), 200))\n",
    "def fn(start=10, duration=500):\n",
    "    fig, axs = plt.subplots(3 if clf is not None else 2, 1, figsize=(WIDTH, WIDTH))\n",
    "    for i in range(X.shape[-1]):\n",
    "        axs[0].plot(\n",
    "            X[start:start+duration, 0, i],\n",
    "            alpha=0.5,\n",
    "            c=['tab:red', 'tab:green', 'tab:blue'][i%3],\n",
    "            lw=1,\n",
    "        )\n",
    "    sns.heatmap(\n",
    "        X[start:start+duration, 0, :].T,\n",
    "        cmap='Spectral',\n",
    "        ax=axs[1],\n",
    "        cbar=False,\n",
    "        vmin=290,\n",
    "        vmax=910,\n",
    "        yticklabels=5,\n",
    "    )\n",
    "\n",
    "    if clf is not None:\n",
    "        sns.heatmap(\n",
    "            y_pred_probs[start-10:start+duration-10, :].T,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            ax=axs[2],\n",
    "            cbar=False,\n",
    "            yticklabels=5,\n",
    "            cmap='Spectral',\n",
    "        )\n",
    "        axs[2].set(\n",
    "            ylabel='Predicted\\ngesture',\n",
    "        )\n",
    "        for idx in np.nonzero(y_pred[start-10:start+duration-10] != 50)[0]:\n",
    "            gidx = y_pred[start-10:start+duration-10][idx]\n",
    "            gidx = 255 if gidx == 50 else gidx\n",
    "            txt = gesture_info[f'gesture{gidx:0>4}']['key']\n",
    "            axs[0].text(\n",
    "                idx, \n",
    "                800,\n",
    "                txt,\n",
    "            )\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "    \n",
    "    axs[0].set(\n",
    "        ylabel='Sensor value',\n",
    "        xticks=[],\n",
    "        ylim=(250, 950)\n",
    "    )\n",
    "    axs[1].set(\n",
    "        ylabel='Sensor number',\n",
    "        xticks=[],\n",
    "    )\n",
    "    axs[0].margins(0)\n",
    "    with_clf =' and model predictions' if clf is not None else ''\n",
    "    axs[0].set_title(\n",
    "        f'Sensor values{with_clf} over time from {np.round(start/40, 2)}s\\n'\n",
    "        f'(duration: {np.round(duration/40, 2)} seconds)'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9de61",
   "metadata": {},
   "source": [
    "## Easily convert text to gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4129ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def char_to_gesture(c):\n",
    "    c_old = c\n",
    "    if c == ' ':\n",
    "        c = 'space'\n",
    "    for k, v in gesture_info.items():\n",
    "        if v['key'] == c.lower():\n",
    "            desc = (\n",
    "                v[\"description\"]\n",
    "                .replace(\"l\", \"left \")\n",
    "                .replace(\"r\", \"right\")\n",
    "                .replace(\" 1\", \" thumb\")\n",
    "                .replace(\" 2\", \" index\")\n",
    "                .replace(\" 3\", \" middle\")\n",
    "                .replace(\" 4\", \" ring\")\n",
    "                .replace(\" 5\", \" pinky\")\n",
    "            )\n",
    "            return f'[{c_old}] {k}  {desc}'\n",
    "text = 'the quick brown fox jumped over the lazy dog'\n",
    "\n",
    "print('\\n'.join(char_to_gesture(c) for c in text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edb018",
   "metadata": {},
   "source": [
    "# Misc Methodology chapter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(\n",
    "    data=df,\n",
    "    x='model_type',\n",
    "    y='fit_time',\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df,\n",
    "    x='model_type',\n",
    "    y='val.pred_time',\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.groupby('model_type').agg({\n",
    "    'group_idx': ['nunique', 'count'], \n",
    "     'fit_time': 'mean',\n",
    "     'val.pred_time': 'mean',\n",
    "})\n",
    "\n",
    "# ['group_idx'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4_true = np.array([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "])\n",
    "y_4_pred = np.array([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 5, 4,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    2, 2, 2, 2, 2, 2,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "\n",
    "])\n",
    "conf_mat = tf.math.confusion_matrix(y_4_true, y_4_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "titles = np.array([\n",
    "    [\"Count of observations\", \"Normalized by columns\"],\n",
    "    [\"Normalized by rows\", \"Normalized by total sum\"],\n",
    "])\n",
    "\n",
    "for i in (0, 1):\n",
    "    for j in (0, 1):\n",
    "        if i == j == 0:\n",
    "            div = 1\n",
    "        elif i == j == 1:\n",
    "            div = conf_mat.sum()\n",
    "        elif i == 0 and j == 1:\n",
    "            div = conf_mat.sum(axis=0)\n",
    "        elif i == 1 and j == 0:\n",
    "            div = conf_mat.sum(axis=1)\n",
    "        sns.heatmap(\n",
    "            conf_mat / div,\n",
    "            square=True,\n",
    "            annot=True,\n",
    "            fmt='.0f' if i == j == 0 else '.2f',\n",
    "            mask=conf_mat == 0,\n",
    "            cmap='Spectral',\n",
    "            vmin=0,\n",
    "            vmax=conf_mat.max() if i == j == 0 else 1.0,\n",
    "            ax=axs[i, j],\n",
    "        )\n",
    "        axs[i, j].set(\n",
    "            title=titles[i, j],\n",
    "            xlabel='Predicted',\n",
    "            ylabel='Ground Truth',\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_example_conf_mat.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH*.25))\n",
    "report = sklearn.metrics.classification_report(\n",
    "    y_4_true,\n",
    "    y_4_pred,\n",
    "    zero_division=0,\n",
    "    output_dict=True,\n",
    ")\n",
    "vis.precision_recall_f1(report, ax=ax, annot=True)\n",
    "# ax.set_xticks([0, 1, 2, 3, 4, 5]);\n",
    "# ax.set_xticklabels([0, 1, 2, 3, 4, 5]);\n",
    "ax.set(\n",
    "    title='Recall, Precision, and $F_1$-score',\n",
    "    xlabel='Class',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_prec_rec_f1_example.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba859a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.05, 1, 19), \n",
    "    cmap='Spectral'\n",
    "#     colors='black',\n",
    "#     alpha=0.5\n",
    ")\n",
    "ax.clabel(contours, inline=True, fmt='%.2f')\n",
    "ax.set(\n",
    "    title='Precision vs Recall, with $F_1$-score on contours',\n",
    "    ylabel='Precision',\n",
    "    xlabel='Recall',\n",
    "    xticks=np.arange(0, 1.01, 0.1),\n",
    "    yticks=np.arange(0, 1.01, 0.1),\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_precision_recall_f1.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4_true = np.array([\n",
    "    5, 5, 5, 5, 5, 5, 5, 0, 0, 0,\n",
    "    5, 5, 5, 5, 5, 5, 5, 1, 1, 1,\n",
    "    5, 5, 5, 5, 5, 5, 5, 2, 2, 2,\n",
    "    5, 5, 5, 5, 5, 5, 5, 3, 3, 3,\n",
    "    5, 5, 5, 5, 5, 5, 5, 4, 4, 4,\n",
    "])\n",
    "y_4_pred = np.array([\n",
    "    5, 5, 5, 5, 5, 5, 0, 5, 0, 0,\n",
    "    5, 5, 5, 5, 5, 5, 1, 5, 5, 1,\n",
    "    5, 5, 5, 5, 5, 5, 2, 5, 2, 2,\n",
    "    5, 5, 5, 5, 5, 5, 3, 5, 4, 3,\n",
    "    5, 5, 5, 5, 5, 5, 4, 5, 4, 4,\n",
    "\n",
    "])\n",
    "conf_mat = tf.math.confusion_matrix(y_4_true, y_4_pred).numpy()\n",
    "\n",
    "sns.heatmap(\n",
    "    conf_mat / conf_mat.sum(axis=1),\n",
    "    square=True,\n",
    "    annot=True,\n",
    "#     fmt='.0f' if i == j == 0 else '.2f',\n",
    "    mask=conf_mat == 0,\n",
    "    cmap='Spectral',\n",
    ")\n",
    "plt.show()\n",
    "report = sklearn.metrics.classification_report(\n",
    "    y_4_true,\n",
    "    y_4_pred,\n",
    "    zero_division=0,\n",
    "    output_dict=True,\n",
    ")\n",
    "vis.precision_recall_f1(report, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61445582",
   "metadata": {},
   "source": [
    "# Misc Results Chapter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f431f5",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100164fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml'\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3241fd3",
   "metadata": {},
   "source": [
    "## All observations of gesture XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140732e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143cd69",
   "metadata": {
    "code_folding": [
     4
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prettify_sensor_name(sensor_name):\n",
    "    return {\n",
    "        \"l5x\": \"Left Little X\",\n",
    "        \"l5y\": \"Left Little Y\",\n",
    "        \"l5z\": \"Left Little Z\",\n",
    "        \"l4x\": \"Left Ring X\",\n",
    "        \"l4y\": \"Left Ring Y\",\n",
    "        \"l4z\": \"Left Ring Z\",\n",
    "        \"l3x\": \"Left Middle X\",\n",
    "        \"l3y\": \"Left Middle Y\",\n",
    "        \"l3z\": \"Left Middle Z\",\n",
    "        \"l2x\": \"Left Index X\",\n",
    "        \"l2y\": \"Left Index Y\",\n",
    "        \"l2z\": \"Left Index Z\",\n",
    "        \"l1x\": \"Left Thumb X\",\n",
    "        \"l1y\": \"Left Thumb Y\",\n",
    "        \"l1z\": \"Left Thumb Z\",\n",
    "        \"r1x\": \"Right Thumb X\",\n",
    "        \"r1y\": \"Right Thumb Y\",\n",
    "        \"r1z\": \"Right Thumb Z\",\n",
    "        \"r2x\": \"Right Index X\",\n",
    "        \"r2y\": \"Right Index Y\",\n",
    "        \"r2z\": \"Right Index Z\",\n",
    "        \"r3x\": \"Right Middle X\",\n",
    "        \"r3y\": \"Right Middle Y\",\n",
    "        \"r3z\": \"Right Middle Z\",\n",
    "        \"r4x\": \"Right Ring X\",\n",
    "        \"r4y\": \"Right Ring Y\",\n",
    "        \"r4z\": \"Right Ring Z\",\n",
    "        \"r5x\": \"Right Little X\",\n",
    "        \"r5y\": \"Right Little Y\",\n",
    "        \"r5z\": \"Right Little Z\",\n",
    "    }.get(sensor_name, sensor_name)\n",
    "\n",
    "\n",
    "for gidx in (0, 5, 11, 16, 22, 27, 33, 38, 44, 49):\n",
    "    idxs = np.nonzero(df['gidx'] == gidx)[0]\n",
    "    cross_idxs = idxs[:, np.newaxis] + np.arange(-10, 21)\n",
    "    fig, axs = plt.subplots(6, 5, figsize=(WIDTH, WIDTH*5/6))\n",
    "    axs = vis.cmp_ts(\n",
    "        df[sensor_names].values[cross_idxs],\n",
    "        axs=axs\n",
    "    )\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_title(\n",
    "            prettify_sensor_name(ax.get_title()),\n",
    "            loc='center',\n",
    "            y=0.85,\n",
    "        )\n",
    "        ax.set_ylim((250, 990))\n",
    "\n",
    "    plt.suptitle(f'Gesture {gidx}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_example_g{gidx:0>4}_plot.pdf'\n",
    "    )\n",
    "    plt.show()\n",
    "# for ax in axs[:, -1]:\n",
    "#     ax.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62187c",
   "metadata": {},
   "source": [
    "## Correlations between the different gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0\n",
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())\n",
    "X_data = X_trn[y_trn != 50][:, timestep, :]\n",
    "y_data = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70849870",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    5, 10,\n",
    "    figsize=(WIDTH, WIDTH*2),\n",
    "    dpi=200,\n",
    ")\n",
    "for i in range(5):\n",
    "    print(f'gesture {i}_', flush=True)\n",
    "    for j in range(10):\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(X_data[y_data == (i * 10 + j)]).corr(),\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            ax=axs[i, j],\n",
    "            xticklabels=[s.upper() for s in sensor_names],\n",
    "            yticklabels=[s.upper() for s in sensor_names],\n",
    "            square=True,\n",
    "        )\n",
    "        axs[i, j].set_title(f'Gesture {i * 10 + j}')\n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    pd.DataFrame(X_data).corr(),\n",
    "    vmin=-1, \n",
    "    vmax=1,\n",
    "    center=0,\n",
    "#     cbar=False,\n",
    "    xticklabels=[s.upper() for s in sensor_names],\n",
    "    yticklabels=[s.upper() for s in sensor_names],\n",
    "    square=True,\n",
    ")\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Sensor')\n",
    "plt.title('Correlations between sensors\\n(over all training data)')\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_correlations.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711495e",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3))\n",
    "axis = ['X', 'Y', 'Z']\n",
    "for i in range(3):\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(X_data[:, i::3]).corr(),\n",
    "        vmin=-1, \n",
    "        vmax=1,\n",
    "        center=0,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        ax=axs[i]\n",
    "    )\n",
    "    axs[i].set_title(f'Correlations between {axis[i]}-axis sensors\\n(over all training data)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f86",
   "metadata": {},
   "source": [
    "## Time-series heatmap + line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_subset(s, f):\n",
    "    df = read.read_data(\n",
    "        '../gesture_data/train/', \n",
    "        constants_path='../src/constants.yaml'\n",
    "    )\n",
    "    df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "    const = common.read_constants('../src/constants.yaml')\n",
    "    sensor_names = list(const['sensors'].values())\n",
    "    data = df[sensor_names].values[s:f]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(WIDTH, WIDTH*.5))\n",
    "    sns.heatmap(\n",
    "        data.T,\n",
    "        ax=axs[0],\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    axs[1].plot(\n",
    "        data,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    plt.margins(0)\n",
    "    plt.show()\n",
    "# plt_subset(91_000, 95_000)\n",
    "plt_subset(93_000, 93_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46355c0e",
   "metadata": {},
   "source": [
    "## Histogram of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gidx'].hist()\n",
    "plt.show()\n",
    "df.loc[df['gidx'] != 50, 'gidx'].hist()\n",
    "df['gidx'].value_counts() / len(df['gidx']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da38f",
   "metadata": {},
   "source": [
    "## All observations of one gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de297a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gidx = 0\n",
    "before = 10\n",
    "after = 10\n",
    "idxs = np.nonzero(df['gidx'] == gidx)[0][:, np.newaxis] + np.arange(-before, after+1)\n",
    "\n",
    "vis.cmp_ts(df[sensor_names].values[idxs + 10]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20810d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-before, after+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01077c33",
   "metadata": {},
   "source": [
    "## 3D plot of the raw acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c84cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vals = df[['l5x', 'l5y', 'l5z']].values[:10000]\n",
    "ax.plot(\n",
    "    vals[:, 0], \n",
    "    vals[:, 1], \n",
    "    vals[:, 2], \n",
    "    label='3D Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97194d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6face1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo-venv",
   "language": "python",
   "name": "ergo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
