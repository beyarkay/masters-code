{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7139088",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a2aca",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change directory to keep paths consistent\n",
    "%cd /Users/brk/projects/masters/SU/ergo/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07445b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "# # NOTE: These two lines let us preview the plots in a notebook, but the inline\n",
    "# # plots will have the *wrong font* ):\n",
    "# from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "# mpl.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     'font.family': 'Cambria',\n",
    "#     'text.usetex': True,\n",
    "#     \"pgf.rcfonts\": False,\n",
    "#     'pgf.texsystem': 'xelatex',\n",
    "#     'pgf.preamble': '\\n'.join([\n",
    "#         r'\\usepackage[math-style=TeX,bold-style=TeX]{unicode-math}',\n",
    "#         r'\\setmainfont{Cambria}',\n",
    "#         r'\\setmathfont{Cambria Math}',\n",
    "#     ])\n",
    "# })\n",
    "\n",
    "# y_trn = np.random.randint(0, 50, (1000,))\n",
    "# WIDTH = 5.5\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5), dpi=200)\n",
    "# counts = pd.Series(y_trn).value_counts()\n",
    "# axs[0].bar(counts.index, counts)\n",
    "\n",
    "# counts = pd.Series(y_trn[y_trn != 50]).value_counts()\n",
    "# axs[1].bar(counts.index, counts)\n",
    "\n",
    "# axs[0].set(\n",
    "#     title='Number of classes\\n',\n",
    "#     xlabel='Class',\n",
    "#     ylabel='Count',\n",
    "# )\n",
    "# axs[1].set_title(\n",
    "#     'Number of classes\\n(excluding class 12345)$12345\\\\frac{1}{2}e^{-x}$',\n",
    "# )\n",
    "# axs[1].set(\n",
    "# #     title=',\n",
    "#     xlabel='Class',\n",
    "#     ylabel='Count',\n",
    "# )\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('tmp.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22165a6e",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d078368",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import vis\n",
    "import common\n",
    "import read\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import tqdm\n",
    "import logging as l\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# NOTE: These two lines let us preview the plots in a notebook, but the inline\n",
    "# plots will have the *wrong font* ):\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "mpl.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Cambria',\n",
    "    'text.usetex': True,\n",
    "    \"pgf.rcfonts\": False,\n",
    "    'pgf.texsystem': 'xelatex',\n",
    "    'pgf.preamble': '\\n'.join([\n",
    "        r'\\usepackage[math-style=TeX,bold-style=TeX]{unicode-math}',\n",
    "        r'\\setmainfont{Cambria}',\n",
    "        r'\\setmathfont{Cambria Math}',\n",
    "    ])\n",
    "})\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     'font.size' : 9,\n",
    "#     'axes.labelsize': 9,\n",
    "#     'legend.fontsize': 9,\n",
    "#     'font.family': 'Cambria',\n",
    "#     \"pgf.rcfonts\": False,\n",
    "#     'pgf.texsystem': 'xelatex',\n",
    "#     'pgf.preamble': '\\n'.join(['',\n",
    "#         r'\\usepackage[math-style=TeX,bold-style=TeX]{unicode-math}',\n",
    "#         r'\\setmainfont{Cambria}',\n",
    "#         r'\\setmathfont{Cambria Math}',\n",
    "#     ])\n",
    "# })\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     'font.size' : 9,                   # Set font size to 11pt\n",
    "#     'axes.labelsize': 9,               # -> axis labels\n",
    "#     'legend.fontsize': 9,              # -> legends\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'text.latex.preamble': (            # LaTeX preamble\n",
    "#         r'\\usepackage{lmodern}'\n",
    "#     )\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbd3fa",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1411",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "def prettify_col_name(x):\n",
    "    return x.split('.')[-1].replace('_', ' ').title()\n",
    "\n",
    "def calculate_prediction_ellipse(x, y, alpha=0.95):\n",
    "    \"\"\"Given some x and y data, calculate the (1-alpha) confidence ellipse.\"\"\"\n",
    "    data = np.column_stack((x, y)) # Combine x and y into a single data array\n",
    "    num_dimensions = data.shape[1]\n",
    "    num_data_points = data.shape[0]\n",
    "    # Estimate the sample covariance matrix\n",
    "    sample_covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Calculate the sample mean for each dimension\n",
    "    sample_mean = np.mean(data, axis=0)\n",
    "    # Generate angles for the ellipse\n",
    "    theta = np.linspace(0, 2*np.pi, num=100)\n",
    "    # Calculate the radius of the ellipse. `f.ppf` is the inverse of the CDF\n",
    "    radius = np.sqrt(\n",
    "        num_dimensions * (num_data_points - 1) / (num_data_points - num_dimensions) *\n",
    "        (1 + 1/num_data_points) * f.ppf(1 - alpha, num_dimensions, num_data_points - num_dimensions)\n",
    "    )\n",
    "#     print(sample_covariance_matrix)\n",
    "    # Compute the Cholesky decomposition of the covariance matrix\n",
    "    chol_cov_matrix = np.linalg.cholesky(sample_covariance_matrix)\n",
    "    # Generate ellipse offset based on Cholesky decomposition\n",
    "    ellipse_offset = np.outer(np.cos(theta), chol_cov_matrix[0, :]) + np.outer(np.sin(theta), chol_cov_matrix[1, :])\n",
    "    # Calculate the points of the prediction interval ellipse\n",
    "    prediction_ellipse_points = sample_mean + radius * ellipse_offset\n",
    "    return prediction_ellipse_points\n",
    "\n",
    "def get_npz_data_from_model(model_dir):\n",
    "    \"\"\"Given a directory of a model, return it's y_pred and y_true.\"\"\"\n",
    "    data = np.load(f'{model_dir}/y_val_true_y_val_pred.npz')\n",
    "    y_true = data['y_true']\n",
    "    y_pred = data['y_pred']\n",
    "    return y_true, y_pred\n",
    "\n",
    "def show_conf_mat_from_model(model_dir, ax=None):\n",
    "    \"\"\"Given a directory of a model, plot its confidence matrix\"\"\"\n",
    "    y_true, y_pred = get_npz_data_from_model(model_dir)\n",
    "    cm_val = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    p = vis.conf_mat(cm_val / cm_val.sum(axis=0), ax=ax)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46788",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab12f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data from hpar optimisation\n",
    "paths = sorted(glob.glob('../saved_models/results_*_optuna.jsonl'))\n",
    "print(f'Reading data from\\n', \"\\n\".join(paths))\n",
    "dfs = map(\n",
    "    lambda path: pd.read_json(path, lines=True),\n",
    "    paths\n",
    ")\n",
    "# Concat the dataframes together, and then do a \n",
    "# copy to avoid a dataframe fragmentation warning\n",
    "# Reset the index to avoid a seaborn error https://github.com/mwaskom/seaborn/issues/3291\n",
    "df = pd.concat(dfs).reset_index(drop=True).copy()\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].fillna('51')\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].astype(int).astype(str)\n",
    "\n",
    "# 50-class HFFNNs don't make sense, remove them\n",
    "df = df[~(\n",
    "    (df['model_type'] == 'HFFNN')\n",
    "    & (df['preprocessing.num_gesture_classes'] == '50')\n",
    ")]\n",
    "\n",
    "df.groupby(['model_type', 'preprocessing.num_gesture_classes']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7801a6",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colours = {\n",
    "    'FFNN': 'tab:blue',\n",
    "    'HFFNN': 'tab:orange',\n",
    "    'CuSUM': 'tab:green',\n",
    "    'HMM': 'tab:red',\n",
    "    'SVM': 'tab:purple',\n",
    "}\n",
    "palette = 'Spectral'\n",
    "other_colours = [\n",
    "    'tab:brown',\n",
    "    'tab:pink',\n",
    "    'tab:grey',\n",
    "    'tab:olive',\n",
    "    'tab:cyan',\n",
    "]\n",
    "WIDTH = 5.5\n",
    "BIG_WIDTH = WIDTH * 1.4\n",
    "\n",
    "rename_hpars = {\n",
    "    'ffnn.dropout_rate'            : 'Dropout Rate',\n",
    "    'ffnn.l2_coefficient.log10'    : 'L2 ($\\log_{10}$)',\n",
    "    'nn.batch_size.log10'          : 'Batch Size ($\\log_{10}$)',\n",
    "    'nn.learning_rate.log10'       : 'LR ($\\log_{10}$)',\n",
    "    'ffnn.l2_coefficient'          : 'L2 Coef.',\n",
    "    'nn.batch_size'                : 'Batch Size',\n",
    "    'nn.learning_rate'             : 'LR',\n",
    "    'ffnn.num_layers'              : '\\#Layers',\n",
    "    'ffnn.nodes_per_layer.1'       : '\\#Nodes (layer 1)',\n",
    "    'ffnn.nodes_per_layer.2'       : '\\#Nodes (layer 2)',\n",
    "    'ffnn.nodes_per_layer.3'       : '\\#Nodes (layer 3)',\n",
    "    'ffnn.nodes_per_layer.-1'      : '\\#Nodes (last layer)',\n",
    "    'ffnn.nodes_per_layer.1.log10' : '\\#Nodes (layer 1, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.2.log10' : '\\#Nodes (layer 2, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.3.log10' : '\\#Nodes (layer 3, $\\log_{10}$)',\n",
    "    'ffnn.nodes_per_layer.-1.log10': '\\#Nodes (last layer, $\\log_{10}$)',\n",
    "    'val.macro avg.f1-score'       : '$F_1$-score',\n",
    "    'val.macro avg.recall'         : 'Recall',\n",
    "    'val.macro avg.precision'      : 'Precision',\n",
    "    'val.loss.log10'               : 'Val. Loss ($\\log_{10}$)',\n",
    "    'trn.loss.log10'               : 'Trn. Loss ($\\log_{10}$)',\n",
    "    'val.loss'                     : 'Val. Loss',\n",
    "    'trn.loss'                     : 'Trn. Loss',\n",
    "}\n",
    "# Add rename cols for the HFFNNs\n",
    "rename_hpars |= {\n",
    "    f'hffnn.majority.{k}': f'Maj. {v}' for k, v in rename_hpars.items() if 'nn.' in k\n",
    "} | {\n",
    "    f'hffnn.minority.{k}': f'Min. {v}' for k, v in rename_hpars.items() if 'nn.' in k\n",
    "}\n",
    "\n",
    "stripplot_kwargs = dict(\n",
    "    s=2.5,\n",
    "    linewidth=.1,\n",
    "    alpha=0.75,\n",
    "    edgecolor='#000a',\n",
    ")\n",
    "\n",
    "scatterplot_kwargs = dict(\n",
    "    s=5,\n",
    "    edgecolor='#000a',\n",
    "    linewidth=0.1,\n",
    "    alpha=0.75,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1f85",
   "metadata": {},
   "source": [
    "## Calculate some auxillary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18c065",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data a little bit, and get a list of dependant variables\n",
    "# Preprocess the df a bit to get some nice-to-use columns\n",
    "\n",
    "# Convert nodes_per_layer into nodes_per_layer.1, .2, .3\n",
    "prefixes = (\n",
    "    'ffnn.nodes_per_layer',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer',\n",
    ")\n",
    "for prefix in prefixes:\n",
    "    for i in (1, 2, 3):\n",
    "        df[f'{prefix}.{i}'] = df[prefix].apply(\n",
    "            lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else None\n",
    "        )\n",
    "    df[f'{prefix}.-1'] = df[prefix].apply(\n",
    "        lambda x: x[-1] if isinstance(x, list) and len(x) >= 1 else None\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate ratios\n",
    "avgs = ('macro avg', 'weighted avg')\n",
    "metrics = ('f1-score', 'precision', 'recall')\n",
    "\n",
    "for avg in avgs:\n",
    "    for metric in metrics:\n",
    "        df[f'ratio.{avg}.{metric}'] = df[f'trn.{avg}.{metric}'] / df[f'val.{avg}.{metric}']\n",
    "        df[f'ratio.{avg}.{metric}'] = np.where(\n",
    "            np.isfinite(df[f'ratio.{avg}.{metric}']),\n",
    "            df[f'ratio.{avg}.{metric}'],\n",
    "            np.nan\n",
    "        )\n",
    "df['ratio.loss'] = df['trn.loss'] / df['val.loss']\n",
    "\n",
    "# Print out a list of dependant variables\n",
    "# dep_vars = sorted([\n",
    "#     c for c in df.columns \n",
    "#     if 'val' not in c and 'trn' not in c and 'ratio' not in c and c not in (\n",
    "#         'saved_at', 'fit_time', 'preprocessing.gesture_allowlist', \n",
    "# )], key=lambda c: str(c))\n",
    "# print(f\"Dependant variables: {dep_vars}\")\n",
    "# print(\"\\nVariables which change:\")\n",
    "# max_len = max(map(lambda x: len(x), dep_vars))\n",
    "# Print out all dependant variables that change\n",
    "# for var in dep_vars:\n",
    "#     uniq = df[var].apply(lambda x: str(x) if isinstance(x, list) else x).unique()\n",
    "#     if len(uniq) > 1:\n",
    "#         print(f\"{var: <{max_len}} {uniq}\")\n",
    "        \n",
    "df['ffnn.dropout_rate'] = np.round(df['ffnn.dropout_rate'], 6)\n",
    "\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['trn.pred_time_per_obs'] = df['trn.pred_time'] / df['trn.num_observations']\n",
    "df['fit_time_per_obs'] = df['fit_time'] / df['trn.num_observations']\n",
    "\n",
    "\n",
    "# Add some log10 columns\n",
    "log10_cols = [\n",
    "    'val.loss',\n",
    "    'trn.loss',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    "    'ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer.-1',\n",
    "    'hffnn.majority.ffnn.l2_coefficient',\n",
    "    'hffnn.minority.ffnn.l2_coefficient',\n",
    "    'hffnn.majority.nn.batch_size',\n",
    "    'hffnn.minority.nn.batch_size',\n",
    "    'hffnn.majority.nn.learning_rate',\n",
    "    'hffnn.minority.nn.learning_rate',\n",
    "]\n",
    "\n",
    "df[[f'{c}.log10' for c in log10_cols]] = np.log10(df[log10_cols])\n",
    "# df[[f'{c}.log10' for c in log10_cols]] = df[[f'{c}.log10' for c in log10_cols]].fillna(0)\n",
    "\n",
    "for c in log10_cols:\n",
    "    if df[f'{c}.log10'].isna().any():\n",
    "        print(f\"{df[f'{c}.log10'].isna().sum()} NaNs in {c}.log10\")\n",
    "\n",
    "# There are a *lot* of columns. Here's a more-useful subset\n",
    "subset_cols = [\n",
    "    c for c in df.columns\n",
    "    if (not re.search(r'((trn|val)\\.\\d+\\.)|weighted avg', c)) and \n",
    "        (c not in [\n",
    "            'hmm', 'lstm', 'ffnn', 'nn', 'hffnn', 'cusum', 'svm',\n",
    "            'preprocessing.n_timesteps',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "        ])\n",
    "]\n",
    "\n",
    "df['ffnn.num_layers'] = df['ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")\n",
    "df['hffnn.majority.ffnn.num_layers'] = df['hffnn.majority.ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")\n",
    "df['hffnn.minority.ffnn.num_layers'] = df['hffnn.minority.ffnn.nodes_per_layer'].apply(\n",
    "    lambda x: np.nan if type(x) is not list else len(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df['model_type'] == \"HFFNN\")\n",
    "    & (df['preprocessing.num_gesture_classes'] == '51')\n",
    "].groupby(['hffnn.majority.ffnn.num_layers']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance charactersitcs of the models\")\n",
    "(\n",
    "    df\n",
    "    .groupby(['model_type', 'preprocessing.num_gesture_classes'])\n",
    "    ['val.macro avg.f1-score']\n",
    "    .agg(['min', 'median', 'max'])\n",
    "#     .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5643dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "fig, axs = plt.subplots(3, 1, figsize=(WIDTH, WIDTH))\n",
    "ngestures = ('51', '50', '5')\n",
    "xmin = None\n",
    "xmax = None\n",
    "for ax, ngesture in zip(axs, ngestures):\n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == ngesture],\n",
    "        x='saved_at',\n",
    "        y='preprocessing.seed',\n",
    "        hue='model_type',\n",
    "        s=10,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "    #     alpha=0.1,\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    ax.set_title(f'{ngesture} gestures')\n",
    "#     if xmin is None: xmin = ax.get_xlim()[0]\n",
    "#     if xmax is None: xmax = ax.get_xlim()[1]\n",
    "#     xmin = min(xmin, ax.get_xlim()[0])\n",
    "#     xmax = min(xmax, ax.get_xlim()[1])\n",
    "# for ax in axs:\n",
    "#     ax.set_xlim((xmin, xmax))\n",
    "plt.tight_layout()\n",
    "\n",
    "print(df.shape)\n",
    "df = df[\n",
    "    (df['model_type'] != 'HFFNN')\n",
    "    | (df['saved_at'] > pd.to_datetime('2023-10-01T11:00:00'))\n",
    "]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eeb4a",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a664e",
   "metadata": {},
   "source": [
    "## Bar plot of number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f504e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "counts = pd.Series(y_trn).value_counts()\n",
    "axs[0].bar(counts.index, counts)\n",
    "\n",
    "\n",
    "counts = pd.Series(y_trn[y_trn != 50]).value_counts()\n",
    "axs[1].bar(counts.index, counts)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Number of classes\\n',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Number of classes\\n(excluding class 50)',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_class_imbalance.pdf',\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4427f33",
   "metadata": {},
   "source": [
    "### 51 classes, Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "# recall_grid, precision_grid = np.meshgrid(\n",
    "#     np.linspace(0, 1, 100), \n",
    "#     np.linspace(0, 1, 100)\n",
    "# )\n",
    "# f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "# contours = axs[0].contour(\n",
    "#     recall_grid, \n",
    "#     precision_grid,\n",
    "#     f1_score, \n",
    "#     levels=np.linspace(0.1, 1, 10), \n",
    "#     colors='black',\n",
    "#     alpha=0.25\n",
    "# )\n",
    "# axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "#     s=5,\n",
    "#     alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    "#     edgecolor=None,\n",
    "    **scatterplot_kwargs,\n",
    "    legend=False,\n",
    ")\n",
    "axs[1].set_xlim((-0.1, 1.1))\n",
    "axs[1].set_ylim((-0.1, 1.1))\n",
    "# axs[1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[1].set_title(f'Precision vs Recall\\n51-classes')\n",
    "axs[1].set_xlabel(f'Precision')\n",
    "axs[1].set_ylabel(f'Recall')\n",
    "# axs[0].legend().set_title(\"Model \")\n",
    "\n",
    "\n",
    "order = ['FFNN', 'SVM', 'HFFNN', 'HMM', 'CuSUM']\n",
    "sns.stripplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='model_type',\n",
    "#     s=2,\n",
    "#     alpha=0.5,\n",
    "#     order=list(model_colours.keys()),\n",
    "    **stripplot_kwargs,\n",
    "    jitter=0.3, \n",
    "    order=order,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     hue_order=order,\n",
    "    ax=axs[0],\n",
    "    legend=False,\n",
    ")\n",
    "axs[0].set_title(f'$F_1$-score vs Model Type\\n51-classes')\n",
    "axs[0].set_xlabel(f'Model Type')\n",
    "axs[0].set_ylabel(f'$F_1$-score')\n",
    "axs[0].set_ylim((-0.1, 1.1))\n",
    "axs[0].grid(axis='y')\n",
    "\n",
    "vis.add_grid(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_51_classes.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00f5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "data = df.loc[\n",
    "    df['preprocessing.num_gesture_classes'] == '51',\n",
    "    ['model_type', 'val.macro avg.recall', 'val.macro avg.precision']\n",
    "].melt(\n",
    "    id_vars=['model_type'], \n",
    "    var_name='metric', \n",
    "    value_name='value'\n",
    ")\n",
    "data['metric'] = data['metric'].replace({\n",
    "    'val.macro avg.recall': 'Recall',\n",
    "    'val.macro avg.precision': 'Precision',\n",
    "})\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x=\"model_type\", \n",
    "    y=\"value\", \n",
    "    hue=\"metric\",\n",
    "    order=list(model_colours.keys()),\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    alpha=0.75,\n",
    "    size=2,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "\n",
    "ax.set_title(f'Precision and recall for all model types')\n",
    "ax.set_xlabel(f'Model Type')\n",
    "ax.set_ylabel(f'Metric Value')\n",
    "ax.legend().set_title(\"Metric\")\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "ax.set_yticklabels(np.round(np.arange(0, 1.1, .1), 1))\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_precision_recall_stripplot.pdf', \n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1b84",
   "metadata": {},
   "source": [
    "### Precision vs Recall for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760213ee",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3.))\n",
    "n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "# recall_grid, precision_grid = np.meshgrid(\n",
    "#     np.linspace(0, 1, 100), \n",
    "#     np.linspace(0, 1, 100)\n",
    "# )\n",
    "# f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for ax, n_classes in zip(axs, n_gesture_classes):\n",
    "#     contours = ax.contour(\n",
    "#         recall_grid, \n",
    "#         precision_grid,\n",
    "#         f1_score, \n",
    "#         levels=np.linspace(0.1, 1, 5), \n",
    "#         colors='black',\n",
    "#         alpha=0.25\n",
    "#     )\n",
    "#     ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == n_classes],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=2.5,\n",
    "        alpha=0.5,\n",
    "        hue='model_type',\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    ax.set_xlim((-0.1, 1.1))\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{n_classes} gesture classes')\n",
    "#     ax.legend().set_title('Model Type')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4e33f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "# n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "# recall_grid, precision_grid = np.meshgrid(\n",
    "#     np.linspace(0, 1, 100), \n",
    "#     np.linspace(0, 1, 100)\n",
    "# )\n",
    "# f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for model_type in model_colours.keys():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "    \n",
    "#     contours = ax.contour(\n",
    "#         recall_grid, \n",
    "#         precision_grid,\n",
    "#         f1_score, \n",
    "#         levels=np.linspace(0.1, 1, 10), \n",
    "#         colors='black',\n",
    "#         alpha=0.25\n",
    "#     )\n",
    "#     ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['model_type'] == model_type],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=10,\n",
    "#         alpha=0.5,\n",
    "        hue='preprocessing.num_gesture_classes',\n",
    "        style='preprocessing.num_gesture_classes',\n",
    "        hue_order=['5', '50', '51'],\n",
    "        style_order=['5', '50', '51'],\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "    ax.set_xlim((-0.05, 1.05))\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{model_type} $F_1$-score by number of classes')\n",
    "    ax.legend().set_title('Number of classes')\n",
    "    \n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_f1_by_num_gesture_classes_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77f603",
   "metadata": {},
   "source": [
    "## Best model by highest lower 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109bfea",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the best model\n",
    "from scipy import stats\n",
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight'],\n",
    "}\n",
    "\n",
    "def tenth_conf_interval(series):\n",
    "    mean = np.mean(series)\n",
    "    sem = stats.sem(series)\n",
    "    if sem == 0:\n",
    "        return mean\n",
    "    confidence_interval = stats.t.interval(\n",
    "        0.90, \n",
    "        len(series) - 1, \n",
    "        loc=mean, \n",
    "        scale=sem\n",
    "    )\n",
    "#     print(mean, sem, confidence_interval)\n",
    "    return confidence_interval[0]\n",
    "\n",
    "\n",
    "all_hpars = ['model_type'] + [\n",
    "    item \n",
    "    for sublist in list(type_to_hpars.values()) \n",
    "    for item in sublist\n",
    "]\n",
    "\n",
    "subset = df[(df['preprocessing.num_gesture_classes'] == '51')]\n",
    "# print(subset.shape)\n",
    "gb = subset.groupby(all_hpars, dropna=False)\n",
    "subset['val.macro avg.f1-score.count'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "subset = subset[\n",
    "    subset['val.macro avg.f1-score.count'].between(5, 100)\n",
    "]\n",
    "\n",
    "subset['val.macro avg.f1-score.tenth_conf_interval'] = (\n",
    "    gb['val.macro avg.f1-score']\n",
    "    .transform(tenth_conf_interval)\n",
    ")\n",
    "subset['val.macro avg.f1-score.mean']  = gb['val.macro avg.f1-score'].transform('mean')\n",
    "subset['val.macro avg.f1-score.min']   = gb['val.macro avg.f1-score'].transform('min')\n",
    "subset['val.macro avg.f1-score.max']   = gb['val.macro avg.f1-score'].transform('max')\n",
    "subset['val.macro avg.f1-score.std']   = gb['val.macro avg.f1-score'].transform('std')\n",
    "subset['val.macro avg.f1-score.count'] = gb['val.macro avg.f1-score'].transform('count')\n",
    "\n",
    "subset['group_idx'] = gb.ngroup()\n",
    "subset = subset.sort_values('val.macro avg.f1-score.tenth_conf_interval')\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07205941",
   "metadata": {},
   "source": [
    "### Table of fitting times per model/nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight'],\n",
    "}\n",
    "\n",
    "all_hpars = ['preprocessing.num_gesture_classes', 'model_type'] + [\n",
    "    item \n",
    "    for sublist in list(type_to_hpars.values()) \n",
    "    for item in sublist\n",
    "]\n",
    "\n",
    "\n",
    "# print(subset.shape)\n",
    "gb = df.groupby(all_hpars, dropna=False)\n",
    "df['group_idx'] = gb.ngroup()\n",
    "\n",
    "table = (\n",
    "    df[df['preprocessing.rep_num'] == 4]\n",
    "    .groupby([\n",
    "        'model_type', 'preprocessing.num_gesture_classes'\n",
    "    ])\n",
    "    ['group_idx']\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .sort_values(['model_type', 'preprocessing.num_gesture_classes'])\n",
    "    .pivot(\n",
    "        columns='model_type', \n",
    "        index='preprocessing.num_gesture_classes',\n",
    "    )\n",
    "    .T\n",
    ")\n",
    "display(table)\n",
    "display(table.sum())\n",
    "display(table.T.sum())\n",
    "display(table.sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefb8a4",
   "metadata": {},
   "source": [
    "### Table of fitting times per model/nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_to_hms(s):\n",
    "#     print(series)\n",
    "#     s = series['fit_time']\n",
    "    h = np.floor(s / (60 * 60)).astype(int)\n",
    "    m = np.floor((s - 60*60*h) / (60)).astype(int)\n",
    "    s = s - 60*60*h - 60*m\n",
    "    \n",
    "    h_str = '' if h == 0 else f'{h: >2}h '\n",
    "    m_str = '' if m == 0 and h == 0 else f'{m: >2}m '\n",
    "    s_str = '' if s == 0 and m == 0 and h == 0  else f'{s: >5.2f}s'\n",
    "    return f'{h_str}{m_str}{s_str}'\n",
    "\n",
    "display(\n",
    "    df[df['preprocessing.rep_num'] == 4]\n",
    "    .groupby([\n",
    "        'model_type', 'preprocessing.num_gesture_classes'\n",
    "    ])\n",
    "    ['fit_time']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .assign(**{\n",
    "        'fit_time': lambda x: [s_to_hms(xi) for xi in x['fit_time']]\n",
    "    })\n",
    "    .sort_values(['model_type', 'preprocessing.num_gesture_classes'])\n",
    "    .pivot(\n",
    "        columns='model_type', \n",
    "        index='preprocessing.num_gesture_classes',\n",
    "    ).T\n",
    ")\n",
    "# Grouped by model type\n",
    "display(\n",
    "    df[df['preprocessing.rep_num'] == 4]\n",
    "    .groupby(['model_type'])\n",
    "    ['fit_time']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .assign(**{\n",
    "        'fit_time': lambda x: [s_to_hms(xi) for xi in x['fit_time']]\n",
    "    })\n",
    ")\n",
    "# Grouped by n gesture classes\n",
    "display(\n",
    "    df[df['preprocessing.rep_num'] == 4]\n",
    "    .groupby(['preprocessing.num_gesture_classes'])\n",
    "    ['fit_time']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .assign(**{\n",
    "        'fit_time': lambda x: [s_to_hms(xi) for xi in x['fit_time']]\n",
    "    })\n",
    ")\n",
    "\n",
    "display(s_to_hms(\n",
    "    df[df['preprocessing.rep_num'] == 4]\n",
    "    .groupby(['preprocessing.num_gesture_classes'])\n",
    "    ['fit_time']\n",
    "    .sum()\n",
    "    .sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccbc02",
   "metadata": {},
   "source": [
    "### Plot models grouped by hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0df26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, 5))\n",
    "\n",
    "order = subset.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval'\n",
    ")['group_idx'].unique()\n",
    "\n",
    "sns.stripplot(\n",
    "    data=subset,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "#     legend=False,\n",
    "    order=order,\n",
    "    size=2,\n",
    "#     alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=subset, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=2, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='$F_1$ score for each set of hyperparameters, by model type',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    "    ylim=((-0.05, 1.05)),\n",
    "    xticks=[],\n",
    ")\n",
    "\n",
    "vis.add_grid(ax)\n",
    "# ax.set_xticks(ax.get_xticks())\n",
    "# ax.set_xticklabels(\n",
    "#     order,\n",
    "#     rotation=90,\n",
    "# )\n",
    "\n",
    "\n",
    "# vis.fmt_legend(ax)\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# ax.add_artist(plt.legend(handles[:-5], labels[:-5], title=\"Model Type\"))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(\n",
    "    handles=handles[:-5],\n",
    "    labels=labels[:-5],\n",
    "    borderpad=0.5,\n",
    "    labelspacing=0.1,\n",
    "    handlelength=0.1,\n",
    "    title='Model Type',\n",
    "    loc='upper left',\n",
    ")\n",
    "\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_all_f1_scores.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8d7c5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, 2.5))\n",
    "\n",
    "order = subset.sort_values(\n",
    "    'val.macro avg.f1-score.tenth_conf_interval',\n",
    "    ascending=False,\n",
    ")['group_idx'].unique()[:50][::-1]\n",
    "\n",
    "data = subset[subset['group_idx'].isin(order)]\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='group_idx',\n",
    "    hue='model_type',\n",
    "    order=order,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     size=4,\n",
    "    **stripplot_kwargs,\n",
    "    jitter=False,\n",
    "#     alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=data, \n",
    "    x=\"group_idx\", \n",
    "    y=\"val.macro avg.f1-score\", \n",
    "    hue=\"model_type\",\n",
    "    linestyle=\"none\", \n",
    "    errorbar=None,\n",
    "    marker=\"_\", \n",
    "    markersize=4, \n",
    "    palette='dark:black',\n",
    "    markeredgewidth=1,\n",
    "    zorder=10,\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title=f'$F_1$-score for the top {len(order)} hyperparameters\\n'\n",
    "    '(ordered by the lower bound of the 90\\% CI)',\n",
    "    xlabel='Hyperparameter index',\n",
    "    ylabel='$F_1$-score',\n",
    ")\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(\n",
    "    order,\n",
    "    rotation=90,\n",
    ")\n",
    "yticks = np.linspace(\n",
    "    data['val.macro avg.f1-score'].min() * 0.95,\n",
    "    data['val.macro avg.f1-score'].max() / 0.95,\n",
    "    10,\n",
    ")\n",
    "ax.set(\n",
    "    yticks=yticks,    \n",
    "    yticklabels=np.round(yticks, 2),    \n",
    ")\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# ax.add_artist(plt.legend(handles[:5], labels[:5], title=\"Model Type\"))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(\n",
    "    handles=handles[:5],\n",
    "    labels=labels[:5],\n",
    "    borderpad=0.5,\n",
    "    labelspacing=0.1,\n",
    "    handlelength=0.1,\n",
    "    title='Model Type',\n",
    "#     **kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_best_hpar_comparison.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c67d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best model:\")\n",
    "from pprint import pprint\n",
    "pprint(\n",
    "    subset\n",
    "    .sort_values('val.macro avg.f1-score.tenth_conf_interval', ascending=False)\n",
    "    .groupby('group_idx')\n",
    "    .tail(1)\n",
    "#     [type_to_hpars['FFNN']]\n",
    "    .head(1)\n",
    "    .squeeze()\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea557ab",
   "metadata": {
    "code_folding": [
     2,
     43,
     56
    ]
   },
   "outputs": [],
   "source": [
    "model_type = 'FFNN'\n",
    "\n",
    "def prettify_col(col):\n",
    "    return {\n",
    "        'val.macro avg.f1-score.mean': '$F_1$-score Mean',\n",
    "        'val.macro avg.f1-score.std': '$F_1$-score Std.Dev.',\n",
    "        'group_idx': 'Index',\n",
    "        'cusum.thresh': 'Threshold',\n",
    "        'ffnn.dropout_rate': 'Dropout Rate',\n",
    "        'ffnn.l2_coefficient': 'L2 Coefficient',\n",
    "        'ffnn.l2_coefficient.log10': '$\\log_{10}(\\text{L2 Coefficient})$',\n",
    "        'ffnn.nodes_per_layer.1': 'Nodes (layer 1)',\n",
    "        'ffnn.nodes_per_layer.2': 'Nodes (layer 2)',\n",
    "        'ffnn.nodes_per_layer.3': 'Nodes (layer 3)',\n",
    "        'hffnn.majority.ffnn.dropout_rate': 'Majority: Dropout Rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient': 'Majority: L2 Coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1': 'Majority: Nodes (layer 1)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2': 'Majority: Nodes (layer 2)',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3': 'Majority: Nodes (layer 3)',\n",
    "        'hffnn.majority.nn.batch_size': 'Majority: Batch Size',\n",
    "        'hffnn.majority.nn.epochs': 'Majority: Epochs',\n",
    "        'hffnn.majority.nn.learning_rate': 'Majority: Learning Rate',\n",
    "        'hffnn.majority.nn.optimizer': 'Majority: Optimizer',\n",
    "        'hffnn.minority.ffnn.dropout_rate': 'Minority: Dropout Rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient': 'Minority: L2 Coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1': 'Minority: Nodes (layer 1)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2': 'Minority: Nodes (layer 2)',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3': 'Minority: Nodes (layer 3)',\n",
    "        'hffnn.minority.nn.batch_size': 'Minority: Batch Size',\n",
    "        'hffnn.minority.nn.epochs': 'Minority: Epochs',\n",
    "        'hffnn.minority.nn.learning_rate': 'Minority: Learning Rate',\n",
    "        'hffnn.minority.nn.optimizer': 'Minority: Optimizer',\n",
    "        'hmm.covariance_type': 'Covariance Type',\n",
    "        'nn.batch_size': 'Batch Size',\n",
    "        'nn.batch_size.log10': '$\\log_{10}(\\text{Batch Size})$',\n",
    "        'nn.epochs': 'Epochs',\n",
    "        'nn.learning_rate': 'Learning Rate',\n",
    "        'nn.learning_rate.log10': '$\\log_{10}(\\text{Learning Rate})$',\n",
    "        'nn.optimizer': 'Optimizer',\n",
    "        'svm.c': 'C',\n",
    "        'svm.class_weight': 'Class Weight',\n",
    "    }.get(col, col)\n",
    "\n",
    "def df_to_latex(df, model_type):\n",
    "    path = f'../../report/src/tables/05_best_{model_type.lower().replace(\" \", \"_\")}_hpars.generated.tex'\n",
    "    print('DONT FORGET TO UPDATE LaTeX tables: ', path)\n",
    "    df.to_latex(\n",
    "        path,\n",
    "        caption=f'Top {len(df)} performing {model_type} hyperparameter combinations, ordered by '\n",
    "                f'the lower bound of the 90 percent confidence interval for $F_1$-score.',\n",
    "        label=f'tab:05_best_{model_type.lower().replace(\" \", \"_\")}_hpars',\n",
    "        index=False,\n",
    "        float_format=lambda x: '%.3e' % x,\n",
    "        na_rep='-'\n",
    "    )\n",
    "\n",
    "for model_type in type_to_hpars.keys():\n",
    "    latex_df = (\n",
    "        subset[\n",
    "            subset['model_type'] == model_type\n",
    "        ]\n",
    "        .sort_values('val.macro avg.f1-score.tenth_conf_interval', ascending=False)\n",
    "        .groupby('group_idx')\n",
    "        .tail(1)\n",
    "        [\n",
    "            ['group_idx', 'val.macro avg.f1-score.mean', 'val.macro avg.f1-score.std'] \n",
    "            + type_to_hpars[model_type]\n",
    "        ]\n",
    "        .head(10)\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns=prettify_col)\n",
    "        .replace({\n",
    "            'tied': 'Tied',\n",
    "            'spherical': 'Spherical',\n",
    "            'diag': 'Diagonal',\n",
    "            'full': 'Full',\n",
    "            'balanced': 'Balanced',\n",
    "        } | {} if model_type != 'SVM' else {\n",
    "            np.nan: 'Unbalanced',\n",
    "        } | {} if model_type not in ('HFFNN', 'FFNN') else {\n",
    "            np.nan: 'None',\n",
    "        })\n",
    "    )\n",
    "    display(latex_df)\n",
    "    \n",
    "    if model_type == 'HFFNN':\n",
    "        majority = latex_df[[c for c in latex_df.columns if 'Minority' not in c]]\n",
    "        minority = latex_df[[c for c in latex_df.columns if 'Majority' not in c]]\n",
    "        majority.columns = [c.replace(\"Majority: \", \"\") for c in majority.columns]\n",
    "        minority.columns = [c.replace(\"Minority: \", \"\") for c in minority.columns]\n",
    "        df_to_latex(majority, 'Majority HFFNN')\n",
    "        df_to_latex(minority, 'Minority HFFNN')\n",
    "    else:\n",
    "        df_to_latex(latex_df, model_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f5a52",
   "metadata": {},
   "source": [
    "### Model types grouped by hpar index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c1d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "fig = plt.figure(figsize=(WIDTH, 7))\n",
    "gs = GridSpec(4, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "ax3 = fig.add_subplot(gs[2, :])\n",
    "ax4 = fig.add_subplot(gs[3, 0])\n",
    "ax5 = fig.add_subplot(gs[3, 1])\n",
    "\n",
    "model_axs = {\n",
    "    'FFNN':  ax1,\n",
    "    'HFFNN': ax2,\n",
    "    'SVM':   ax3,\n",
    "    'HMM':   ax4,\n",
    "    'CuSUM': ax5,\n",
    "}\n",
    "\n",
    "for model_type, color in model_colours.items():\n",
    "    ax = model_axs[model_type]\n",
    "    data = subset[subset['model_type'] == model_type]\n",
    "    \n",
    "    order = data.sort_values(\n",
    "        'val.macro avg.f1-score.tenth_conf_interval'\n",
    "    )['group_idx'].unique()\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='group_idx',\n",
    "#         hue='model_type',\n",
    "        color=color,\n",
    "        order=order,\n",
    "        **(stripplot_kwargs | dict(\n",
    "            size=2.5\n",
    "        )),\n",
    "#         alpha=0.5,\n",
    "        ax=ax,\n",
    "        jitter=False,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    sns.pointplot(\n",
    "        data=data, \n",
    "        x=\"group_idx\", \n",
    "        y=\"val.macro avg.f1-score\", \n",
    "        hue=\"model_type\",\n",
    "        linestyle=\"none\", \n",
    "        errorbar=None,\n",
    "        marker=\"_\", \n",
    "        markersize=2.5 if model_type in ['HFFNN', 'FFNN'] else 5,\n",
    "        palette='dark:black',\n",
    "        markeredgewidth=1,\n",
    "        zorder=10,\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "    )\n",
    "    \n",
    "    ax.set(\n",
    "        title=f'{model_type} $F_1$-scores',\n",
    "        xlabel='Hyperparameter index',\n",
    "        ylabel='$F_1$-score',\n",
    "        ylim=((-0.05, 1.05)),\n",
    "        yticks=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    )\n",
    "    ax.yaxis.grid(True)\n",
    "#     ax.set_xticks(ax.get_xticks())\n",
    "#     ax.set_xticklabels(order, rotation=90)\n",
    "\n",
    "    xticks = ax.get_xticks()\n",
    "    if len(xticks) > 10:\n",
    "        ax.set_xticks([xticks[i] for i in range(len(xticks)) if i % 8 == 0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_hpar_comparison_per_model_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713a7c1",
   "metadata": {},
   "source": [
    "## ECDF for all model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c426d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "for model_type, color in model_colours.items():\n",
    "    scores = df.loc[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type),\n",
    "        'val.macro avg.f1-score'\n",
    "    ]\n",
    "    sorted_scores = np.sort(scores)\n",
    "    ecdf = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "    ax.plot(ecdf, sorted_scores, color=color, label=model_type)\n",
    "plt.legend()\n",
    "ax.set(\n",
    "    title='ECDF for all model types',\n",
    "    ylabel='$F_1$-score',\n",
    "    xlabel='Cumulative Probability',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ec2db",
   "metadata": {},
   "source": [
    "## Training vs Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ba735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'])\n",
    "df['trn.pred_time_per_obs.log10'] = np.log10(df['trn.pred_time_per_obs'])\n",
    "df['fit_time_per_obs.log10'] = np.log10(df['fit_time_per_obs'])\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs.log10',\n",
    "    y='trn.pred_time_per_obs.log10',\n",
    "#     s=5,\n",
    "#     edgecolor=None,\n",
    "#     linewidth=0.5,\n",
    "    **scatterplot_kwargs,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    x='fit_time_per_obs.log10',\n",
    "    y='trn.pred_time_per_obs.log10',\n",
    "#     s=5,\n",
    "#     edgecolor=None,\n",
    "#     linewidth=0.5,\n",
    "    legend=False,\n",
    "    **scatterplot_kwargs,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation vs Training Inference Time',\n",
    "    xlabel='Validation inference time\\n($\\log_{10}$ seconds/observation)',\n",
    "    ylabel='Training inference time\\n($\\log_{10}$ seconds/observation)',\n",
    "    yticks=np.arange(-6, 0.1, 1),\n",
    "    xticks=np.arange(-6, 0.1, 1),\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Fitting vs inference time',\n",
    "    xlabel='Fitting time\\n($\\log_{10}$ seconds/observation)',\n",
    "#     ylabel='Inference Time\\n($\\log_{10}$ seconds/observation)',\n",
    "    ylabel=None,\n",
    "    yticks=np.arange(-6, 0.1, 1),\n",
    "    xticks=np.arange(-4, -0.9, 0.5),\n",
    "    yticklabels=[],\n",
    ")\n",
    "\n",
    "# for ax in axs.flatten():\n",
    "# axs[0].legend().set_title(\"Model Type\")\n",
    "vis.fmt_legend(axs[0], title='Model Type')\n",
    "\n",
    "vis.add_grid(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_trn_times_per_obs.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473064",
   "metadata": {},
   "source": [
    "## Inference time vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e99dc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    s=5,\n",
    "    edgecolor=None,\n",
    "    linewidth=0.1,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "ax.set_ylabel('$F_1$-score')\n",
    "ax.set_xlabel('Inference time\\n($\\log_{10}$ seconds/observation)')\n",
    "ax.set_title('Inference time per observation against $F_1$ score')\n",
    "ax.legend().set_title(\"Model Type\")\n",
    "\n",
    "vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inference_time_per_obs_vs_f1.pdf', \n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55659bd",
   "metadata": {},
   "source": [
    "## Mean Confidence Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b53dd5",
   "metadata": {},
   "source": [
    "### 5 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0e96d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "nclasses = '5'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "# NOTE: Regular WIDTH is used or else LaTeX throws it's toys out the cot\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat[-1, -1] = 0\n",
    "#     conf_mat /= conf_mat_totals[hpar_item]\n",
    "#     conf_mat /= conf_mat.max()\n",
    "#     print(conf_mat_totals[hpar_item])\n",
    "    # Normalize the matrix manually to get nicer annotations\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n{nclasses} classes'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57977c1",
   "metadata": {},
   "source": [
    "### 50 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1706876",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "nclasses = '50'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "#     vis.conf_mat(conf_mat, ax=axs[i])\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n{nclasses} classes'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbdd51",
   "metadata": {},
   "source": [
    "### 51 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da56ddd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# NOTE: skipping this cell might have been a mistake\n",
    "nclasses = '51'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    try:\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    except FileNotFoundError:\n",
    "        y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90935c87",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "fig, axs = plt.subplots(\n",
    "    3, 2,\n",
    "    figsize=(WIDTH, WIDTH)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.conf_mat(conf_mat / conf_mat.sum(axis=0), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n{nclasses} classes'\n",
    "    )\n",
    "axs[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73941aa8",
   "metadata": {},
   "source": [
    "## Conf Mats for each num-gesture-class with precision-recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d5298",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# recall_grid, precision_grid = np.meshgrid(\n",
    "#     np.linspace(0, 1, 100), \n",
    "#     np.linspace(0, 1, 100)\n",
    "# )\n",
    "# f1_score_grid = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "\n",
    "for model_type in ('FFNN', 'HFFNN', 'SVM', 'CuSUM', 'HMM'):\n",
    "    data = df[\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "\n",
    "    hpar = 'preprocessing.num_gesture_classes'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "    print(model_type, flush=True)\n",
    "\n",
    "    for i, row in data.sort_values(hpar).iterrows():\n",
    "        try:\n",
    "            y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        except FileNotFoundError:\n",
    "            y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        f1_score = sklearn.metrics.f1_score(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] += f1_score\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] = f1_score\n",
    "        if i % 50 == 0:\n",
    "            print(i, end=' ', flush=True)\n",
    "\n",
    "    if model_type == 'HFFNN':\n",
    "        fig, axs = plt.subplots(\n",
    "            1, 2,\n",
    "            figsize=(WIDTH, WIDTH*.5),\n",
    "            squeeze=False,\n",
    "        )\n",
    "    else:\n",
    "        fig, axs = plt.subplots(\n",
    "            2, 2,\n",
    "            figsize=(WIDTH, WIDTH),\n",
    "            squeeze=False,\n",
    "        )\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "        cmat = conf_mat / conf_mat_totals[hpar_item]\n",
    "        vis.conf_mat(cmat, ax=axs[i])\n",
    "        axs[i].set_title(\n",
    "            f'Weighted Confusion Matrix\\n'\n",
    "            f'{model_type} {hpar_item}-class'\n",
    "        )\n",
    "\n",
    "#     contours = axs[-1].contour(\n",
    "#         recall_grid, \n",
    "#         precision_grid,\n",
    "#         f1_score_grid, \n",
    "#         levels=np.linspace(0.1, 1, 10), \n",
    "#         colors='black',\n",
    "#         alpha=0.25\n",
    "#     )\n",
    "#     axs[-1].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['model_type'] == model_type],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "#         s=5,\n",
    "#         alpha=0.5,\n",
    "        hue='preprocessing.num_gesture_classes',\n",
    "        style='preprocessing.num_gesture_classes',\n",
    "        hue_order=['5', '50', '51'],\n",
    "        style_order=['5', '50', '51'],\n",
    "        ax=axs[-1],\n",
    "        **scatterplot_kwargs,\n",
    "#         edgecolor=None,\n",
    "    )\n",
    "    axs[-1].set(\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        title=f'Precision-recall plot\\n{model_type}s by \\#Classes',\n",
    "    )\n",
    "    vis.add_grid(axs[-1])\n",
    "#     axs[-1].plot([0,1], [0,1], color='black', alpha=.25)\n",
    "#     axs[-1].legend().set_title('Classes')\n",
    "    vis.fmt_legend(axs[-1], title='Classes')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_mean_conf_mat_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1fc7b",
   "metadata": {},
   "source": [
    "## Regularization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a3e1d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "n_gesture_classes = (\n",
    "    '5',\n",
    "    '50',\n",
    "    '51',\n",
    ")\n",
    "# TODO this ratio might need to be changed\n",
    "fig, axs = plt.subplots(\n",
    "    3, 2, \n",
    "    figsize=(WIDTH, WIDTH/3.)\n",
    ")\n",
    "\n",
    "for i, ngestures in enumerate(n_gesture_classes):\n",
    "    data = df[df['preprocessing.num_gesture_classes'] == ngestures]\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.l2_coefficient',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 0],\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 1],\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{ngestures} gestures')\n",
    "    axs[i, 1].set_title(f'{ngestures} gestures')\n",
    "\n",
    "plt.suptitle(\"$F_1$-ratio against regularisation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3fa2",
   "metadata": {},
   "source": [
    "## Ratio $F_1$ scores vs actual $F_1$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "#     s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "    ax=axs[0, 0],\n",
    "    **scatterplot_kwargs,\n",
    "#     edgecolor=None,\n",
    ")\n",
    "axs[0, 0].set_xlim((-0.05, 1.05))\n",
    "axs[0, 0].set_ylim((-0.05, 1.05))\n",
    "axs[0, 0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 0].set_title(\"Training vs Val. $F_1$ score\\n\")\n",
    "axs[0, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 0].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 0].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "#     s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "    ax=axs[0, 1],\n",
    "    legend=False,\n",
    "    **scatterplot_kwargs,\n",
    "#     edgecolor=None,\n",
    ")\n",
    "axs[0, 1].set_xlim((0.45, 1.05))\n",
    "axs[0, 1].set_ylim((0.5, 1.05))\n",
    "axs[0, 1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 1].set_title(\"Training vs Val. $F_1$ score\\n(magnified)\")\n",
    "axs[0, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 1].set_ylabel(\"Training $F_1$\")\n",
    "# axs[0, 1].legend().set_title('Model Type')\n",
    "axs[0, 1].set_xticks(np.arange(0.5, 1.01, 0.1))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "#     s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "    legend=False,\n",
    "    ax=axs[1, 0],\n",
    "#     edgecolor=None,\n",
    "    **scatterplot_kwargs,\n",
    ")\n",
    "axs[1, 0].set_xlim((-0.05, 1.05))\n",
    "axs[1, 0].set_title(\"$F_1$-ratio vs $F_1$-score\\n\")\n",
    "axs[1, 0].set_xlabel(\"Val. $F_1$\")\n",
    "axs[1, 0].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Val.}$)\")\n",
    "# axs[1, 0].legend().set_title('Model Type')\n",
    "axs[1, 0].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['val.macro avg.f1-score'] >= 0.5)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "#     s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "    legend=False,\n",
    "    ax=axs[1, 1],\n",
    "#     edgecolor=None,\n",
    "    **scatterplot_kwargs,\n",
    ")\n",
    "axs[1,1].set(\n",
    "    xlim=(0.45, 1.05),\n",
    "    xticks=np.arange(0.5, 1.01, 0.1),\n",
    "    title=\"$F_1$-ratio vs $F_1$-score\\n(magnified)\",\n",
    "    xlabel=\"Val. $F_1$\",\n",
    "    ylabel=r\"$F_1$-ratio ($\\frac{Training}{Val.}$)\",\n",
    ")\n",
    "\n",
    "axs[1, 1].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "vis.fmt_legend(axs[0, 0], title='Model Type')\n",
    "for ax in axs.flat:\n",
    "    vis.add_grid(ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_f1_vs_f1_ratio.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcf2e4",
   "metadata": {},
   "source": [
    "## Training/validation loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7516",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss',\n",
    "    x='trn.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].assign(**{\n",
    "        'ratio.loss': lambda x: x['trn.loss'] / x['val.loss']\n",
    "    }),\n",
    "    x='ratio.loss',\n",
    "    y='val.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[1],\n",
    "    edgecolor=None,\n",
    ")\n",
    "\n",
    "\n",
    "axs[0].set_ylim((-0.05, 3.6))\n",
    "axs[1].set_ylim((-0.05, 3.6))\n",
    "\n",
    "axs[1].plot([1, 1], [0, axs[1].get_ylim()[1]], color='black', alpha=.1)\n",
    "\n",
    "min_max = min(axs[0].get_xlim()[1], axs[0].get_ylim()[1] )\n",
    "axs[0].plot([0, min_max], [0, min_max], color='black', alpha=.1)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation loss vs training loss\\n(FFNN only)',\n",
    "    xlabel='Training Loss',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Validation loss vs loss ratio\\n(FFNN only)',\n",
    "    xlabel=r'Loss ratio ($\\frac{Training}{Validation}$)',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_val_trn_loss_ratios.pdf'\n",
    ")\n",
    "\n",
    "print(\"TODO: The training and validation loss aren't comparable because the training loss is weighed but validation loss is not.\")\n",
    "print(\"TODO: also not comparable because of dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f5df8",
   "metadata": {},
   "source": [
    "## Precision vs Recall plots for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c88f1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "for model_type, color in model_colours.items():\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, fisize=(WIDTH, WIDTH))\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "    print(f\"{p_min=}, {p_max=}, {r_min=}, {r_max=}\")\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        ax=ax,\n",
    "    edgecolor=None,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    ax.set(\n",
    "        title=f\"Precision vs Recall For {model_type} models\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_{model_type.lower()}_p_vs_r.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6c5d8",
   "metadata": {},
   "source": [
    "## In depth FFNN plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef222d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "]\n",
    "hyperpars = [\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.num_layers',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "    'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "data['Recall $>$ 0.7'] = data['val.macro avg.recall'] > 0.7\n",
    "\n",
    "data['ffnn.nodes_per_layer.1.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.2.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.3.log10'].fillna(0, inplace=True)\n",
    "data['ffnn.nodes_per_layer.-1.log10'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b0c87",
   "metadata": {},
   "source": [
    "### Precision recall histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f217f",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(WIDTH, 2))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.histplot(\n",
    "        data=data[data['ffnn.num_layers'] == nlayers],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        binwidth=(0.05, 0.05),\n",
    "        binrange=(\n",
    "            (0.0, 1.0),\n",
    "            (0.0, 1.0)\n",
    "        ),\n",
    "        cmap='Spectral',\n",
    "        vmin=0,\n",
    "        vmax=160,\n",
    "        ax=ax,\n",
    "        cbar=nlayers == 3,\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    \n",
    "    vis.rename_ax(ax)\n",
    "    ax.set(\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(0, 1.01, 0.25),\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        yticks=np.arange(0, 1.01, 0.25),\n",
    "    )\n",
    "    if nlayers != 1:\n",
    "        ax.set(\n",
    "            yticklabels=[],\n",
    "            ylabel=None,\n",
    "        )\n",
    "        \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,c=nlayers,histplot.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036886b",
   "metadata": {},
   "source": [
    "### x=precision y=recall hue=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98b7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    hue='ffnn.num_layers',\n",
    "#     s=2.5,\n",
    "    **scatterplot_kwargs,\n",
    "#     edgecolor='#0005',\n",
    "#     alpha=0.75,\n",
    "    legend=False,\n",
    "    palette=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    ax=axs[1]\n",
    ")\n",
    "# vis.fmt_legend(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "axs[1].set(\n",
    "    xticks=np.arange(0, 1.01, 0.2),\n",
    "    yticks=np.arange(0, 1.01, 0.2),\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='ffnn.num_layers',\n",
    "    hue='ffnn.num_layers',\n",
    "    palette=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    legend=False,\n",
    "#     s=2,\n",
    "    jitter=0.3,\n",
    "#     alpha=0.5, \n",
    "    ax=axs[0],\n",
    "    native_scale=True,\n",
    "    **stripplot_kwargs,\n",
    "#     edgecolor='#0005',\n",
    "#     linewidth=0.5\n",
    ")\n",
    "axs[0].set(\n",
    "    xlim=(0, 4),\n",
    "    xticks=[1, 2, 3],\n",
    "    yticks=np.arange(0, 1.01, 0.2),\n",
    ")\n",
    "vis.add_grid(axs[0])\n",
    "\n",
    "vis.rename_axs(axs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdea624",
   "metadata": {},
   "source": [
    "### x=hpar y=recall, all hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c60aa8",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aspect = 2\n",
    "col_wrap = 3\n",
    "g = sns.catplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.025).melt( \n",
    "        id_vars=['Recall $>$ 0.7'], \n",
    "        value_vars=hyperpars,\n",
    "    ), \n",
    "    x=\"value\", \n",
    "    col=\"variable\",\n",
    "    col_wrap=col_wrap,\n",
    "    hue=\"Recall $>$ 0.7\",\n",
    "    hue_order=[True, False],\n",
    "    kind=\"strip\",\n",
    "    sharex=False,\n",
    "    dodge=True,\n",
    "    **stripplot_kwargs,\n",
    "#     size=4,\n",
    "    jitter=0.25,\n",
    "#     alpha=0.1,\n",
    "    height=WIDTH / col_wrap / aspect,\n",
    "    legend=False,\n",
    "    aspect=aspect,\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    hpar = ax.get_title().split(' = ')[1]\n",
    "    ax.set(\n",
    "        xlabel=f'{rename_hpars[hpar]}',\n",
    "        title=None,\n",
    "        ylabel='Recall $<$ 0.7?'\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,c=hpar,x=hpar,y=recall>70.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b030745",
   "metadata": {},
   "source": [
    "### x=LR y=Nodes layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89885f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Nodes layer 1 vs LR has something happening\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, 0.5*WIDTH))\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.025),\n",
    "    y='ffnn.nodes_per_layer.1.log10',\n",
    "    x='nn.learning_rate.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    **scatterplot_kwargs,\n",
    "#     s=5,\n",
    "#     edgecolor='#0005',\n",
    "    palette='Spectral',\n",
    "    hue_norm=(0, 1),\n",
    "    ax=ax,\n",
    "    legend=False,\n",
    ")\n",
    "vis.rename_ax(ax)\n",
    "ax.set(\n",
    "    xticks=np.arange(-6, -0.9, 0.5),\n",
    "    yticks=np.arange(0.5, 3, 0.25),\n",
    "    xlabel=r'Learning Rate ($\\log_{10}$)',\n",
    ")\n",
    "vis.add_cbar(\n",
    "    fig, ax, data['val.macro avg.f1-score'],\n",
    "    label='$F_1$-score', vmin=0, vmax=1,\n",
    ")\n",
    "vis.add_grid(ax)\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn_x=lr,y=npl1,h=f1.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530833d",
   "metadata": {},
   "source": [
    "### N-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea446a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data\n",
    "    .groupby(['ffnn.num_layers'])\n",
    "    [['val.macro avg.recall',  'val.macro avg.precision', 'val.macro avg.f1-score']]\n",
    "    .agg(['max'])\n",
    "#     .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89777e6",
   "metadata": {},
   "source": [
    "#### x=hpar y=recall, all hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7aed3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "for nlayers in [1, 2, 3]:\n",
    "    aspect=2\n",
    "    subset_hpars = [\n",
    "        hpar for hpar in hyperpars\n",
    "        if data.loc[data['ffnn.num_layers'] == nlayers, hpar].nunique() > 1\n",
    "    ]\n",
    "    print([data.loc[data['ffnn.num_layers'] == nlayers, hpar].nunique() for hpar in hyperpars])\n",
    "    print(subset_hpars)\n",
    "    g = sns.catplot(\n",
    "        data=vis.add_jitter(\n",
    "            data[data['ffnn.num_layers'] == nlayers], subset_hpars\n",
    "        ).melt( \n",
    "            id_vars=['Recall $>$ 0.7'], \n",
    "            value_vars=subset_hpars,\n",
    "        ), \n",
    "        x=\"value\", \n",
    "        col=\"variable\",\n",
    "        col_wrap=2,\n",
    "        hue=\"Recall $>$ 0.7\",\n",
    "        kind=\"violin\",\n",
    "        sharex=False,\n",
    "\n",
    "        dodge=True,\n",
    "        inner='stick',\n",
    "        linewidth=1,\n",
    "        split=True,\n",
    "\n",
    "    #     size=2.5,\n",
    "    #     jitter=0.25,\n",
    "    #     alpha=0.5,\n",
    "        height=WIDTH*0.5 / aspect,\n",
    "        legend=False,\n",
    "        aspect=aspect,\n",
    "    )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        hpar = ax.get_title().split(' = ')[1]\n",
    "        ax.set_title(f'{rename_hpars[hpar]}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99e2c1",
   "metadata": {},
   "source": [
    "#### x=p,y=r,h=lr,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f11b5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Three clusters in top right of precision-recall plots \n",
    "# -> caused by learning rate which needs to be _just_ right.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, 2))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue='nn.learning_rate.log10',\n",
    "        hue_norm=(\n",
    "            data['nn.learning_rate.log10'].min(), \n",
    "            data['nn.learning_rate.log10'].max()\n",
    "        ),\n",
    "        legend=False,\n",
    "        palette='Spectral',\n",
    "        **scatterplot_kwargs,\n",
    "        ax=ax,\n",
    "    )\n",
    "    vis.rename_ax(ax)\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(0, 1.01, 0.25),\n",
    "        yticks=np.arange(0, 1.01, 0.25),\n",
    "    )\n",
    "    if nlayers != 1:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[],\n",
    "        )\n",
    "    vis.add_grid(ax)\n",
    "vis.add_cbar(\n",
    "    fig, axs[-1], data['nn.learning_rate.log10'],\n",
    "    label=vis.rename_hpars['nn.learning_rate.log10']\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=lr,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1026e8f",
   "metadata": {},
   "source": [
    "#### x=lr y=f1,h=lr,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b3c1a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# Three clusters in top right of precision-recall plots \n",
    "# -> caused by learning rate which needs to be _just_ right.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(BIG_WIDTH, 2.5))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(\n",
    "            data[data['ffnn.num_layers'] == nlayers], \n",
    "            hyperpars, \n",
    "            amount=0\n",
    "        ),\n",
    "        x='nn.learning_rate.log10',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='nn.learning_rate.log10',\n",
    "        edgecolor='#0005',\n",
    "        legend=False,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "#         xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(-6, -0.95, 1)\n",
    "    )\n",
    "    if nlayers != 1:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[],\n",
    "        )\n",
    "\n",
    "    vis.add_grid(ax)\n",
    "#     vis.fmt_legend(ax)\n",
    "    vis.rename_ax(ax)\n",
    "vis.add_cbar(\n",
    "    fig, axs[-1], data['nn.learning_rate.log10'],\n",
    "    label=vis.rename_hpars['nn.learning_rate.log10']\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=f1,h=lr,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ae4d4",
   "metadata": {},
   "source": [
    "#### x=lr,y=f1,h=npl-1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715ade5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# The last layer of the FFNNs have a big impact on the overall performance\n",
    "# Generally the best-performing FFNNs have many nodes in the last layer, \n",
    "# and reducing the number of nodes reduces the performance\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0),\n",
    "        x='nn.learning_rate.log10',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='ffnn.nodes_per_layer.-1.log10',\n",
    "        edgecolor='#0005',\n",
    "#         legend=False,\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "#         xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(-6, -1, 1)\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    vis.fmt_legend(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=f1,h=npl-1,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1698c7a",
   "metadata": {},
   "source": [
    "#### x=lr,y=npl-1,h=f1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2c9d6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# nodes in last layer vs learning rate and F_1\n",
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, 2))\n",
    "for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='nn.learning_rate.log10',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "        edgecolor='#0005',\n",
    "        legend=False,\n",
    "        hue_norm=(0, 1),\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "#     if nlayers == 1:\n",
    "#         vis.fmt_legend(ax, title='$F_1$')\n",
    "        \n",
    "    ax.set(\n",
    "        title=f\"{nlayers}-layer FFNNs\",\n",
    "        xlim=(-6.5, -0.5),\n",
    "        xticks=np.arange(-6, -.5, 1),\n",
    "        ylim=(0.5, 2.75),\n",
    "        yticks=np.arange(0.5, 2.75, 0.5),\n",
    "    )\n",
    "    vis.rename_ax(ax)\n",
    "    vis.add_grid(ax)\n",
    "    if nlayers != 1:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[],\n",
    "        )\n",
    "vis.add_cbar(\n",
    "    fig, axs[-1], data['val.macro avg.f1-score'],\n",
    "    label=vis.rename_hpars['val.macro avg.f1-score'],\n",
    "    vmin=0,vmax=1,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=lr,y=npl-1,h=f1,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685667f",
   "metadata": {},
   "source": [
    "#### x=npl1,y=npl2,h=f1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8cd1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# More nodes generally means they do better\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, 5.5))\n",
    "\n",
    "sns.stripplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 1], \n",
    "        hyperpars, \n",
    "        amount=0.05\n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    s=3,\n",
    "    edgecolor='#0005',\n",
    "    linewidth=.25,\n",
    "    legend=False,\n",
    "    jitter=.2,\n",
    "    palette='Spectral',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "# axs[0, 0].set_ylabel(vis.rename_hpars['val.macro avg.f1-score'])\n",
    "# vis.fmt_legend(axs[0, 0], title='$F_1$', loc='upper left')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 2], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 3], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    x='ffnn.nodes_per_layer.1.log10',\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data[data['ffnn.num_layers'] == 3], \n",
    "        hyperpars, \n",
    "    ),\n",
    "    y='ffnn.nodes_per_layer.2.log10',\n",
    "    x='ffnn.nodes_per_layer.3.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    legend=False,\n",
    "    palette='Spectral',\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "for ax, nlayers in zip(axs.flatten(), [1, 2, 3, 3]):\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        xlabel=rename_hpars.get(ax.get_xlabel(), None),\n",
    "        ylabel=rename_hpars.get(ax.get_ylabel(), None),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "    \n",
    "for ax in axs[:, 1]:\n",
    "    vis.add_cbar(\n",
    "        fig, ax, data['val.macro avg.f1-score'],\n",
    "        label=vis.rename_hpars['val.macro avg.f1-score'],\n",
    "        vmin=0, vmax=1,\n",
    "    )    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=npl1,y=npl2,h=f1,c=nlayers.pdf'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fee06",
   "metadata": {},
   "source": [
    "#### x=npl1,y=npl2,z=npl3,h=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a737140",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# 3D plot of npl1 vs npl2 vs npl3 for 3-layer FFNNs\n",
    "fig = plt.figure(dpi=200, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "data_ = vis.add_jitter(\n",
    "    data.loc[data['ffnn.num_layers'] == 3],\n",
    "    ['ffnn.nodes_per_layer.1.log10', 'ffnn.nodes_per_layer.2.log10', 'ffnn.nodes_per_layer.3.log10'],\n",
    "    amount=0.075\n",
    ")\n",
    "norm = plt.Normalize(0, 1)\n",
    "ax.scatter(\n",
    "    data_['ffnn.nodes_per_layer.1.log10'],\n",
    "    data_['ffnn.nodes_per_layer.2.log10'],\n",
    "    data_['ffnn.nodes_per_layer.3.log10'],\n",
    "    c=data_['val.macro avg.f1-score'],\n",
    "    s=1,\n",
    "    alpha=1,\n",
    "    cmap='Spectral',\n",
    "    norm=norm,\n",
    ")\n",
    "ax.set(\n",
    "    xlabel='\\#Nodes (layer 1, $\\log_{10}$)',\n",
    "    ylabel='\\#Nodes (layer 2, $\\log_{10}$)',\n",
    "    zlabel='\\#Nodes (layer 3, $\\log_{10}$)',\n",
    "    title=vis.rename_hpars['val.macro avg.f1-score'] + ' against nodes per layer',\n",
    "    xlim=(0.4, 2.75),\n",
    "    ylim=(0.4, 2.75),\n",
    "    zlim=(0.4, 2.75),\n",
    ")\n",
    "\n",
    "ax.view_init(35, -45)\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=npl1,y=npl2,z=npl3,h=f1.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82c044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # Not for publication -- too big\n",
    "# x=dropout\n",
    "# y=nodes per layer\n",
    "# cols = nlayers\n",
    "# rows = layer index\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10,10))\n",
    "\n",
    "for i, nlayers in enumerate([1,2,3]):\n",
    "    for j, layer_idx in enumerate([1,2,3]):\n",
    "        ax = axs[i, j]\n",
    "        if layer_idx > nlayers:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        data_ = data[data['ffnn.num_layers'] == nlayers]\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=vis.add_jitter(data_, hyperpars, amount=0.05),\n",
    "            x='ffnn.dropout_rate',\n",
    "            hue='val.macro avg.f1-score',\n",
    "            y=f'ffnn.nodes_per_layer.{layer_idx}.log10',\n",
    "            s=20,\n",
    "            legend=False,\n",
    "            edgecolor='#0005',\n",
    "            palette='Spectral',\n",
    "            ax=ax,\n",
    "            hue_norm=(0, 1),\n",
    "#             vmin=0,\n",
    "#             vmax=1,\n",
    "        )\n",
    "        \n",
    "        ax.set(\n",
    "            title=f'{nlayers}-layer FFNNs, layer {layer_idx}',\n",
    "            xlabel=None if nlayers != 3 else ax.get_xlabel(),\n",
    "#             xticks=np.round(ax.get_xticks(), 2),\n",
    "#             xticklabels=[] if nlayers != 3 else np.round(ax.get_xticks(), 2),\n",
    "            ylabel=None if layer_idx != 1 else ax.get_ylabel(),\n",
    "#             yticks=np.round(ax.get_yticks(), 2),\n",
    "#             yticklabels=[] if layer_idx != 1 else np.round(ax.get_yticks(), 2),\n",
    "        )\n",
    "#         vis.fmt_legend(ax)\n",
    "        vis.add_grid(ax)\n",
    "        vis.add_cbar(\n",
    "            fig, ax, data['val.macro avg.f1-score'], \n",
    "            label='$F_1$', vmin=0, vmax=1,\n",
    "        )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d7f7b",
   "metadata": {},
   "source": [
    "#### x=dropout,y=npl-1,h=npl1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a741cb",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(1,3, figsize=(WIDTH,WIDTH*0.5))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "#         s=20,\n",
    "        **scatterplot_kwargs,\n",
    "#         edgecolor='black',\n",
    "    #     legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs\\n'\n",
    "              f'(coloured by {rename_hpars[\"val.macro avg.f1-score\"]})',\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51fffnn,x=dropout,y=npl-1,h=npl1,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6ae63",
   "metadata": {},
   "source": [
    "#### x=dropout,y=f1,h=l2,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50efbff",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(1,3, figsize=(BIG_WIDTH, 2.5))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='val.macro avg.f1-score',\n",
    "        hue='ffnn.l2_coefficient.log10',\n",
    "        hue_norm=(data['ffnn.l2_coefficient.log10'].min(),data['ffnn.l2_coefficient.log10'].max()),\n",
    "        edgecolor='#0005',\n",
    "        s=10,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "        legend=False\n",
    "    )\n",
    "#     vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    vis.rename_ax(ax)\n",
    "    \n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        xticks=np.arange(0, 0.51, 0.1),\n",
    "        xlim=(-0.01, 0.51),\n",
    "        ylabel=None if nlayers != 1 else ax.get_ylabel(),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        yticks=np.arange(0, 1.05, 0.2),\n",
    "        yticklabels=[] if nlayers != 1 else np.round(np.arange(0, 1.05, 0.2), 1),\n",
    "    )\n",
    "vis.add_cbar(\n",
    "    fig, ax, data['ffnn.l2_coefficient.log10'],\n",
    "    label=vis.rename_hpars['ffnn.l2_coefficient.log10'],\n",
    "    vmin=data['ffnn.l2_coefficient.log10'].min(),\n",
    "    vmax=data['ffnn.l2_coefficient.log10'].max(),\n",
    ")    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=dropout,y=f1,h=l2,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60440056",
   "metadata": {},
   "source": [
    "#### x=dropout,y=npl-1,h=npl1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd2b09",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(1,3, figsize=(BIG_WIDTH, 2.5))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "        hue_norm=(0, 1),\n",
    "        s=10,\n",
    "        edgecolor='#0005',\n",
    "        legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "#     vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    vis.rename_ax(ax),\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs',\n",
    "        xticks=np.arange(0, 0.51, 0.1),\n",
    "        xlim=(-0.01, 0.51),\n",
    "        \n",
    "        ylabel=None if nlayers != 1 else ax.get_ylabel(),\n",
    "        ylim=(.5, 2.8),\n",
    "        yticks=np.arange(.5, 2.8, 0.5),\n",
    "        yticklabels=[] if nlayers != 1 else np.round(np.arange(.5, 2.8, 0.5), 1),\n",
    "    )\n",
    "    \n",
    "vis.add_cbar(\n",
    "    fig, ax, data['val.macro avg.f1-score'], vmin=0, vmax=1,\n",
    "    label=vis.rename_hpars['val.macro avg.f1-score'],\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51fffnn,x=dropout,y=npl-1,h=npl1,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c085c",
   "metadata": {},
   "source": [
    "#### loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bbd61",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "## loss ratios\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "# for ax, nlayers in zip(axs, [1, 2, 3]):\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "#     data=data[data['ffnn.num_layers'] == nlayers],\n",
    "    x=np.log10(data['trn.loss']),\n",
    "    y=np.log10(data['val.loss']),\n",
    "    edgecolor='#0005',\n",
    "    hue='ffnn.num_layers',\n",
    "#         style='ffnn.num_layers',\n",
    "    palette='tab10',\n",
    "    s=10,\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].plot(\n",
    "    [-1.25, 0.5],\n",
    "    [-1.25, 0.5],\n",
    "    c='#0005',\n",
    "    alpha=0.5,\n",
    "    linewidth=1,\n",
    ")\n",
    "vis.add_grid(axs[0])\n",
    "vis.fmt_legend(axs[0], title='\\#Layers')\n",
    "axs[0].set(\n",
    "    xlabel='Training Loss ($\\\\log_{10}$)',\n",
    "    ylabel='Validation Loss ($\\\\log_{10}$)',\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "#     data=data[data['ffnn.num_layers'] == nlayers],\n",
    "    y=(data['ratio.loss']),\n",
    "    x=np.log10(data['trn.loss']),\n",
    "    edgecolor='#0005',\n",
    "    hue='ffnn.num_layers',\n",
    "#         style='ffnn.num_layers',\n",
    "    palette='tab10',\n",
    "    s=10,\n",
    "    ax=axs[1],\n",
    ")\n",
    "vis.add_grid(axs[1])\n",
    "vis.fmt_legend(axs[1], title='\\#Layers')\n",
    "axs[1].plot(\n",
    "    [-1.25, 1.0],\n",
    "    [1, 1],\n",
    "    c='#0005',\n",
    "    alpha=0.5,\n",
    "    linewidth=1,\n",
    ")\n",
    "axs[1].set(\n",
    "    ylabel='$\\\\frac{Training}{Validation}$ Loss',\n",
    "    xlabel='Training Loss ($\\\\log_{10}$)',\n",
    ")\n",
    "plt.suptitle(\n",
    "    f'Training and Validation loss'\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=trnloss,y=valloss,h=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "# ratio = training / validation\n",
    "# low ratio -> training lower than validation -> overfitting (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106cc14",
   "metadata": {},
   "source": [
    "#### 1-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[data['ffnn.num_layers'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae7ac1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# Precision-recall plots for 1-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(2, 3, figsize=(BIG_WIDTH, 4))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "#     'ffnn.nodes_per_layer.2.log10',\n",
    "#     'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data1, subset_hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        s=5,\n",
    "        edgecolor='#0005',\n",
    "        legend=data1[hpar].nunique() < 10,\n",
    "        palette='Spectral' if data1[hpar].nunique() > 10 else 'tab10',\n",
    "        ax=ax,\n",
    "    )\n",
    "    if data1[hpar].nunique() > 10:\n",
    "        vis.add_cbar(\n",
    "            fig, ax, data1[hpar],\n",
    "#             label=rename_hpars[hpar],\n",
    "        )\n",
    "    else:\n",
    "        vis.fmt_legend(ax, title=rename_hpars[hpar])\n",
    "    ax.set(\n",
    "        title=rename_hpars[hpar],\n",
    "        xlabel=rename_hpars['val.macro avg.precision'],\n",
    "        ylabel=rename_hpars['val.macro avg.recall'],\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(0, 1.1, 0.25),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )\n",
    "    if i // 3 != (len(axs)-1)//3:\n",
    "        ax.set(\n",
    "            xlabel=None,\n",
    "            xticklabels=[]\n",
    "        )\n",
    "    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    wspace=0.25,\n",
    "    hspace=0.35,\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=hpar,c=hpar,nlayers=1.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb8d9d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hyperparameter-F1 plots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(WIDTH, 4))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "#     'ffnn.nodes_per_layer.2.log10',\n",
    "#     'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    print(hpar)\n",
    "    if data1[hpar].nunique() < 10:\n",
    "        print(hpar, data1[hpar].nunique())\n",
    "        sns.stripplot(\n",
    "            data=data1,\n",
    "            y='val.macro avg.f1-score',\n",
    "            x=hpar,\n",
    "            jitter=0.25,\n",
    "            **stripplot_kwargs,\n",
    "            ax=ax,\n",
    "        )\n",
    "    else:\n",
    "        sns.scatterplot(\n",
    "            data=data1,\n",
    "            y='val.macro avg.f1-score',\n",
    "            x=hpar,\n",
    "            **scatterplot_kwargs,\n",
    "            ax=ax,\n",
    "        )\n",
    "    ax.set(\n",
    "        xlabel=rename_hpars[hpar],\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "    if data1[hpar].nunique() < 10:\n",
    "        ax.set_xticklabels(data1[hpar].unique())\n",
    "\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=hpar,y=f1,c=hpar,nlayers=1.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cbdc9b",
   "metadata": {},
   "source": [
    "#### 2-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['ffnn.num_layers'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac5c1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# Precision-recall plots for 1-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(3, 3, figsize=(WIDTH, 5.5))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "#     'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data2, subset_hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        s=5,\n",
    "        edgecolor='#0005',\n",
    "        legend=data2[hpar].nunique() < 10,\n",
    "        palette='Spectral' if data2[hpar].nunique() > 10 else 'tab10',\n",
    "        ax=ax,\n",
    "    )\n",
    "    if data2[hpar].nunique() > 10:\n",
    "        vis.add_cbar(\n",
    "            fig, ax, data2[hpar],\n",
    "#             label=rename_hpars[hpar],\n",
    "        )\n",
    "    else:\n",
    "        vis.fmt_legend(ax, title=rename_hpars[hpar])\n",
    "    ax.set(\n",
    "        title=rename_hpars[hpar],\n",
    "        xlabel=rename_hpars['val.macro avg.precision'],\n",
    "        ylabel=rename_hpars['val.macro avg.recall'],\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(0, 1.1, 0.25),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )\n",
    "    if i + 3 < len(subset_hyperpars):\n",
    "        ax.set(\n",
    "            xlabel=None,\n",
    "            xticklabels=[]\n",
    "        )\n",
    "    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    wspace=0.25,\n",
    "    hspace=0.35,\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=hpar,c=hpar,nlayers=2.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01bb1d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hyperparameter-F1 plots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(WIDTH, 5.5))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "#     'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    if data2[hpar].nunique() < 10:\n",
    "        sns.stripplot(\n",
    "            data=data2,\n",
    "            y='val.macro avg.f1-score',\n",
    "            jitter=0.25,\n",
    "            **stripplot_kwargs,\n",
    "#             s=2.5,\n",
    "#             linewidth=.5,\n",
    "#             edgecolor='#0005',\n",
    "            ax=ax,\n",
    "        )\n",
    "    else:\n",
    "        sns.scatterplot(\n",
    "            data=data2,\n",
    "            y='val.macro avg.f1-score',\n",
    "            x=hpar,\n",
    "#             s=5,\n",
    "#             edgecolor='#0005',\n",
    "            **scatterplot_kwargs,\n",
    "            ax=ax,\n",
    "        )\n",
    "    ax.set(\n",
    "        xlabel=rename_hpars[hpar],\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "#     if data2[hpar].nunique() < 10:\n",
    "#         ax.set_xticklabels([2])\n",
    "    if data2[hpar].nunique() < 10:\n",
    "        ax.set_xticklabels(data2[hpar].unique())\n",
    "\n",
    "\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# plt.subplots_adjust(\n",
    "#     wspace=0.25,\n",
    "#     hspace=0.35,\n",
    "# )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=hpar,y=f1,c=hpar,nlayers=2.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb26ec2",
   "metadata": {},
   "source": [
    "#### 3-layer FFNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3104c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data[data['ffnn.num_layers'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe02b1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# Precision-recall plots for 1-layer FFNNs with hue for each hyperparameter\n",
    "fig, axs = plt.subplots(3, 3, figsize=(BIG_WIDTH, 5.5))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data3, subset_hyperpars, amount=0.1),\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hpar,\n",
    "        **scatterplot_kwargs,\n",
    "#         s=5,\n",
    "#         edgecolor='#0005',\n",
    "        legend=data3[hpar].nunique() < 10,\n",
    "        palette='Spectral' if data3[hpar].nunique() > 10 else 'tab10',\n",
    "        ax=ax,\n",
    "    )\n",
    "    if data3[hpar].nunique() > 10:\n",
    "        vis.add_cbar(\n",
    "            fig, ax, data3[hpar],\n",
    "#             label=rename_hpars[hpar],\n",
    "        )\n",
    "    else:\n",
    "        vis.fmt_legend(ax, title=rename_hpars[hpar])\n",
    "    ax.set(\n",
    "        title=rename_hpars[hpar],\n",
    "        xlabel=rename_hpars['val.macro avg.precision'],\n",
    "        ylabel=rename_hpars['val.macro avg.recall'],\n",
    "        xlim=(-0.05, 1.05),\n",
    "        ylim=(-0.05, 1.05),\n",
    "        xticks=np.arange(0, 1.1, 0.25),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )\n",
    "    if i + 3 < len(subset_hyperpars):\n",
    "        ax.set(\n",
    "            xlabel=None,\n",
    "            xticklabels=[]\n",
    "        )\n",
    "    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    wspace=0.25,\n",
    "    hspace=0.35,\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=p,y=r,h=hpar,c=hpar,nlayers=3.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7872d4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hyperparameter-F1 plots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(WIDTH, 5.5))\n",
    "axs = axs.flatten()\n",
    "subset_hyperpars = [\n",
    "    'ffnn.num_layers',\n",
    "    'nn.learning_rate.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'ffnn.nodes_per_layer.1.log10',\n",
    "    'ffnn.nodes_per_layer.2.log10',\n",
    "    'ffnn.nodes_per_layer.3.log10',\n",
    "#     'ffnn.nodes_per_layer.-1.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'ffnn.dropout_rate',\n",
    "]\n",
    "for hpar, ax in zip(subset_hyperpars, axs):\n",
    "    if data3[hpar].nunique() < 10:\n",
    "        sns.stripplot(\n",
    "            data=data3,\n",
    "            y='val.macro avg.f1-score',\n",
    "            jitter=0.25,\n",
    "            **stripplot_kwargs,\n",
    "#             s=2.5,\n",
    "#             linewidth=.5,\n",
    "#             edgecolor='#0005',\n",
    "            ax=ax,\n",
    "        )\n",
    "    else:\n",
    "        sns.scatterplot(\n",
    "            data=data3,\n",
    "            y='val.macro avg.f1-score',\n",
    "            x=hpar,\n",
    "            **scatterplot_kwargs,\n",
    "#             s=5,\n",
    "#             edgecolor='#0005',\n",
    "            ax=ax,\n",
    "        )\n",
    "    ax.set(\n",
    "        xlabel=rename_hpars[hpar],\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "#     if data3[hpar].nunique() < 10:\n",
    "#         ax.set_xticklabels([2])\n",
    "    if data3[hpar].nunique() < 10:\n",
    "        ax.set_xticklabels(data3[hpar].unique())\n",
    "\n",
    "\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i % 3 != 0:\n",
    "        ax.set(\n",
    "            ylabel=None,\n",
    "            yticklabels=[]\n",
    "        )    \n",
    "for i in range(len(subset_hyperpars), len(axs)):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.subplots_adjust(\n",
    "#     wspace=0.25,\n",
    "#     hspace=0.35,\n",
    "# )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51ffnn,x=hpar,y=f1,c=hpar,nlayers=3.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146513f",
   "metadata": {},
   "source": [
    "#### x=dropout,y=npl-1,h=npl1,c=nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed410db",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(1,3, figsize=(WIDTH,WIDTH*.5))\n",
    "for ax, nlayers in zip(axs, [1,2,3]):\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data[data['ffnn.num_layers'] == nlayers], hyperpars, amount=0.05),\n",
    "        x='ffnn.dropout_rate',\n",
    "        hue='val.macro avg.f1-score',\n",
    "        y='ffnn.nodes_per_layer.-1.log10',\n",
    "        s=20,\n",
    "        edgecolor='black',\n",
    "    #     legend=False,\n",
    "        palette='Spectral',\n",
    "        ax=ax,\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    ax.set(\n",
    "        title=f'{nlayers}-layer FFNNs\\n'\n",
    "              f'(coloured by {rename_hpars[\"val.macro avg.f1-score\"]})',\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51fffnn,x=dropout,y=npl-1,h=npl1,c=nlayers.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1fef3",
   "metadata": {},
   "source": [
    "# In depth HFFNN plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a4ec8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "maj_min_hyperpars = [\n",
    "    'hffnn.{}.ffnn.dropout_rate',\n",
    "    'hffnn.{}.ffnn.l2_coefficient.log10',\n",
    "    'hffnn.{}.nn.batch_size.log10',\n",
    "    'hffnn.{}.nn.learning_rate.log10',\n",
    "    'hffnn.{}.nn.epochs',\n",
    "    'hffnn.{}.ffnn.num_layers',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.1.log10',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.2.log10',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.3.log10',\n",
    "    'hffnn.{}.ffnn.nodes_per_layer.-1.log10',\n",
    "]\n",
    "\n",
    "hyperpars = [\n",
    "    hpar.format(subtype) \n",
    "    for hpar in maj_min_hyperpars\n",
    "    for subtype in ['majority', 'minority'] \n",
    "]\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'HFFNN')\n",
    "    # some of the HFFNNs didn't get their hyperparameters recorded. Exclude them\n",
    "    & (df['hffnn.majority.ffnn.dropout_rate'].notna())\n",
    "]\n",
    "data['$F_1 >$ 0.5'] = data['val.macro avg.f1-score'] > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70a503",
   "metadata": {},
   "source": [
    "#### x=nlayers,y=f1,h=nlayers,c=majmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c4bbd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(WIDTH, 5))\n",
    "axs = axs.flatten()\n",
    "kwargs_arr = [\n",
    "    dict(\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='Maj. \\#Layers',\n",
    "        hue='Min. \\#Layers',\n",
    "        ax=axs[0],\n",
    "    ),\n",
    "    dict(\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='Min. \\#Layers',\n",
    "        hue='Maj. \\#Layers',\n",
    "        ax=axs[1]\n",
    "    )\n",
    "]\n",
    "data_ = data.assign(**{\n",
    "    'Maj. \\#Layers': lambda ddf: ddf['hffnn.majority.ffnn.num_layers'].astype(int),\n",
    "    'Min. \\#Layers': lambda ddf: ddf['hffnn.minority.ffnn.num_layers'].astype(int),\n",
    "})\n",
    "for kwargs in kwargs_arr:\n",
    "    sns.stripplot(\n",
    "        **kwargs,\n",
    "        data=data_,\n",
    "#         s=2.5,\n",
    "        palette='tab10' if data_[kwargs['hue']].nunique() < 10 else 'Spectral',\n",
    "#         linewidth=0.5,\n",
    "        jitter=0.25,\n",
    "#         edgecolor='#0005',\n",
    "        **stripplot_kwargs,\n",
    "    )\n",
    "    vis.add_grid(kwargs['ax'])\n",
    "    vis.fmt_legend(\n",
    "        kwargs['ax'], \n",
    "        title=kwargs['hue'],\n",
    "        loc='best',\n",
    "    )\n",
    "    kwargs['ax'].set(\n",
    "        xlabel=kwargs['x'],\n",
    "        ylabel=kwargs['y'],\n",
    "        ylim=(-0.05, 1.25),\n",
    "        yticks=np.arange(0, 1.1, 0.25),\n",
    "        yticklabels=np.arange(0, 1.1, 0.25),\n",
    "    )\n",
    "    vis.rename_ax(kwargs['ax'])\n",
    "        \n",
    "\n",
    "    \n",
    "for i, hue in enumerate(['Min. \\#Layers', 'Maj. \\#Layers']):\n",
    "    sns.scatterplot(\n",
    "        data=data_,\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hue,\n",
    "        ax=axs[2+i],\n",
    "        **scatterplot_kwargs,\n",
    "        palette='tab10',\n",
    "    )\n",
    "\n",
    "    vis.rename_ax(axs[2+i])\n",
    "    vis.add_grid(axs[2+i])\n",
    "    axs[2+i].set(\n",
    "        xlim=(0, 1),\n",
    "        ylim=(0, 1),\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51hffnn,x=nlayers,y=f1,h=nlayers,c=majmin.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499779b",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(WIDTH, 5)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "axs[-1].axis('off')\n",
    "jittered = vis.add_jitter(data, hyperpars, amount=0.05, clamp=False)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=jittered,\n",
    "    hue='hffnn.minority.ffnn.nodes_per_layer.-1.log10',\n",
    "    x='hffnn.majority.ffnn.nodes_per_layer.-1.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    ax=axs[0],\n",
    "    legend=False,\n",
    "    \n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=jittered,\n",
    "    hue='hffnn.majority.ffnn.nodes_per_layer.-1.log10',\n",
    "    x='hffnn.minority.ffnn.nodes_per_layer.-1.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=jittered.sort_values('val.macro avg.f1-score'),\n",
    "    y='hffnn.minority.ffnn.nodes_per_layer.-1.log10',\n",
    "    x='hffnn.majority.ffnn.nodes_per_layer.-1.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    legend=False,\n",
    "    ax=axs[2]\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    xlabel=rename_hpars['hffnn.majority.ffnn.nodes_per_layer.-1.log10'],\n",
    "    ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "    ylim=(-0.05, 1.05),\n",
    "    yticks=np.arange(0, 1.1, 0.2),\n",
    ")\n",
    "axs[1].set(\n",
    "    xlabel=rename_hpars['hffnn.minority.ffnn.nodes_per_layer.-1.log10'],\n",
    "    ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "#     ylabel=None,\n",
    "    yticks=np.arange(0, 1.1, 0.2),\n",
    "#     yticklabels=[],\n",
    "    ylim=(-0.05, 1.05),\n",
    ")\n",
    "\n",
    "# for ax in axs[[0, 1]]:\n",
    "vis.add_cbar(\n",
    "    fig, axs[1], data['hffnn.majority.ffnn.nodes_per_layer.1.log10'],\n",
    "    label=rename_hpars['ffnn.nodes_per_layer.-1.log10'],\n",
    "    vmin=np.log10(4),\n",
    "    vmax=np.log10(512),\n",
    ")\n",
    "\n",
    "axs[2].set(\n",
    "    xlim=(0.45, 2.8),\n",
    "    ylim=(0.45, 2.8),\n",
    "    xlabel=rename_hpars['hffnn.majority.ffnn.nodes_per_layer.-1.log10'],\n",
    "    ylabel=rename_hpars['hffnn.minority.ffnn.nodes_per_layer.-1.log10'],\n",
    ")\n",
    "\n",
    "vis.add_cbar(\n",
    "    fig, axs[2], data['val.macro avg.f1-score'],\n",
    "    label=rename_hpars['val.macro avg.f1-score'],\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "vis.add_grid(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "vis.add_grid(axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51hffnn,x=npl-1,y=f1,h=majmin,c=majmin.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459174e7",
   "metadata": {},
   "source": [
    "#### x=lr,y=f1,h=lr,c=majmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de9df2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(WIDTH, 5.5)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "axs[-1].axis('off')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.025),\n",
    "    x='hffnn.majority.nn.learning_rate.log10',\n",
    "    hue='hffnn.minority.nn.learning_rate.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    ax=axs[0],\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    xlabel=rename_hpars['hffnn.majority.nn.learning_rate.log10'],\n",
    "    ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "    xticks=np.arange(-6, -0.95, 1),\n",
    "    ylim=(0, 1),\n",
    "    title='Majority LR against $F_1$\\n'\n",
    "          '(colour is the Min. LR)'\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.025),\n",
    "    hue='hffnn.majority.nn.learning_rate.log10',\n",
    "    x='hffnn.minority.nn.learning_rate.log10',\n",
    "    y='val.macro avg.f1-score',\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "vis.add_cbar(\n",
    "    fig, axs[1], data['hffnn.majority.nn.learning_rate.log10'],\n",
    "    label=rename_hpars['nn.learning_rate.log10'],\n",
    "    vmin=-6,\n",
    "    vmax=-1,\n",
    ")\n",
    "\n",
    "axs[1].set(\n",
    "    xlabel=rename_hpars['hffnn.minority.nn.learning_rate.log10'],\n",
    "    xticks=np.arange(-6, -0.95, 1),\n",
    "    ylabel=vis.rename_hpars['val.macro avg.f1-score'],\n",
    "    yticks=axs[0].get_yticks(),\n",
    "#     yticklabels=[],\n",
    "    title='Minority LR against $F_1$\\n'\n",
    "          '(colour is the Maj. LR)'\n",
    ")\n",
    "vis.add_grid(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(data, hyperpars, amount=0.025),\n",
    "    x='hffnn.majority.nn.learning_rate.log10',\n",
    "    y='hffnn.minority.nn.learning_rate.log10',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    hue_norm=(0, 1),\n",
    "    palette='Spectral',\n",
    "    s=10,\n",
    "    edgecolor='#0005',\n",
    "    ax=axs[2],\n",
    "    legend=False,\n",
    ")\n",
    "vis.add_cbar(\n",
    "    fig, axs[2], data['val.macro avg.f1-score'],\n",
    "    vmin=0, vmax=1, label='$F_1$'\n",
    ")\n",
    "\n",
    "vis.rename_ax(axs[2])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_51hffnn,x=lr,y=f1,h=lr,c=majmin.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3a45f",
   "metadata": {},
   "source": [
    "#### x=p,y=r,h=hpar,col=hpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a3c44",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(5, 4, figsize=(16, 20), dpi=300)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i >= len(hyperpars):\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        hue=hyperpars[i],\n",
    "        edgecolor='#0005',\n",
    "        s=10,\n",
    "        ax=ax,\n",
    "#         legend=False,\n",
    "        palette='Spectral' if data[hyperpars[i]].nunique() > 5 else 'tab10',\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel=None,\n",
    "        ylabel=None,\n",
    "        title=vis.rename_hpars[hyperpars[i]],\n",
    "        xlim=(0, 1),\n",
    "        ylim=(0, 1),\n",
    "    )\n",
    "    vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2177eb2",
   "metadata": {},
   "source": [
    "#### x=majhpar,y=minhpar,h=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b6a6e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(5, 4, figsize=(10, 10), dpi=300)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i >= len(hyperpars):\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    kwargs = dict(\n",
    "        hue=(\n",
    "            hyperpars[i].replace('maj', 'min')\n",
    "            if 'maj' in hyperpars[i] else\n",
    "            hyperpars[i].replace('min', 'maj')\n",
    "        ),\n",
    "        x=hyperpars[i],\n",
    "        y='val.macro avg.f1-score',\n",
    "    )\n",
    "    discrete = data[kwargs['x']].nunique() < 5\n",
    "    jitter_amount = 0.025 if not discrete else 0.15\n",
    "    jitter_hpars = hyperpars if not discrete else [kwargs['x']]\n",
    "    sns.scatterplot(\n",
    "        data=vis.add_jitter(data, jitter_hpars, amount=jitter_amount, clamp=not discrete),\n",
    "        **kwargs,\n",
    "        edgecolor='#0005',\n",
    "        s=5,\n",
    "        hue_norm=(\n",
    "            data[kwargs['hue']].min(),\n",
    "            data[kwargs['hue']].max(),\n",
    "        ),\n",
    "        ax=ax,\n",
    "        legend=discrete,\n",
    "        palette='Spectral' if not discrete else 'tab10',\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel=vis.rename_hpars[kwargs['x']],\n",
    "        ylabel=vis.rename_hpars[kwargs['y']],\n",
    "        ylim=(-0.05, 1.05),\n",
    "        yticks=np.arange(0, 1.01, 0.2),\n",
    "        yticklabels=np.round(np.arange(0, 1.01, 0.2), 1),\n",
    "#         title=rename_hpars[kwargs['hue']],\n",
    "    )\n",
    "#     vis.fmt_legend(ax)\n",
    "    vis.add_grid(ax)\n",
    "    if discrete:\n",
    "        vis.fmt_legend(ax)\n",
    "    else:\n",
    "\n",
    "        vis.add_cbar(\n",
    "            fig, ax, \n",
    "            data[kwargs['hue']],\n",
    "            label=vis.rename_hpars[kwargs['hue']],\n",
    "            vmin=data[kwargs['hue']].min(),\n",
    "            vmax=data[kwargs['hue']].max(),\n",
    "            cmap='Spectral',\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6db23",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10), dpi=200)\n",
    "\n",
    "hpar = 'nn.learning_rate.log10'\n",
    "\n",
    "for i, majlayers in enumerate([1, 2, 3]):\n",
    "    for j, minlayers in enumerate([1, 2, 3]):\n",
    "        ax = axs[i, j]\n",
    "        sns.scatterplot(\n",
    "            data=vis.add_jitter(data[\n",
    "                (data['hffnn.majority.ffnn.num_layers'] == majlayers)\n",
    "                & (data['hffnn.minority.ffnn.num_layers'] == minlayers)\n",
    "            ], hyperpars, amount=0.05),\n",
    "            x=f'hffnn.majority.{hpar}',\n",
    "            y=f'hffnn.minority.{hpar}',\n",
    "            hue='val.macro avg.f1-score',\n",
    "            ax=ax,\n",
    "            edgecolor='#0005',\n",
    "            s=20,\n",
    "            palette='Spectral',\n",
    "            legend=False,\n",
    "        )\n",
    "        ax.set(\n",
    "            title=f'MajLayers: {majlayers} MinLayers: {minlayers}',\n",
    "        )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaae8f8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "sns.scatterplot(\n",
    "    data=vis.add_jitter(\n",
    "        data,\n",
    "        ['hffnn.majority.ffnn.num_layers', 'hffnn.minority.ffnn.num_layers'],\n",
    "        amount=0.1,\n",
    "        clamp=False,\n",
    "    ),\n",
    "    x='hffnn.majority.ffnn.num_layers',\n",
    "    y='hffnn.minority.ffnn.num_layers',\n",
    "    hue='val.macro avg.f1-score',\n",
    "    palette='Spectral',\n",
    "    legend=False,\n",
    "    s=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78d5e8",
   "metadata": {},
   "source": [
    "#### all HFFNN triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77ea10",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# This plot is broken because it's not needed\n",
    "for i, maj_min_hyperpar in enumerate(maj_min_hyperpars):\n",
    "    maj_hpar = maj_min_hyperpar.format('majority')\n",
    "    min_hpar = maj_min_hyperpar.format('minority')\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 2,\n",
    "        figsize=(WIDTH, 5.5)\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    axs[-1].axis('off')\n",
    "    \n",
    "    kwargs_arr = [\n",
    "        dict(x=maj_hpar, y='val.macro avg.f1-score', hue=min_hpar),\n",
    "        dict(x=min_hpar, y='val.macro avg.f1-score', hue=maj_hpar),\n",
    "        dict(x=maj_hpar, y=min_hpar, hue='val.macro avg.f1-score'),\n",
    "    ]\n",
    "\n",
    "    for j, kwargs in enumerate(kwargs_arr):\n",
    "        continuous = data[kwargs['x']].nunique() > 5\n",
    "        \n",
    "        jitter_hpars = (\n",
    "            [kwargs['x']]\n",
    "            if kwargs['y'] == 'val.macro avg.f1-score' else\n",
    "            [kwargs['x'], kwargs['y']]\n",
    "        )\n",
    "        jitter_amount = 0.025 if continuous else 0.2\n",
    "\n",
    "        sns.scatterplot(\n",
    "            **kwargs,\n",
    "            data=vis.add_jitter(\n",
    "                data, \n",
    "                jitter_hpars, \n",
    "                amount=jitter_amount,\n",
    "                clamp=continuous,\n",
    "            ),\n",
    "            palette='Spectral' if continuous else ['tab:blue', 'tab:orange', 'tab:green'],\n",
    "            s=10,\n",
    "            edgecolor='#0005',\n",
    "            ax=axs[j],\n",
    "            legend=continuous,\n",
    "        )\n",
    "#         print(kwargs, continuous)\n",
    "    \n",
    "    axs[0].set(\n",
    "        xlabel=rename_hpars[maj_hpar],\n",
    "        ylabel=rename_hpars['val.macro avg.f1-score'],\n",
    "        ylim=(0, 1),\n",
    "        title=f'{vis.rename_hpars[maj_hpar]} vs $F_1$\\n'\n",
    "              f'(colour is {vis.rename_hpars[min_hpar]})'\n",
    "    )\n",
    "    if data[maj_hpar].nunique() > 5:\n",
    "        vis.add_cbar(\n",
    "            fig, axs[1], data[maj_hpar],\n",
    "            label=rename_hpars[maj_min_hyperpar[9:]],\n",
    "        )\n",
    "    else:\n",
    "        vis.fmt_legend(axs[1], title=rename_hpars[maj_min_hyperpar[9:]])\n",
    "\n",
    "    axs[1].set(\n",
    "        xlabel=rename_hpars[min_hpar],\n",
    "#         xticks=np.arange(-6, -0.95, 1),\n",
    "        ylabel=vis.rename_hpars['val.macro avg.f1-score'],\n",
    "        yticks=axs[0].get_yticks(),\n",
    "#         yticklabels=[],\n",
    "        title=f'{vis.rename_hpars[min_hpar]} vs $F_1$\\n'\n",
    "              f'(colour is {vis.rename_hpars[maj_hpar]})'\n",
    "    )\n",
    "    vis.add_grid(axs[0])\n",
    "    vis.add_grid(axs[1])\n",
    "    vis.add_grid(axs[2])\n",
    "\n",
    "    vis.add_cbar(\n",
    "        fig, axs[2], data['val.macro avg.f1-score'],\n",
    "        vmin=0, vmax=1, \n",
    "        label=vis.rename_hpars['val.macro avg.f1-score']\n",
    "    )\n",
    "\n",
    "    vis.rename_ax(axs[2])\n",
    "    plt.tight_layout()\n",
    "\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_51hffnn,triplets={maj_min_hyperpar[9:]}.pdf'\n",
    "#     )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c5618",
   "metadata": {},
   "source": [
    "### Distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0d7a",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "maj_min = (\n",
    "    'majority',\n",
    "    'minority',\n",
    ")\n",
    "for submodel in maj_min:\n",
    "    hyperpars = (\n",
    "        f'hffnn.{submodel}.ffnn.dropout_rate',\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.1',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.2',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.3',\n",
    "    )\n",
    "    df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "    ]] = np.log10(df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient',\n",
    "        f'hffnn.{submodel}.nn.batch_size',\n",
    "        f'hffnn.{submodel}.nn.learning_rate',\n",
    "    ]])\n",
    "    xlabels = (\n",
    "        f'Dropout Rate\\n({submodel.title()} Classifier)',\n",
    "        f'L2 Coefficient ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Batch Size ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Learning Rate ($\\log_{{10}}$)\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 1\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 2\\n({submodel.title()} Classifier)',\n",
    "        f'Nodes in Layer 3\\n({submodel.title()} Classifier)',\n",
    "    )\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'HFFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        3, 3,\n",
    "        figsize=(WIDTH, WIDTH)\n",
    "    )\n",
    "    print(axs.shape)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y='val.macro avg.f1-score',\n",
    "            s=10,\n",
    "            alpha=0.5,\n",
    "            ax=ax,\n",
    "            color='tab:orange',\n",
    "            edgecolor=None,\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'$F_1$ score vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel='$F_1$ score',\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_in_depth_hffnn_{submodel}_hpars.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d79be",
   "metadata": {},
   "source": [
    "## In depth CuSUM plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee9347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'CuSUM')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*.5))\n",
    "    p_min = max(-0.05, data['val.macro avg.precision'].min() / 1.10)\n",
    "    p_max = min( 1.05, data['val.macro avg.precision'].max() * 1.10)\n",
    "    r_min = max(-0.05, data['val.macro avg.recall'].min()    / 1.10)\n",
    "    r_max = min( 1.05, data['val.macro avg.recall'].max()    * 1.10)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        hue='cusum.thresh',\n",
    "        **scatterplot_kwargs,\n",
    "#         alpha=0.75,\n",
    "#         s=10,\n",
    "        ax=axs[0],\n",
    "        palette=palette,\n",
    "        legend=False,\n",
    "#         edgecolor=None\n",
    "    )\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        x='cusum.thresh',\n",
    "        y='val.macro avg.f1-score',\n",
    "        **stripplot_kwargs,\n",
    "#         alpha=0.5,\n",
    "#         s=2.5,\n",
    "        ax=axs[1],\n",
    "        jitter=0.25,\n",
    "        color=model_colours['CuSUM'],\n",
    "        native_scale=True,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs recall\\n{nclasses}-class CuSUM models\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "\n",
    "#     axs[0].legend().set_title('Threshold')\n",
    "    vis.add_cbar(\n",
    "        fig, axs[0], data=data['cusum.thresh'],\n",
    "        label='Threshold'\n",
    "    )\n",
    "\n",
    "    axs[1].set(\n",
    "        title=f'Threshold vs $F_1$ score\\n{nclasses}-class CuSUM models',\n",
    "        xlabel='CuSUM Threshold',\n",
    "        ylabel='$F_1$ score',\n",
    "    )\n",
    "    for ax in axs.flat:\n",
    "        vis.add_grid(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_hpar_analysis_cusum_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e083f",
   "metadata": {},
   "source": [
    "## In depth SVM plots\n",
    "\n",
    "- Correlation with the training time per observation\n",
    "- Correlation with the precision/recall/f1\n",
    "- clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368145d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some summary stats\n",
    "(\n",
    "    df.loc[(df['model_type'] == 'SVM')]\n",
    "    .groupby(['preprocessing.num_gesture_classes'], dropna=False)\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'median', 'mean', 'min', 'max', 'std'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d6899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes = ('5', '50', '51')\n",
    "for num_gesture_classes in n_classes:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == num_gesture_classes)\n",
    "        & (df['model_type'] == 'SVM')\n",
    "    ]\n",
    "\n",
    "    data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "    data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "    data = data.rename(columns={\n",
    "        'svm.c.log10': '$\\log_{10}(C)$', \n",
    "        'svm.class_weight': 'Class Weight'\n",
    "    })\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, 0.5*WIDTH))\n",
    "    axs = axs.flatten()\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.05\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.05\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.05\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.05\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        hue='$\\log_{10}(C)$',\n",
    "        style='Class Weight',\n",
    "#         alpha=0.8,\n",
    "        **scatterplot_kwargs,\n",
    "#         s=10,\n",
    "        ax=axs[0],\n",
    "        palette=palette,\n",
    "        legend=False,\n",
    "#         edgecolor='#0005',\n",
    "    )\n",
    "\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs Recall\"\n",
    "        f\"\\n({num_gesture_classes}-class SVM)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='$\\log_{10}(C)$',\n",
    "        y='val.macro avg.f1-score',\n",
    "        style='Class Weight',\n",
    "        **scatterplot_kwargs,\n",
    "#         alpha=0.8,\n",
    "#         s=10,\n",
    "        ax=axs[1],\n",
    "        color='tab:purple',\n",
    "#         legend=False,\n",
    "#         edgecolor='#0005',\n",
    "    )\n",
    "\n",
    "    axs[1].set(\n",
    "        title=f\"$F_1$-score vs C\\n\"\n",
    "        f\"({num_gesture_classes}-class SVM)\",\n",
    "        xlabel='C ($\\log_{10}$)',\n",
    "        ylabel='$F_1$-score',\n",
    "    )\n",
    "    \n",
    "#     move_legend(axs[0], axs[-1])\n",
    "    vis.add_cbar(\n",
    "        fig, axs[0],\n",
    "        data['$\\log_{10}(C)$'],\n",
    "        label='$\\log_{10}(C)$',\n",
    "    )\n",
    "#     axs[-2].axis('off')\n",
    "    vis.fmt_legend(axs[1])\n",
    "    vis.add_grid(axs[0])\n",
    "    vis.add_grid(axs[1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_svm_classes{num_gesture_classes}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc0614",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'SVM')\n",
    "    ]\n",
    "\n",
    "    data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    hpar = 'svm.class_weight'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            zero_division=0,\n",
    "        )\n",
    "\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] += 1.0\n",
    "            precisions[hpar_item] += precision\n",
    "            recalls[hpar_item] += recall\n",
    "            f1_scores[hpar_item] += f1_score\n",
    "\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] = 1.0\n",
    "            precisions[hpar_item] = precision\n",
    "            recalls[hpar_item] = recall\n",
    "            f1_scores[hpar_item] = f1_score\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, len(conf_mats), \n",
    "        figsize=(WIDTH, WIDTH/len(conf_mats))\n",
    "    )\n",
    "\n",
    "\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    #     conf_mat[-1, -1] = 0\n",
    "        conf_mat /= conf_mat_totals[hpar_item]\n",
    "        vis.conf_mat(conf_mat, ax=axs[i])\n",
    "        axs[i].set_title(\n",
    "            f'{hpar_item.title()} SVMs'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_svm_conf_mats_unbalanced_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n",
    "#     fig, axs = plt.subplots(\n",
    "#         1, 2,\n",
    "#         figsize=(WIDTH, WIDTH*.2),\n",
    "#     )\n",
    "#     axs = axs.flatten()\n",
    "#     for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#         axs[i].set_aspect(3)\n",
    "#         vis.precision_recall_f1(\n",
    "#             precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             ax=axs[i],\n",
    "#         )\n",
    "#         axs[i].set_title(hpar_item.title() + \" SVMs\")\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_in_depth_svm_prf1_plots_unbalanced_classes{nclasses}.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e40b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "#     s=10,\n",
    "#     alpha=0.5,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    **scatterplot_kwargs,\n",
    "    palette=palette,\n",
    "    ax=axs[0],\n",
    "#     edgecolor=None,\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='trn.pred_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "#     s=10,\n",
    "    **scatterplot_kwargs,\n",
    "#     alpha=0.5,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=axs[1],\n",
    "#     edgecolor=None,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title='Fit time vs C\\n51-class SVM',\n",
    "    ylabel='Fit time (s/obs.)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Inference time vs C\\n51-class SVM',\n",
    "    ylabel='Inference time (s/obs.)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "\n",
    "vis.add_grid(axs[0])\n",
    "vis.add_grid(axs[1])\n",
    "vis.fmt_legend(axs[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_svm_hpars_vs_fit_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a86b4b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# SVM 51-class fitting time vs f1-score style=class weight hue=C\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='val.macro avg.f1-score',\n",
    "    s=20,\n",
    "#     alpha=0.5,\n",
    "    hue='svm.c.log10',\n",
    "    style='svm.class_weight',\n",
    "#     color='tab:purple',\n",
    "    palette='Spectral',\n",
    "#     ax=axs[0],\n",
    "    edgecolor='#000',\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "data[[\n",
    "    'fit_time_per_obs',\n",
    "    'val.macro avg.f1-score',\n",
    "    'svm.c.log10',\n",
    "    'svm.class_weight',\n",
    "]].to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3871e02",
   "metadata": {},
   "source": [
    "## In depth HMM plots\n",
    "\n",
    "- Clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3904031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some summary stats\n",
    "hue_order = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "(\n",
    "    df.loc[(df['model_type'] == 'HMM')]\n",
    "    .groupby(['preprocessing.num_gesture_classes', 'hmm.covariance_type'])\n",
    "    [['val.macro avg.f1-score', 'val.macro avg.precision', 'val.macro avg.recall']]\n",
    "    .agg(['count', 'median', 'mean', 'min', 'max', 'std'])\n",
    "    .T\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b6b5b",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'HMM'\n",
    "color='tab:red'\n",
    "n_classes = ('5', '50', '51',)\n",
    "for num_gesture_classes in n_classes:\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == num_gesture_classes)\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(WIDTH, WIDTH*0.5))\n",
    "    p_min = data['val.macro avg.precision'].min() # / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() # * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    # / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    # * 1.10\n",
    "\n",
    "#     precision_grid, recall_grid = np.meshgrid(\n",
    "#         np.linspace(p_min, p_max, 50), \n",
    "#         np.linspace(r_min, r_max, 50),\n",
    "#     )\n",
    "\n",
    "#     f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "#     contours = axs[0].contour(\n",
    "#         precision_grid,\n",
    "#         recall_grid, \n",
    "#         f1_score,\n",
    "#         levels=np.linspace(\n",
    "#             f1_score.min(),\n",
    "#             f1_score.max(),\n",
    "#             10,\n",
    "#         ), \n",
    "#         colors='#0005',\n",
    "#         alpha=0.25\n",
    "#     )\n",
    "#     axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "#         hue='val.macro avg.f1-score',\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "        alpha=0.5,\n",
    "        s=10,\n",
    "        ax=axs[0],\n",
    "        palette=other_colours,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    axs[0].set(\n",
    "        title=f\"Precision vs Recall\"\n",
    "        f\"\\n({num_gesture_classes}-class {model_type}s)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "#         xlim=(0, .05),\n",
    "#         ylim=(0, 1),\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "    axs[0].legend().set_title('Covariance')\n",
    "    \n",
    "    \n",
    "    sns.stripplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.f1-score',\n",
    "        x='hmm.covariance_type',\n",
    "        order=hue_order,\n",
    "        size=3,\n",
    "        alpha=0.5,\n",
    "        ax=axs[1],\n",
    "        palette=other_colours,\n",
    "#         hue='val.macro avg.f1-score',\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "\n",
    "    )\n",
    "    axs[1].set(\n",
    "        title=f\"$F_1$-score vs Covariance Type\"\n",
    "        f\"\\n({num_gesture_classes}-class {model_type}s)\",\n",
    "        xlabel='Covariance Type',\n",
    "        ylabel='$F_1$-score',\n",
    "#         xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "#         ylim=(-0.05, 1.05),\n",
    "    )\n",
    "    axs[0].legend().set_title('Covariance Type')\n",
    "    plt.tight_layout()\n",
    "    vis.add_grid(axs[0])\n",
    "    vis.add_grid(axs[1])\n",
    "    vis.fmt_legend(axs[0])\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_{num_gesture_classes}_p_vs_r_covar_type.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b276149",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df.assign(**{\n",
    "        'calc_f1-score': lambda ddf: 2 * (ddf['val.macro avg.precision'] * ddf['val.macro avg.precision']) / (ddf['val.macro avg.recall'] + ddf['val.macro avg.recall'])\n",
    "    }),\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='calc_f1-score',\n",
    "    hue='preprocessing.num_gesture_classes',\n",
    "    s=.5,\n",
    "    alpha=0.5,\n",
    "    edgecolor=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371abd2d",
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH*0.5, WIDTH*0.5))\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'HMM')\n",
    "    ]\n",
    "\n",
    "    data['val.pred_time_per_obs.log10'] = np.log10(data['val.pred_time_per_obs'])\n",
    "    data['trn.pred_time_per_obs.log10'] = np.log10(data['trn.pred_time_per_obs'])\n",
    "    data['fit_time_per_obs.log10'] = np.log10(data['fit_time_per_obs'])\n",
    "\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='fit_time_per_obs.log10',\n",
    "        y='trn.pred_time_per_obs.log10',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        hue='hmm.covariance_type',\n",
    "        hue_order=hue_order,\n",
    "        ax=ax,\n",
    "        palette=other_colours,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "\n",
    "#     ax.legend().set_title('Covariance Type')\n",
    "\n",
    "    ax.set(\n",
    "        title=f'Fitting time vs inference time\\n({nclasses}-class HMMs)',\n",
    "        xlabel=r'Fit time ($\\log_{10}(s/obs)$)',\n",
    "        ylabel='Inference time ($\\log_{10}(s/obs)$)',\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "    vis.fmt_legend(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_inf_trn_time_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c0aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nclasses_list = ('5', '50', '51')\n",
    "for nclasses in nclasses_list:\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "        & (df['model_type'] == 'HMM')\n",
    "    ]\n",
    "    data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "        'spherical': 'Spherical',\n",
    "        'diag': 'Diagonal',\n",
    "        'full': 'Full',\n",
    "        'tied': 'Tied',\n",
    "    })\n",
    "\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    f1_scores = {}\n",
    "    y_preds_dict = {}\n",
    "    y_true_dict = {}\n",
    "    reports_dict = {}\n",
    "\n",
    "    hpar = 'hmm.covariance_type'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "    #         average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] += 1.0\n",
    "            precisions[hpar_item] += precision\n",
    "            recalls[hpar_item] += recall\n",
    "            f1_scores[hpar_item] += f1_score\n",
    "            y_preds_dict[hpar_item] = np.concatenate((y_preds_dict[hpar_item], y_pred.flatten()))\n",
    "            y_true_dict[hpar_item] = np.concatenate((y_true_dict[hpar_item], y_true.flatten()))\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float)\n",
    "            conf_mat_totals[hpar_item] = 1.0\n",
    "            precisions[hpar_item] = precision\n",
    "            recalls[hpar_item] = recall\n",
    "            f1_scores[hpar_item] = f1_score\n",
    "            y_preds_dict[hpar_item] = np.copy(y_pred.flatten())\n",
    "            y_true_dict[hpar_item] = np.copy(y_true.flatten())\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 2,\n",
    "        figsize=(WIDTH, WIDTH),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    hpar_items = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "    for i, hpar_item in enumerate(hpar_items):\n",
    "        conf_mat = conf_mats[hpar_item]\n",
    "        vis.conf_mat(conf_mat, ax=axs[i])\n",
    "    #     vis.conf_mat(conf_mat / conf_mat.max(), ax=axs[i], norm=None)\n",
    "        axs[i].set_title(\n",
    "            f'{hpar_item.title()} {nclasses}-class HMMs'\n",
    "    #         f'(Mean of {int(conf_mat_totals[hpar_item])} confusion matrices)'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hmm_conf_mats_cov_type_classes{nclasses}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "#     fig, axs = plt.subplots(\n",
    "#         2, 2,\n",
    "#         figsize=(WIDTH, WIDTH*.4),\n",
    "#     )\n",
    "#     axs = axs.flatten()\n",
    "#     hpar_items = ['Spherical', 'Diagonal', 'Tied', 'Full']\n",
    "#     for i, hpar_item in enumerate(hpar_items):\n",
    "#         conf_mat = conf_mats[hpar_item]\n",
    "#     #     axs[i].set_aspect(1)\n",
    "#         vis.precision_recall_f1(\n",
    "#             precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "#             ax=axs[i],\n",
    "#         )\n",
    "#         axs[i].set_title(f'{hpar_item} {nclasses}-class HMMs')\n",
    "#         if i % 2 != 0:\n",
    "#             axs[i].set_yticks([])\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     plt.savefig(\n",
    "#         f'../../report/src/imgs/graphs/05_in_depth_hmm_prf1_plots_conv_type_classes{nclasses}.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb27c46",
   "metadata": {},
   "source": [
    "## Inference times vs num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72de56",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "axs = axs.flatten()\n",
    "model_types = [m for m in model_colours.keys() if m != 'HFFNN']\n",
    "for ax, model_type in zip(axs, sorted(model_types)):\n",
    "    sns.stripplot(\n",
    "        data=df[\n",
    "            df['model_type'] == model_type\n",
    "        ].sort_values('preprocessing.num_gesture_classes'),\n",
    "        x='preprocessing.num_gesture_classes',\n",
    "        y='val.pred_time_per_obs.log10',\n",
    "        hue='model_type',\n",
    "#         dodge=True,\n",
    "        s=2,\n",
    "        legend=False,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        alpha=0.5,\n",
    "        jitter=0.3,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=(-6.1, -0.9),\n",
    "        title=f'{model_type} inference time\\nagainst \\#classes',\n",
    "        xlabel='Number of Classes',\n",
    "        ylabel='Inference time $\\log_{10}$(s/obs)',\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_time_vs_num_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7175ab5",
   "metadata": {},
   "source": [
    "## Training times vs num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea92ac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "df['fit_time_per_obs.log10'] = np.log10(df['fit_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "axs = axs.flatten()\n",
    "model_types = [m for m in model_colours.keys() if m != 'HFFNN']\n",
    "for ax, model_type in zip(axs, sorted(model_types)):\n",
    "    sns.stripplot(\n",
    "        data=df[\n",
    "            df['model_type'] == model_type\n",
    "        ].sort_values('preprocessing.num_gesture_classes'),\n",
    "        x='preprocessing.num_gesture_classes',\n",
    "        y='fit_time_per_obs.log10',\n",
    "        hue='model_type',\n",
    "#         dodge=True,\n",
    "        s=2,\n",
    "        legend=False,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        alpha=0.5,\n",
    "        jitter=0.3,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "#         ylim=(-3.5, -0.5),\n",
    "        title=f'{model_type} fitting time\\nagainst \\#classes',\n",
    "        xlabel='Number of Classes',\n",
    "        ylabel='Fitting time $\\log_{10}$(s/obs)',\n",
    "    )\n",
    "    vis.add_grid(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_fit_time_vs_num_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f33187",
   "metadata": {},
   "source": [
    "## Inference times vs $F_1$-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385dba6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='val.pred_time_per_obs.log10',\n",
    "    hue='model_type',\n",
    "    s=5,\n",
    "    edgecolor='#000a',\n",
    "#     legend=False,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "#         alpha=0.5,\n",
    "#         jitter=0.3,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set(\n",
    "    xlim=(-6.1, -0.9),\n",
    "    ylim=(-0.05, 1.05)\n",
    ")\n",
    "vis.add_grid(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b251d46",
   "metadata": {},
   "source": [
    "## PCA Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fa9de",
   "metadata": {},
   "source": [
    "### PCA decomposition only including the gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f7ca",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "shape = (np.nonzero(y_trn != 50)[0].shape[0] * 5,)\n",
    "mask = np.concatenate((\n",
    "    np.random.choice(np.nonzero(y_trn == 50)[0], shape), \n",
    "    np.nonzero(y_trn != 50)[0]\n",
    "))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3), dpi=200)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 20), dpi=200)\n",
    "for i, perplexity in enumerate([35, 45, 55]):\n",
    "    print(f\"PERPLEXITY: {perplexity}\")\n",
    "    X_embedded = TSNE(\n",
    "        n_components=2,\n",
    "        n_iter=1500,\n",
    "        learning_rate='auto',\n",
    "        init='random',\n",
    "        perplexity=perplexity,\n",
    "        verbose=True\n",
    "    ).fit_transform(X_trn[mask].reshape((X_trn[mask].shape[0], 600)))\n",
    "\n",
    "    hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\", \"Non-gesture\"])\n",
    "    styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", \"Non-gesture\"])\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=200)\n",
    "    argsort = np.argsort(y_trn[mask])\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_embedded[:, 0][argsort],\n",
    "        y=X_embedded[:, 1][argsort],\n",
    "        hue=hues[(y_trn[mask][argsort] // 10)],\n",
    "        style=styles[(y_trn[mask][argsort] % 10)],\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        ax=axs.flatten()[i],\n",
    "        legend=False,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    axs.flatten()[i].set_title(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_legend(from_ax, to_ax, title=None):\n",
    "    # Fetch the current legend\n",
    "    handles, labels = from_ax.get_legend_handles_labels()\n",
    "    title = title if title is not None else from_ax.legend().get_title()\n",
    "    # Remove it from the ax\n",
    "    from_ax.legend().remove()\n",
    "    # Add it to the new ax with some styling\n",
    "    to_ax.legend(\n",
    "        handles=handles, \n",
    "        labels=labels,\n",
    "        loc='center',\n",
    "        fancybox=False, \n",
    "        edgecolor=\"black\",\n",
    "        title=title\n",
    "#         linewidth=0.5,\n",
    "    )\n",
    "    # Remove the axis of the ax\n",
    "    to_ax.axis('off')\n",
    "    return from_ax, to_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec2503",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "print(\"Executing PCA\")\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "print(\"PCA complete\")\n",
    "\n",
    "n = 11\n",
    "markers = [\n",
    "    \"o\", \"X\", (4, 0, 45), \"P\", (4, 0, 0), (4, 1, 0), \"^\", (4, 1, 45), \"v\",\n",
    "]\n",
    "\n",
    "# Now generate more from regular polygons of increasing order\n",
    "s = 5\n",
    "while len(markers) < n:\n",
    "    a = 360 / (s + 1) / 2\n",
    "    markers.extend([(s + 1, 1, a), (s + 1, 0, a), (s, 1, 0), (s, 0, 0)])\n",
    "    s += 1\n",
    "\n",
    "markers = np.array([m for m in markers[:n]])\n",
    "# markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f911",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH*0.8), dpi=300)\n",
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", 'k'])\n",
    "# markers = np.array(['o', 'x', 's', '+', 'D', 'p', '^', 'd', 'v', '*', 'x'])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=300)\n",
    "# mask = (y_trn == 50)\n",
    "# axs[1].scatter(\n",
    "#     X_tfrm[:, 0][mask],\n",
    "#     X_tfrm[:, 1][mask],\n",
    "#     color='#0005',\n",
    "#     alpha=0.1,\n",
    "#     s=5,\n",
    "#     edgecolor='none',\n",
    "# )\n",
    "for gidx in range(0, 51):\n",
    "    ax.scatter(\n",
    "        X_tfrm[:, 0][y_trn == gidx],\n",
    "        X_tfrm[:, 1][y_trn == gidx],\n",
    "        color=colours[gidx // 10],\n",
    "        marker=markers[gidx % 10],\n",
    "        alpha=0.75 if gidx != 50 else 0.1,\n",
    "        zorder=10 if gidx != 50 else 0,\n",
    "        s=10 if gidx != 50 else 5,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "ax.set_title('PCA plot of the training data\\n(class 50 in black)')\n",
    "\n",
    "ax.set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    "    xlim=(-1400, 3000),\n",
    "    ylim=(-1300, 1600),\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# display_ = (0,1,2)\n",
    "\n",
    "#Create custom artists\n",
    "color_artists = [\n",
    "    plt.Line2D((0,1),(0,0), color=colour, marker='o', linestyle='')\n",
    "    for colour in colours[:-1]\n",
    "]\n",
    "color_labels = ['$0^{\\circ}$','$45^{\\circ}$','$90^{\\circ}$','$135^{\\circ}$','$180^{\\circ}$']\n",
    "\n",
    "marker_artists = [\n",
    "    plt.Line2D((0,1),(0,0), color='k', fillstyle='none', marker=marker, linestyle='')\n",
    "    for marker in markers[:-1]\n",
    "]\n",
    "marker_labels = [\n",
    "    'Left little',\n",
    "    'Left ring',\n",
    "    'Left middle',\n",
    "    'Left index',\n",
    "    'Left thumb',\n",
    "    'Right thumb',\n",
    "    'Right index',\n",
    "    'Right middle',\n",
    "    'Right ring',\n",
    "    'Right little',\n",
    "]\n",
    "#Create legend from custom artist/label lists\n",
    "ax.legend(\n",
    "    color_artists + marker_artists + [plt.Line2D((0,1),(0,0), color='k', marker='o', linestyle='')],\n",
    "    color_labels + marker_labels + ['Class 50'],\n",
    "    loc='center right'\n",
    ")\n",
    "# vis.fmt_legend(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_pca_plot.png',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4231b",
   "metadata": {},
   "source": [
    "### PCA plot showing just an interesting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4caf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec25ed",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "@interact(\n",
    "    x_start=(-1500, 1500, 50),\n",
    "    y_start=(-1500, 1500, 50),\n",
    "    x_length=(-1500, 1500, 50),\n",
    "    y_length=(-1500, 1500, 50),\n",
    ")\n",
    "def fn(x_start=-150, y_start=1000, x_length=500, y_length=500):\n",
    "    x_finsh = x_start + x_length\n",
    "    y_finsh = y_start + y_length\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "\n",
    "    selection_mask = (\n",
    "        (x_start <= X_tfrm[:, 0]) & (X_tfrm[:, 0] <= x_finsh) &\n",
    "        (y_start <= X_tfrm[:, 1]) & (X_tfrm[:, 1] <= y_finsh)\n",
    "    )\n",
    "    X_subset = X_tfrm[selection_mask]\n",
    "    y_subset = y_trn[selection_mask]\n",
    "#     ax.scatter(\n",
    "#         X_subset[:, 0],\n",
    "#         X_subset[:, 1],\n",
    "#         c='black',\n",
    "#         alpha=0.1,\n",
    "#     )\n",
    "    \n",
    "    y_mask = (y_trn == 50)\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset == 50],\n",
    "        X_subset[:, 1][y_subset == 50],\n",
    "        color='black',\n",
    "        alpha=0.1,\n",
    "        s=20,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset != 50],\n",
    "        X_subset[:, 1][y_subset != 50],\n",
    "        color=colours[(y_subset[y_subset != 50] // 10)],\n",
    "        alpha=0.75,\n",
    "#         s=5,\n",
    "        edgecolor='none',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d3579",
   "metadata": {},
   "source": [
    "### PCA plot that connects sequential datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa9f7e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "order = np.argsort(dt_trn)\n",
    "X_tfrm = X_tfrm[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0ce",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "\n",
    "limit = 1000\n",
    "@interact(start=(0, len(X_tfrm), 25), length=(0, len(X_tfrm), 50))\n",
    "def fn(start=0, length=500):\n",
    "    finsh = min(start + length, len(X_tfrm))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH), dpi=100)\n",
    "    ax.plot(\n",
    "        X_tfrm[:, 0][start:finsh],\n",
    "        X_tfrm[:, 1][start:finsh],\n",
    "        zorder=0,\n",
    "        c='#0005',\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_tfrm[:, 0][start:finsh],\n",
    "        y=X_tfrm[:, 1][start:finsh],\n",
    "        hue=dt_trn[order][start:finsh],\n",
    "        legend=False,\n",
    "        s=(10 + 90*(y_trn != 50)[order][start:finsh]),\n",
    "#         edgecolor=np.where((y_trn != 50)[order][start:finsh], '#0005', 'none'),\n",
    "        linewidth=.5,\n",
    "        edgecolor=None,\n",
    "    )\n",
    "    \n",
    "    idxs = np.nonzero(y_trn[order][start:finsh] != 50)[0]\n",
    "    for idx in idxs:\n",
    "        ax.text(\n",
    "            X_tfrm[start:finsh][idx, 0],\n",
    "            X_tfrm[start:finsh][idx, 1],\n",
    "            y_trn[order][start:finsh][idx],\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "#     ax.set_xlim((\n",
    "#         X_tfrm[:, 0].min() / 1.1,\n",
    "#         X_tfrm[:, 0].max() * 1.1,\n",
    "#     ))\n",
    "#     ax.set_ylim((\n",
    "#         X_tfrm[:, 1].min() / 1.1,\n",
    "#         X_tfrm[:, 1].max() * 1.1,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e39f0",
   "metadata": {},
   "source": [
    "### PCA plot with ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a102cae",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "y_tfrm = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3cdfa",
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "# https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensional dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse(\n",
    "        (0, 0), \n",
    "        width=ell_radius_x * 2, \n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor, \n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Calculating the standard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the standard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "    \n",
    "#     print(f\"{scale_x=}, {scale_y=}\\n{mean_x=}, {mean_y=}\")\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    \n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da5944",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "# gidx = 14\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "markers = ['o', 's', 'D', '^', 'v', '>', '<', 'p', 'H', '+']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "for gidx in range(50):\n",
    "    ax.scatter(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        color=colors[gidx // 10],\n",
    "        marker=markers[gidx % 10],\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "        label=gidx\n",
    "    )\n",
    "    confidence_ellipse(\n",
    "        X_tfrm[y_tfrm == gidx, 0],\n",
    "        X_tfrm[y_tfrm == gidx, 1],\n",
    "        ax,\n",
    "        n_std=2,\n",
    "        edgecolor=colors[gidx // 10],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5233e5",
   "metadata": {},
   "source": [
    "## Visualise mis-predictions\n",
    "\n",
    "1. Load in a continuous dataset\n",
    "2. Load in a classifier\n",
    "3. Use the classifier to make predictions on the dataset\n",
    "4. Visualise the mispredictions, but *with context*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8970",
   "metadata": {},
   "source": [
    "### Load in a model for which to evaluate the mis-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58bae6",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "clf = models.load_tf('../src/saved_models/ffnn_2023-09-18T14:05:16.363404')\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce0a33",
   "metadata": {},
   "source": [
    "### Visualise True and Mispredicted gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61f5b4",
   "metadata": {},
   "source": [
    "Plot all the observations which have the ground truth being gesture 255 but the model is not predicting g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a359ceb",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "for gidx in np.unique(y_val):\n",
    "    if gidx == 50: continue\n",
    "    pred_indxs = np.nonzero((y_val == 50) & (y_pred == gidx))[0]\n",
    "    true_indxs = np.nonzero(y_val == gidx)[0]\n",
    "    axs = vis.cmp_ts(\n",
    "        X_val[true_indxs],\n",
    "    )\n",
    "    vis.cmp_ts(\n",
    "        X_val[pred_indxs],\n",
    "        color='tab:red',\n",
    "        axs=axs,\n",
    "    )\n",
    "\n",
    "#     distances = np.abs(true_indxs[:, np.newaxis] - pred_indxs).min(axis=0)\n",
    "\n",
    "    plt.suptitle(f'Model predicted {gidx}, ground truth: 50 \\\n",
    "                 \\nGesture {gidx} in grey, mispredicted in red ({len(pred_indxs)} observations) \\\n",
    "                 \\nindices: {pred_indxs}')\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'../src/notebooks/pred_{gidx:0>2}_truth_50.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     if gidx > 5:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ac5e1",
   "metadata": {},
   "source": [
    "## Eval model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../src/saved_models/ffnn_2023-10-08T14:47:07.901649'\n",
    "tst_data = np.load('../gesture_data/tst_20_10.npz')\n",
    "y_tst = tst_data['y_tst']\n",
    "X_tst = tst_data['X_tst']\n",
    "dt_tst = tst_data['dt_tst']\n",
    "clf = models.load_tf(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705b94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = clf.config['model_type']\n",
    "y_pred = clf.predict(X_tst)\n",
    "clf_report_dict = sklearn.metrics.classification_report(\n",
    "    y_tst.astype(int),\n",
    "    y_pred.astype(int),\n",
    "    output_dict=True,\n",
    "    zero_division=0,\n",
    ")\n",
    "clf_report = pd.json_normalize(clf_report_dict)\n",
    "# print(sklearn.metrics.classification_report(\n",
    "#     y_tst.astype(int),\n",
    "#     y_pred.astype(int),\n",
    "#     output_dict=False,\n",
    "#     zero_division=0,\n",
    "# ))\n",
    "                            \n",
    "f1 = clf_report['macro avg.f1-score'].values[0]\n",
    "precision = clf_report['macro avg.precision'].values[0]\n",
    "recall = clf_report['macro avg.recall'].values[0]\n",
    "# print(\"val.macro avg.f1-score\", f1)\n",
    "# print(\"val.macro avg.precision\", precision)\n",
    "# print(\"val.macro avg.recall\", recall)\n",
    "# print (clf_report['macro avg.f1-score'].values[0])\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_tst, y_pred, num_classes=51).numpy()\n",
    "# cm[-1, -1] = 0\n",
    "fig, axs = plt.subplots(2, 1, figsize=(WIDTH, WIDTH))\n",
    "vis.conf_mat(\n",
    "    cm,\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_title(\n",
    "    f'Confusion Matrix (Test set)\\n'\n",
    "    f'$F_1$={np.round(f1, 3)}, Precision={np.round(precision, 3)}, Recall={np.round(recall, 3)}'\n",
    ")\n",
    "\n",
    "axs[1].set_aspect(2.5)\n",
    "vis.precision_recall_f1(\n",
    "    report=clf_report_dict,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_tst_set_conf_mat.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame()\n",
    "ddf['Recall'] = {\n",
    "    int(k): d['recall']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf['Precision'] = {\n",
    "    int(k): d['precision']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf['$F_1$-score'] = {\n",
    "    int(k): d['f1-score']\n",
    "    for k, d in clf_report_dict.items()\n",
    "    if type(d) is dict and k.isdigit()\n",
    "}\n",
    "ddf = ddf.reset_index()\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158449ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, 0.9*WIDTH))\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\", 'Non-Gesture'])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", 'Non-Gesture'])\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=ddf,\n",
    "    x='Precision',\n",
    "    y='Recall',\n",
    "    hue=hues[ddf.index // 10],\n",
    "    style=styles[ddf.index % 10],\n",
    "    ax=ax,\n",
    "    s=20,\n",
    "    linewidth=1,\n",
    "    edgecolor='#0005',\n",
    ")\n",
    "\n",
    "for i, row in ddf.iterrows():\n",
    "    ax.text(\n",
    "        row['Precision'],\n",
    "        row['Recall'],\n",
    "        str(int(row['index'])),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "    )\n",
    "vis.add_grid(ax)\n",
    "ax.set(\n",
    "    xlim=(-0.05, 1.05),\n",
    "    ylim=(-0.05, 1.05),\n",
    "    xticks=np.arange(0, 1.01, 0.1),\n",
    "    yticks=np.arange(0, 1.01, 0.1),\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='Precision and Recall for all gestures (best model)'\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_p_r_best_model.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1601b8",
   "metadata": {},
   "source": [
    "# Interactive plot to see data at a certain time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a5966",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "df_trn = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml',\n",
    ")\n",
    "vc = df_trn['gesture'].value_counts()\n",
    "vc = vc[vc.index != 'gesture0255']\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921ad7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml',\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "\n",
    "@interact(dt='2022-10-08T20:23:46.665276000')\n",
    "def fn(dt='2022-10-08T20:23:46.665276000'):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH))\n",
    "    mask = df['datetime'].between(\n",
    "        dt - pd.to_timedelta(1, 'second'),\n",
    "        dt + pd.to_timedelta(1, 'second')\n",
    "    )\n",
    "    \n",
    "    vis.cmp_ts(\n",
    "        [df.loc[mask, sensor_names].values]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d246d",
   "metadata": {},
   "source": [
    "# Plot a CSV file + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb8819",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # This cell is unused\n",
    "\n",
    "csv_path = '../gesture_data/saved_from_cli_2023-10-08_tqbfjotld.csv'\n",
    "# model_dir = '../src/saved_models/ffnn_2023-10-08T14:14:07.933452'\n",
    "model_dir = '../src/saved_models/ffnn_2023-10-08T14:47:07.901649'\n",
    "\n",
    "import yaml\n",
    "with open('../gesture_data/gesture_info.yaml', 'r') as f:\n",
    "    gesture_info = yaml.safe_load(f)['gestures']\n",
    "\n",
    "sensors = list(common.read_constants('./constants.yaml')[\"sensors\"].values())\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    names=[\"datetime\", \"gesture\"] + sensors,\n",
    "    parse_dates=[\"datetime\"],\n",
    "    date_format='ISO8601',\n",
    ")\n",
    "df['file'] = csv_path\n",
    "\n",
    "X, y, dt = common.make_windows(\n",
    "    df,\n",
    "    20,\n",
    "    constants_path='../src/constants.yaml',\n",
    "    pbar=tqdm.tqdm(total=len(df), desc=\"Making windows\"),\n",
    ")\n",
    "clf = models.load_tf(model_dir)\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234b3f6",
   "metadata": {},
   "source": [
    "## Plot data, labels, predictions over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b42107",
   "metadata": {
    "code_folding": [
     13
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start = 9000\n",
    "duration = 420\n",
    "\n",
    "def key(gidx): \n",
    "    gidx = gidx if gidx != 50 else 255\n",
    "    return (\n",
    "        gesture_info[f\"gesture{gidx:0>4}\"][\"key\"]\n",
    "        .replace('space', \"` '\")\n",
    "    )\n",
    "\n",
    "def make_lbl(gidx): return f'{key(gidx)}\\n{gidx}'\n",
    "\n",
    "def pred_plot(start, finsh, y_pred_probs, X, y, dt):\n",
    "    duration = finsh - start\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(WIDTH, 2.5), dpi=200)\n",
    "\n",
    "    g50 = y_pred_probs[start:start+duration, 50]\n",
    "    for idx in np.nonzero(g50 < 0.9)[0]:\n",
    "        likely_preds = np.nonzero(y_pred_probs[start + idx] > 0.1)[0]\n",
    "        probs_preds = [\n",
    "            e for e in \n",
    "            sorted(\n",
    "                zip(y_pred_probs[start + idx, likely_preds], likely_preds),\n",
    "                key=lambda tpl: -tpl[0]\n",
    "            )\n",
    "            if e[1] != 50\n",
    "        ]\n",
    "        if not probs_preds:\n",
    "            continue\n",
    "        lbl = '\\n'.join([\n",
    "            f'{key(pred)}: {round(prob*100)}\\%'\n",
    "            for prob, pred in \n",
    "            probs_preds\n",
    "        ])\n",
    "#         print(\n",
    "#             start + idx,\n",
    "#             y[start + idx],\n",
    "#             probs_preds\n",
    "#         )\n",
    "        true_val = y[start + idx]\n",
    "        true_gidx = 50 if true_val == 'nan' else int(y[start + idx][-4:])\n",
    "        pred_gidx = probs_preds[0][1]\n",
    "        axs[0].text(\n",
    "            idx, probs_preds[0][0], lbl,\n",
    "            ha='center', va='bottom',\n",
    "            bbox=dict(\n",
    "                boxstyle=\"round\",\n",
    "                ec=(\n",
    "                    'tab:green' \n",
    "                    if true_gidx == pred_gidx and probs_preds[0][0] > 0.5 else \n",
    "                    'tab:red'\n",
    "                ),\n",
    "                fc='#ddda',\n",
    "            )\n",
    "        )\n",
    "        axs[0].plot(\n",
    "            [idx, idx],\n",
    "            [0, 1],\n",
    "            c='k', alpha=0.5, linewidth=1, linestyle='dotted'\n",
    "        )\n",
    "\n",
    "    # For each class\n",
    "    for gidx in range(y_pred_probs.shape[-1]):\n",
    "        axs[0].plot(\n",
    "            y_pred_probs[start:start+duration, gidx],\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "    # print('plotting lines', flush=True)\n",
    "    for i in range(X.shape[-1]):\n",
    "        axs[1].plot(\n",
    "            X[start:start+duration, -1, i],\n",
    "            alpha=0.5,\n",
    "            c=[mpl.colormaps['tab10'](i) for i in range(10)][i//3],\n",
    "            lw=1,\n",
    "        )\n",
    "    axs[0].grid('both',lw=0.5, alpha=0.5)\n",
    "    axs[1].grid('both',lw=0.5, alpha=0.5)\n",
    "\n",
    "    for i, lbl in enumerate(y[start:start+duration]):\n",
    "        if pd.isna(lbl) or lbl == 'nan' or lbl == 'gesture0255': continue\n",
    "        gidx = int(lbl[-4:])\n",
    "        axs[1].text(\n",
    "            i, 800,\n",
    "            key(gidx) if duration > 3000 else f'{key(gidx)}\\n({gidx})',\n",
    "            ha='center', va='bottom',\n",
    "            bbox=None if duration > 3000 else dict(\n",
    "                boxstyle=\"round\",\n",
    "                ec='#dddf',\n",
    "                fc='#ddda',\n",
    "            )\n",
    "        )\n",
    "        axs[1].plot(\n",
    "            [i, i], [250, 950],\n",
    "            c='k', alpha=0.5, linewidth=1, linestyle='dotted'\n",
    "        )\n",
    "\n",
    "    axs[0].set(\n",
    "        ylabel='Probability',\n",
    "        yticks=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "        xticks=[],\n",
    "    )\n",
    "    axs[1].set(\n",
    "        ylabel='Sensor Value',\n",
    "        xticks=[],\n",
    "#         xticks=np.linspace(0, duration, 20).astype(int),\n",
    "#         xticklabels=np.linspace(0, duration, 20).astype(int) + start,\n",
    "        ylim=(250, 950),\n",
    "        yticks=np.arange(300, 901, 100),\n",
    "    )\n",
    "    return fig, axs\n",
    "    \n",
    "fig, axs = pred_plot(\n",
    "    900, 1800, y_pred_probs, X, y, dt\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369cbe5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_finshs = [\n",
    "#     (0, 9420, 'full_text'),\n",
    "    (140, 750  , 'the'),\n",
    "    (900, 1800 , 'quick'),\n",
    "    (2050, 3000, 'brown'),\n",
    "    (3460, 3900, 'fox'),\n",
    "    (4000, 5800, 'jumped'),\n",
    "    (5830, 6500, 'over'),\n",
    "    (6700, 7270, 'the'),\n",
    "    (7400, 8500, 'lazy'),\n",
    "    (8560, 9150, 'dog'),\n",
    "]\n",
    "\n",
    "for start, finsh, text in start_finshs:\n",
    "    print(start, finsh)\n",
    "    fig, axs = pred_plot(\n",
    "        start, finsh, y_pred_probs, X, y, dt\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_pred_plot_{start:0>4}_to_{finsh:0>4}_{text}.pdf'\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e17eea2",
   "metadata": {},
   "source": [
    "## Make a confusion matrix and precision-recall heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec5282",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "y_true = pd.Series(y).apply(lambda x: 50 if x in ('nan', 'gesture0255') else int(x[-4:]))\n",
    "cm = tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "report = sklearn.metrics.classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    output_dict=True,\n",
    "    zero_division=0,\n",
    "    labels=list(range(51))\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(0.5*WIDTH, 0.5*WIDTH))\n",
    "vis.conf_mat(cm, ax=ax)\n",
    "ax.set(\n",
    "    title='Confusion Matrix\\nEnglish-language phrase'\n",
    ")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_eng_lang_phrase_conf_mat.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(0.5*WIDTH, 0.15*WIDTH))\n",
    "vis.precision_recall_f1(report=report, ax=ax)\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/c.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a2d5e",
   "metadata": {},
   "source": [
    "## Plot data, predictions, keystrokes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454dc576",
   "metadata": {
    "code_folding": [
     0,
     3
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "# clf=None\n",
    "@interact(start=(0, len(df), 200), duration=(0, len(df), 200))\n",
    "def fn(start=10, duration=500):\n",
    "    fig, axs = plt.subplots(3 if clf is not None else 2, 1, figsize=(WIDTH, WIDTH))\n",
    "    for i in range(X.shape[-1]):\n",
    "        axs[0].plot(\n",
    "            X[start:start+duration, 0, i],\n",
    "            alpha=0.5,\n",
    "            c=['tab:red', 'tab:green', 'tab:blue'][i%3],\n",
    "            lw=1,\n",
    "        )\n",
    "    sns.heatmap(\n",
    "        X[start:start+duration, 0, :].T,\n",
    "        cmap='Spectral',\n",
    "        ax=axs[1],\n",
    "        cbar=False,\n",
    "        vmin=290,\n",
    "        vmax=910,\n",
    "        yticklabels=5,\n",
    "    )\n",
    "\n",
    "    if clf is not None:\n",
    "        sns.heatmap(\n",
    "            y_pred_probs[start-10:start+duration-10, :].T,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            ax=axs[2],\n",
    "            cbar=False,\n",
    "            yticklabels=5,\n",
    "            cmap='Spectral',\n",
    "        )\n",
    "        axs[2].set(\n",
    "            ylabel='Predicted\\ngesture',\n",
    "        )\n",
    "        for idx in np.nonzero(y_pred[start-10:start+duration-10] != 50)[0]:\n",
    "            gidx = y_pred[start-10:start+duration-10][idx]\n",
    "            gidx = 255 if gidx == 50 else gidx\n",
    "            txt = gesture_info[f'gesture{gidx:0>4}']['key']\n",
    "            axs[0].text(\n",
    "                idx, \n",
    "                800,\n",
    "                txt,\n",
    "            )\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "    \n",
    "    axs[0].set(\n",
    "        ylabel='Sensor value',\n",
    "        xticks=[],\n",
    "        ylim=(250, 950)\n",
    "    )\n",
    "    axs[1].set(\n",
    "        ylabel='Sensor number',\n",
    "        xticks=[],\n",
    "    )\n",
    "    axs[0].margins(0)\n",
    "    with_clf =' and model predictions' if clf is not None else ''\n",
    "    axs[0].set_title(\n",
    "        f'Sensor values{with_clf} over time from {np.round(start/40, 2)}s\\n'\n",
    "        f'(duration: {np.round(duration/40, 2)} seconds)'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9de61",
   "metadata": {},
   "source": [
    "## Easily convert text to gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4129ff",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def char_to_gesture(c):\n",
    "    c_old = c\n",
    "    if c == ' ':\n",
    "        c = 'space'\n",
    "    for k, v in gesture_info.items():\n",
    "        if v['key'] == c.lower():\n",
    "            desc = (\n",
    "                v[\"description\"]\n",
    "                .replace(\"l\", \"left \")\n",
    "                .replace(\"r\", \"right\")\n",
    "                .replace(\" 1\", \" thumb\")\n",
    "                .replace(\" 2\", \" index\")\n",
    "                .replace(\" 3\", \" middle\")\n",
    "                .replace(\" 4\", \" ring\")\n",
    "                .replace(\" 5\", \" pinky\")\n",
    "            )\n",
    "            return f'[{c_old}] {k}  {desc}'\n",
    "text = 'the quick brown fox jumps over the lazy dog'\n",
    "\n",
    "print('\\n'.join(char_to_gesture(c) for c in text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edb018",
   "metadata": {},
   "source": [
    "# Misc Methodology chapter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4_true = np.array([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "])\n",
    "y_4_pred = np.array([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    0, 1, 2, 3, 5, 4,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    2, 2, 2, 2, 2, 2,\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "\n",
    "])\n",
    "conf_mat = tf.math.confusion_matrix(y_4_true, y_4_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(WIDTH, WIDTH))\n",
    "\n",
    "titles = np.array([\n",
    "    [\"Count of observations\", \"Normalized by columns\"],\n",
    "    [\"Normalized by rows\", \"Normalized by total sum\"],\n",
    "])\n",
    "\n",
    "for i in (0, 1):\n",
    "    for j in (0, 1):\n",
    "        if i == j == 0:\n",
    "            div = 1\n",
    "        elif i == j == 1:\n",
    "            div = conf_mat.sum()\n",
    "        elif i == 0 and j == 1:\n",
    "            div = conf_mat.sum(axis=0)\n",
    "        elif i == 1 and j == 0:\n",
    "            div = conf_mat.sum(axis=1)\n",
    "        sns.heatmap(\n",
    "            conf_mat / div,\n",
    "            square=True,\n",
    "            annot=True,\n",
    "            fmt='.0f' if i == j == 0 else '.2f',\n",
    "            mask=conf_mat == 0,\n",
    "            cmap='Spectral',\n",
    "            vmin=0,\n",
    "            vmax=conf_mat.max() if i == j == 0 else 1.0,\n",
    "            ax=axs[i, j],\n",
    "        )\n",
    "        axs[i, j].set(\n",
    "            title=titles[i, j],\n",
    "            xlabel='Predicted',\n",
    "            ylabel='Ground Truth',\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_example_conf_mat.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(WIDTH, WIDTH*.25))\n",
    "report = sklearn.metrics.classification_report(\n",
    "    y_4_true,\n",
    "    y_4_pred,\n",
    "    zero_division=0,\n",
    "    output_dict=True,\n",
    ")\n",
    "vis.precision_recall_f1(report, ax=ax, annot=True)\n",
    "# ax.set_xticks([0, 1, 2, 3, 4, 5]);\n",
    "# ax.set_xticklabels([0, 1, 2, 3, 4, 5]);\n",
    "ax.set(\n",
    "    title='Precision, Recall, and $F_1$-score',\n",
    "    xlabel='Class',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_prec_rec_f1_example.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba859a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(0.5*WIDTH, 0.5*WIDTH))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.arange(0.1, 0.96, 0.1), \n",
    "    cmap='Spectral'\n",
    "#     colors='black',\n",
    "#     alpha=0.5\n",
    ")\n",
    "ax.clabel(contours, inline=True, fmt='%.2f')\n",
    "ax.set(\n",
    "    title='Precision vs Recall',\n",
    "    ylabel='Recall',\n",
    "    xlabel='Precision',\n",
    "    xticks=np.arange(0, 1.01, 0.1),\n",
    "    yticks=np.arange(0, 1.01, 0.1),\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_precision_recall_f1.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4_true = np.array([\n",
    "    5, 5, 5, 5, 5, 5, 5, 0, 0, 0,\n",
    "    5, 5, 5, 5, 5, 5, 5, 1, 1, 1,\n",
    "    5, 5, 5, 5, 5, 5, 5, 2, 2, 2,\n",
    "    5, 5, 5, 5, 5, 5, 5, 3, 3, 3,\n",
    "    5, 5, 5, 5, 5, 5, 5, 4, 4, 4,\n",
    "])\n",
    "y_4_pred = np.array([\n",
    "    5, 5, 5, 5, 5, 5, 0, 5, 0, 0,\n",
    "    5, 5, 5, 5, 5, 5, 1, 5, 5, 1,\n",
    "    5, 5, 5, 5, 5, 5, 2, 5, 2, 2,\n",
    "    5, 5, 5, 5, 5, 5, 3, 5, 4, 3,\n",
    "    5, 5, 5, 5, 5, 5, 4, 5, 4, 4,\n",
    "\n",
    "])\n",
    "conf_mat = tf.math.confusion_matrix(y_4_true, y_4_pred).numpy()\n",
    "\n",
    "sns.heatmap(\n",
    "    conf_mat / conf_mat.sum(axis=1),\n",
    "    square=True,\n",
    "    annot=True,\n",
    "#     fmt='.0f' if i == j == 0 else '.2f',\n",
    "    mask=conf_mat == 0,\n",
    "    cmap='Spectral',\n",
    ")\n",
    "plt.show()\n",
    "report = sklearn.metrics.classification_report(\n",
    "    y_4_true,\n",
    "    y_4_pred,\n",
    "    zero_division=0,\n",
    "    output_dict=True,\n",
    ")\n",
    "vis.precision_recall_f1(report, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61445582",
   "metadata": {},
   "source": [
    "# Misc Results Chapter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f431f5",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100164fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml'\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c09256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'].iloc[np.arange(s, f, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdce773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(WIDTH, WIDTH))\n",
    "s = 3270\n",
    "f = 3350\n",
    "idxs = np.arange(s, f)\n",
    "\n",
    "axs[0].plot(\n",
    "    df[sensor_names].iloc[idxs]\n",
    ")\n",
    "axs[0].set(\n",
    "    xticks=np.arange(0, f - s, 10),\n",
    "    yticks=np.arange(250, 950, 100),\n",
    "    ylabel='Sensor Value',\n",
    "    title='Sensor Values over Time',\n",
    ")\n",
    "axs[0].margins(x=0)\n",
    "vis.add_grid(axs[0])\n",
    "\n",
    "axs[1].imshow(\n",
    "    df[sensor_names].iloc[idxs].T,\n",
    "    cmap='Spectral'\n",
    ")\n",
    "# xticklabels = df['datetime'].iloc[np.arange(s, f, 10)].apply(lambda x: str(x)[:-3])\n",
    "axs[1].set(\n",
    "    ylabel='Sensor Number',\n",
    "    yticks=np.arange(0, 30, 5),\n",
    "    xlabel='Timestep',\n",
    "    xticks=np.arange(0, f - s, 10),\n",
    "    xticklabels=np.arange(s, f, 10),\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/04_sensors_over_time.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3241fd3",
   "metadata": {},
   "source": [
    "## All observations of gesture XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143cd69",
   "metadata": {
    "code_folding": [
     0,
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "def prettify_sensor_name(sensor_name):\n",
    "    return {\n",
    "        \"l5x\": \"Left Little X\",\n",
    "        \"l5y\": \"Left Little Y\",\n",
    "        \"l5z\": \"Left Little Z\",\n",
    "        \"l4x\": \"Left Ring X\",\n",
    "        \"l4y\": \"Left Ring Y\",\n",
    "        \"l4z\": \"Left Ring Z\",\n",
    "        \"l3x\": \"Left Middle X\",\n",
    "        \"l3y\": \"Left Middle Y\",\n",
    "        \"l3z\": \"Left Middle Z\",\n",
    "        \"l2x\": \"Left Index X\",\n",
    "        \"l2y\": \"Left Index Y\",\n",
    "        \"l2z\": \"Left Index Z\",\n",
    "        \"l1x\": \"Left Thumb X\",\n",
    "        \"l1y\": \"Left Thumb Y\",\n",
    "        \"l1z\": \"Left Thumb Z\",\n",
    "        \"r1x\": \"Right Thumb X\",\n",
    "        \"r1y\": \"Right Thumb Y\",\n",
    "        \"r1z\": \"Right Thumb Z\",\n",
    "        \"r2x\": \"Right Index X\",\n",
    "        \"r2y\": \"Right Index Y\",\n",
    "        \"r2z\": \"Right Index Z\",\n",
    "        \"r3x\": \"Right Middle X\",\n",
    "        \"r3y\": \"Right Middle Y\",\n",
    "        \"r3z\": \"Right Middle Z\",\n",
    "        \"r4x\": \"Right Ring X\",\n",
    "        \"r4y\": \"Right Ring Y\",\n",
    "        \"r4z\": \"Right Ring Z\",\n",
    "        \"r5x\": \"Right Little X\",\n",
    "        \"r5y\": \"Right Little Y\",\n",
    "        \"r5z\": \"Right Little Z\",\n",
    "    }.get(sensor_name, sensor_name)\n",
    "\n",
    "for gidx in (0, 5, 11, 16, 22, 27, 33, 38, 44, 49):\n",
    "    idxs = np.nonzero(df['gidx'] == gidx)[0][:20]\n",
    "    cross_idxs = idxs[:, np.newaxis] + np.arange(-10, 21)\n",
    "    fig, axs = plt.subplots(5, 6, figsize=(BIG_WIDTH, BIG_WIDTH*5/6))\n",
    "    axs = vis.cmp_ts(\n",
    "        df[sensor_names].values[cross_idxs],\n",
    "        axs=axs,\n",
    "        lw=0.25,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        ax.set_title(\n",
    "            prettify_sensor_name(ax.get_title()),\n",
    "            loc='center',\n",
    "            y=0.95,\n",
    "        )\n",
    "        ax.set_ylim()\n",
    "        ax.set(\n",
    "            ylim=(250, 990),\n",
    "            yticks=[300, 500, 700, 900],\n",
    "            yticklabels=[] if i%6 != 0 else [300, 500, 700, 900],\n",
    "            xticks=[5, 15, 25],\n",
    "            xticklabels=[] if i+6 < len(axs.flat) else ['-10', '0', '+10'],\n",
    "        )\n",
    "        ax.grid('y', alpha=0.25, lw=1)\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "#         vis.add_grid(ax)\n",
    "\n",
    "    plt.suptitle(f'Gesture {gidx}')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(\n",
    "        wspace=0.1,\n",
    "        hspace=0.3,\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_example_g{gidx:0>4}_plot.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62187c",
   "metadata": {},
   "source": [
    "## Correlations between the different gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "timestep = 0\n",
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())\n",
    "X_data = X_trn[y_trn != 50][:, timestep, :]\n",
    "y_data = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70849870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "fig, axs = plt.subplots(\n",
    "    5, 10,\n",
    "    figsize=(WIDTH, WIDTH*2),\n",
    "    dpi=200,\n",
    ")\n",
    "for i in range(5):\n",
    "    print(f'gesture {i}_', flush=True)\n",
    "    for j in range(10):\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(X_data[y_data == (i * 10 + j)]).corr(),\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            ax=axs[i, j],\n",
    "            xticklabels=[s.upper() for s in sensor_names],\n",
    "            yticklabels=[s.upper() for s in sensor_names],\n",
    "            square=True,\n",
    "        )\n",
    "        axs[i, j].set_title(f'Gesture {i * 10 + j}')\n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fc41b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(X_data).corr(),\n",
    "    vmin=-1, \n",
    "    vmax=1,\n",
    "    center=0,\n",
    "#     cbar=False,\n",
    "    xticklabels=[s.upper() for s in sensor_names],\n",
    "    yticklabels=[s.upper() for s in sensor_names],\n",
    "    square=True,\n",
    ")\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Sensor')\n",
    "plt.title('Correlations between sensors\\n(over all training data)')\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_correlations.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711495e",
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(WIDTH, WIDTH/3))\n",
    "axis = ['X', 'Y', 'Z']\n",
    "for i in range(3):\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(X_data[:, i::3]).corr(),\n",
    "        vmin=-1, \n",
    "        vmax=1,\n",
    "        center=0,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        ax=axs[i]\n",
    "    )\n",
    "    axs[i].set_title(f'Correlations between {axis[i]}-axis sensors\\n(over all training data)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f86",
   "metadata": {},
   "source": [
    "## Time-series heatmap + line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "def plt_subset(s, f):\n",
    "    df = read.read_data(\n",
    "        '../gesture_data/train/', \n",
    "        constants_path='../src/constants.yaml'\n",
    "    )\n",
    "    df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "    const = common.read_constants('../src/constants.yaml')\n",
    "    sensor_names = list(const['sensors'].values())\n",
    "    data = df[sensor_names].values[s:f]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(WIDTH, WIDTH*.5))\n",
    "    sns.heatmap(\n",
    "        data.T,\n",
    "        ax=axs[0],\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    axs[1].plot(\n",
    "        data,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    plt.margins(0)\n",
    "    plt.show()\n",
    "# plt_subset(91_000, 95_000)\n",
    "plt_subset(93_000, 93_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46355c0e",
   "metadata": {},
   "source": [
    "## Histogram of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "df['gidx'].hist()\n",
    "plt.show()\n",
    "df.loc[df['gidx'] != 50, 'gidx'].hist()\n",
    "df['gidx'].value_counts() / len(df['gidx']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da38f",
   "metadata": {},
   "source": [
    "## All observations of one gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de297a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # This cell is unused\n",
    "\n",
    "gidx = 0\n",
    "before = 10\n",
    "after = 10\n",
    "idxs = np.nonzero(df['gidx'] == gidx)[0][:, np.newaxis] + np.arange(-before, after+1)\n",
    "\n",
    "vis.cmp_ts(df[sensor_names].values[idxs + 10]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo-venv",
   "language": "python",
   "name": "ergo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
