{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69b0d03",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff0b1d",
   "metadata": {},
   "source": [
    "## Notes and Quick ideas\n",
    "\n",
    "- Now do plots with the repetitions baked in. Show which hyperparameter combinations have the least variance\n",
    "\n",
    "- Figure out what went wrong in the labelling\n",
    "    - Potentially relabel validation/training/testing(!)\n",
    "- Redo difference graph after the relabelling\n",
    "- Give a description of the dataset, what's in it\n",
    "- Load dataset onto zenodo\n",
    "- Create a bridge from background chapter to how the models are used\n",
    "\n",
    "### Meeting notes\n",
    "- [x] Check (before writing results chapter) that the delay isn't too big\n",
    "- [x] Make *very* sure that the model can be run in real time, with the gloves\n",
    "- [x] Conf matrix should be %age of the class\n",
    "- [x] Explain Conf matrix structure (diagonals/orientations/fingers) in thesis\n",
    "- [x] Include 'dummy' models which perfectly predict only finger/orientation/hand, etc\n",
    "     - put it in a separate section in methodology\n",
    "- [x] Look into plotting error on FFNN\n",
    "- Discuss precision/recall for 51 gesture FFNN/HMM/CuSUM  -> Why would this happen\n",
    "- Error types: (wrong timestep) x (wrong gesture)\n",
    "    - It seems like the FFNN is not getting the timestep wrong, it's just wrong\n",
    "- Explore plots of hpars affecting regularization and validation performance\n",
    "- Make note that the HMM is only predicting 200 g255 gestures\n",
    "\n",
    "### Changes made\n",
    "\n",
    "- F1 score was being set to NaN, resulting in the average being too high (and F1 ~= 1.0)\n",
    "- Grid search was unable to explore the search space fully, so [Optuna](https://optuna.readthedocs.io/en/stable/) was used for the search.\n",
    "    - Specifically, the [Tree-structured Parzen Estimator](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler) performs the search. Bergstra, James et al. “Algorithms for Hyper-Parameter Optimization.” NIPS (2011). [Explanatory Blog](http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#tree-structured-parzen-estimators-tpe)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139088",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a2aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:17:09.963720Z",
     "start_time": "2023-10-06T13:17:09.294069Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change directory to keep paths consistent\n",
    "%cd /Users/brk/projects/masters/SU/ergo/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22165a6e",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d078368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:14.614173Z",
     "start_time": "2023-10-06T13:55:14.581936Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import vis\n",
    "import common\n",
    "import read\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import tqdm\n",
    "import logging as l\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f\n",
    "\n",
    "mpl.rc('font', family='serif', serif='cmr10')\n",
    "mpl.rc('axes.formatter', use_mathtext=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbd3fa",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:15.215870Z",
     "start_time": "2023-10-06T13:55:15.185260Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "def prettify_col_name(x):\n",
    "    return x.split('.')[-1].replace('_', ' ').title()\n",
    "\n",
    "def calculate_prediction_ellipse(x, y, alpha=0.5):\n",
    "    \"\"\"Given some x and y data, calculate the (1-alpha) confidence ellipse.\"\"\"\n",
    "    data = np.column_stack((x, y)) # Combine x and y into a single data array\n",
    "    num_dimensions = data.shape[1]\n",
    "    num_data_points = data.shape[0]\n",
    "    # Estimate the sample covariance matrix\n",
    "    sample_covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Calculate the sample mean for each dimension\n",
    "    sample_mean = np.mean(data, axis=0)\n",
    "    # Generate angles for the ellipse\n",
    "    theta = np.linspace(0, 2*np.pi, num=100)\n",
    "    # Calculate the radius of the ellipse. `f.ppf` is the inverse of the CDF\n",
    "    radius = np.sqrt(\n",
    "        num_dimensions * (num_data_points - 1) / (num_data_points - num_dimensions) *\n",
    "        (1 + 1/num_data_points) * f.ppf(1 - alpha, num_dimensions, num_data_points - num_dimensions)\n",
    "    )\n",
    "#     print(sample_covariance_matrix)\n",
    "    # Compute the Cholesky decomposition of the covariance matrix\n",
    "    chol_cov_matrix = np.linalg.cholesky(sample_covariance_matrix)\n",
    "    # Generate ellipse offset based on Cholesky decomposition\n",
    "    ellipse_offset = np.outer(np.cos(theta), chol_cov_matrix[0, :]) + np.outer(np.sin(theta), chol_cov_matrix[1, :])\n",
    "    # Calculate the points of the prediction interval ellipse\n",
    "    prediction_ellipse_points = sample_mean + radius * ellipse_offset\n",
    "    return prediction_ellipse_points\n",
    "\n",
    "def get_npz_data_from_model(model_dir):\n",
    "    \"\"\"Given a directory of a model, return it's y_pred and y_true.\"\"\"\n",
    "    data = np.load(f'{model_dir}/y_val_true_y_val_pred.npz')\n",
    "    y_true = data['y_true']\n",
    "    y_pred = data['y_pred']\n",
    "    return y_true, y_pred\n",
    "\n",
    "def show_conf_mat_from_model(model_dir, ax=None):\n",
    "    \"\"\"Given a directory of a model, plot its confidence matrix\"\"\"\n",
    "    y_true, y_pred = get_npz_data_from_model(model_dir)\n",
    "    cm_val = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    p = vis.conf_mat(cm_val / cm_val.sum(axis=0), ax=ax)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46788",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:16.780408Z",
     "start_time": "2023-10-06T13:55:15.641925Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data from hpar optimisation\n",
    "paths = sorted(glob.glob('../saved_models/results_*_optuna.jsonl'))\n",
    "print(f'Reading data from\\n', \"\\n\".join(paths))\n",
    "dfs = map(\n",
    "    lambda path: pd.read_json(path, lines=True),\n",
    "    paths\n",
    ")\n",
    "# Concat the dataframes together, and then do a \n",
    "# copy to avoid a dataframe fragmentation warning\n",
    "# Reset the index to avoid a seaborn error https://github.com/mwaskom/seaborn/issues/3291\n",
    "df = pd.concat(dfs).reset_index(drop=True).copy()\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].fillna('51')\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].astype(int).astype(str)\n",
    "\n",
    "# 50-class HFFNNs don't make sense, remove them\n",
    "df = df[~(\n",
    "    (df['model_type'] == 'HFFNN')\n",
    "    & (df['preprocessing.num_gesture_classes'] == '50')\n",
    ")]\n",
    "\n",
    "df.groupby(['model_type', 'preprocessing.num_gesture_classes']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1f85",
   "metadata": {},
   "source": [
    "## Calculate some auxillary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18c065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:17.141312Z",
     "start_time": "2023-10-06T13:55:17.100874Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data a little bit, and get a list of dependant variables\n",
    "# Preprocess the df a bit to get some nice-to-use columns\n",
    "\n",
    "prefixes = (\n",
    "    'ffnn.nodes_per_layer',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer',\n",
    ")\n",
    "for i in (1, 2, 3):\n",
    "    for prefix in prefixes:\n",
    "        print(f'{prefix}.{i}')\n",
    "        df[f'{prefix}.{i}'] = df[prefix].apply(\n",
    "            lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else None\n",
    "        )\n",
    "\n",
    "# Calculate ratios\n",
    "avgs = ('macro avg', 'weighted avg')\n",
    "metrics = ('f1-score', 'precision', 'recall')\n",
    "\n",
    "for avg in avgs:\n",
    "    for metric in metrics:\n",
    "        df[f'ratio.{avg}.{metric}'] = df[f'trn.{avg}.{metric}'] / df[f'val.{avg}.{metric}']\n",
    "        df[f'ratio.{avg}.{metric}'] = np.where(\n",
    "            np.isfinite(df[f'ratio.{avg}.{metric}']),\n",
    "            df[f'ratio.{avg}.{metric}'],\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "# Print out a list of dependant variables\n",
    "dep_vars = sorted([\n",
    "    c for c in df.columns \n",
    "    if 'val' not in c and 'trn' not in c and 'ratio' not in c and c not in (\n",
    "        'saved_at', 'fit_time', 'preprocessing.gesture_allowlist', \n",
    ")], key=lambda c: str(c))\n",
    "print(f\"Dependant variables: {dep_vars}\")\n",
    "# print(\"\\nVariables which change:\")\n",
    "# max_len = max(map(lambda x: len(x), dep_vars))\n",
    "# Print out all dependant variables that change\n",
    "# for var in dep_vars:\n",
    "#     uniq = df[var].apply(lambda x: str(x) if isinstance(x, list) else x).unique()\n",
    "#     if len(uniq) > 1:\n",
    "#         print(f\"{var: <{max_len}} {uniq}\")\n",
    "        \n",
    "df['ffnn.dropout_rate'] = np.round(df['ffnn.dropout_rate'], 6)\n",
    "\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['trn.pred_time_per_obs'] = df['trn.pred_time'] / df['trn.num_observations']\n",
    "df['fit_time_per_obs'] = df['fit_time'] / df['trn.num_observations']\n",
    "\n",
    "\n",
    "# Add some log10 columns\n",
    "log10_cols = [\n",
    "    'val.loss',\n",
    "    'trn.loss',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]\n",
    "df[[f'{c}.log10' for c in log10_cols]] = np.log10(df[log10_cols])\n",
    "\n",
    "# There are a *lot* of columns. Here's a more-useful subset\n",
    "subset_cols = [\n",
    "    c for c in df.columns\n",
    "    if (not re.search(r'((trn|val)\\.\\d+\\.)|weighted avg', c)) and \n",
    "        (c not in [\n",
    "            'hmm', 'lstm', 'ffnn', 'nn', 'hffnn', 'cusum', 'svm',\n",
    "            'preprocessing.n_timesteps',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5643dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:18.056795Z",
     "start_time": "2023-10-06T13:55:17.445133Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "ngestures = ('51', '50', '5')\n",
    "xmin = None\n",
    "xmax = None\n",
    "for ax, ngesture in zip(axs, ngestures):\n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == ngesture],\n",
    "        x='saved_at',\n",
    "        y='preprocessing.seed',\n",
    "        hue='model_type',\n",
    "        s=10,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "    #     alpha=0.1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f'{ngesture} gestures')\n",
    "#     if xmin is None: xmin = ax.get_xlim()[0]\n",
    "#     if xmax is None: xmax = ax.get_xlim()[1]\n",
    "#     xmin = min(xmin, ax.get_xlim()[0])\n",
    "#     xmax = min(xmax, ax.get_xlim()[1])\n",
    "# for ax in axs:\n",
    "#     ax.set_xlim((xmin, xmax))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21ea87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:18.394546Z",
     "start_time": "2023-10-06T13:55:18.359175Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[\n",
    "    (df['model_type'] != 'HFFNN')\n",
    "    | (df['saved_at'] > pd.to_datetime('2023-10-01T11:00:00'))\n",
    "]\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49356a4",
   "metadata": {},
   "source": [
    "## Constants to keep colours consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d325959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:36:11.068099Z",
     "start_time": "2023-10-06T13:36:11.042554Z"
    }
   },
   "outputs": [],
   "source": [
    "model_colours = {\n",
    "    'FFNN': 'tab:blue',\n",
    "    'HFFNN': 'tab:orange',\n",
    "    'CuSUM': 'tab:green',\n",
    "    'HMM': 'tab:red',\n",
    "    'SVM': 'tab:purple',\n",
    "}\n",
    "palette = 'Spectral'\n",
    "other_colours = [\n",
    "    'tab:brown',\n",
    "    'tab:pink',\n",
    "    'tab:grey',\n",
    "    'tab:olive',\n",
    "    'tab:cyan',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eeb4a",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491a623",
   "metadata": {},
   "source": [
    "## Bar plot of number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bec16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:05:48.032093Z",
     "start_time": "2023-10-05T18:05:47.052531Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "counts = pd.Series(y_trn).value_counts()\n",
    "axs[0].bar(counts.index, counts)\n",
    "\n",
    "\n",
    "counts = pd.Series(y_trn[y_trn != 50]).value_counts()\n",
    "axs[1].bar(counts.index, counts)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Count of classes in the training dataset\\n',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Count of classes in the training dataset\\n(excluding class 50)',\n",
    "    xlabel='Class',\n",
    "    ylabel='Count',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_class_imbalance.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c94d8c",
   "metadata": {},
   "source": [
    "## Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4427f33",
   "metadata": {},
   "source": [
    "### 51 classes, Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:23:59.091066Z",
     "start_time": "2023-10-06T13:23:58.716235Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.1, 1, 10), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_xlim((-0.1, 1.1))\n",
    "axs[0].set_ylim((-0.1, 1.1))\n",
    "axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0].set_title(f'Precision vs Recall for models trained on 51 classes\\n(contours denote $F_1$)')\n",
    "axs[0].set_xlabel(f'Precision')\n",
    "axs[0].set_ylabel(f'Recall')\n",
    "axs[0].legend().set_title(\"Model \")\n",
    "\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='model_type',\n",
    "    s=2,\n",
    "    alpha=0.5,\n",
    "    order=list(model_colours.keys()),\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "axs[1].set_title(f'$F_1$-score for models trained on 51 classes')\n",
    "axs[1].set_xlabel(f'Model Type')\n",
    "axs[1].set_ylabel(f'$F_1$-score')\n",
    "axs[1].set_ylim((-0.1, 1.1))\n",
    "axs[1].grid(axis='y')\n",
    "\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_precision_recall_51_classes.pdf', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:25:17.676183Z",
     "start_time": "2023-10-06T13:25:17.465325Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "data = df.loc[\n",
    "    df['preprocessing.num_gesture_classes'] == '51',\n",
    "    ['model_type', 'val.macro avg.recall', 'val.macro avg.precision']\n",
    "].melt(\n",
    "    id_vars=['model_type'], \n",
    "    var_name='metric', \n",
    "    value_name='value'\n",
    ")\n",
    "data['metric'] = data['metric'].replace({\n",
    "    'val.macro avg.recall': 'Recall',\n",
    "    'val.macro avg.precision': 'Precision',\n",
    "})\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x=\"model_type\", \n",
    "    y=\"value\", \n",
    "    hue=\"metric\",\n",
    "    order=list(model_colours.keys()),\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    alpha=0.75,\n",
    "    size=2,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "\n",
    "ax.set_title(f'Precision and recall for all model types')\n",
    "ax.set_xlabel(f'Model Type')\n",
    "ax.set_ylabel(f'Metric Value')\n",
    "ax.legend().set_title(\"Metric\")\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "ax.set_yticklabels(np.round(np.arange(0, 1.1, .1), 1))\n",
    "ax.grid(axis='y')\n",
    "\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_precision_recall_stripplot.pdf', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1b84",
   "metadata": {},
   "source": [
    "### Precision vs Recall for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760213ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:25:37.577349Z",
     "start_time": "2023-10-06T13:25:36.989987Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for ax, n_classes in zip(axs, n_gesture_classes):\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == n_classes],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        hue='model_type',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlim((-0.1, 1.1))\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{n_classes} gesture classes')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77f603",
   "metadata": {},
   "source": [
    "## Average Models by hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109bfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:06:13.731019Z",
     "start_time": "2023-10-05T18:06:13.588852Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-errors\n",
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight', 'svm.max_iter'],\n",
    "}\n",
    "\n",
    "agg_functions = {\n",
    "    'val.macro avg.f1-score': ['min', 'mean', 'median', 'max', 'std', 'count']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_type, hpars in type_to_hpars.items():\n",
    "    print(model_type, hpars)\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    # Group by the specified columns and calculate the statistics for 'metric'\n",
    "    # result_df = df.groupby(hpars)['val.macro avg.f1-score'].mean()\n",
    "    result_df = data.groupby(hpars).agg(agg_functions).reset_index()\n",
    "\n",
    "    # Flatten the multi-level column index\n",
    "    result_df.columns = ['.'.join(col).strip() if col[1] else col[0] for col in result_df.columns.values]\n",
    "    result_df['model_type'] = model_type\n",
    "    results.append(result_df)\n",
    "\n",
    "results_df = pd.concat(results)\n",
    "results_df\n",
    "# df[hpars]\n",
    "# TODO delete all the old observations which only have one repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c6477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:06:16.599977Z",
     "start_time": "2023-10-05T18:06:16.521777Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "hpars = [\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "for hpar, ax in zip(hpars, axs.flatten()):\n",
    "    sns.scatterplot(\n",
    "        data=result_df,\n",
    "        x=hpar,\n",
    "        y='val.macro avg.f1-score.mean',\n",
    "        ax=ax,\n",
    "    )\n",
    "#     result_df[hpar]\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0e507",
   "metadata": {},
   "source": [
    "## Top X performing models by precision/recall/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c55ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:06:17.904192Z",
     "start_time": "2023-10-05T18:06:17.373981Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Since every model gets 5 repetitions, the \"top 5\" will likely only contain one model.\n",
    "top_n = 9\n",
    "metric = 'val.macro avg.f1-score'\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "].sort_values(metric, ascending=False).head(top_n)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    best = data.iloc[i]\n",
    "    show_conf_mat_from_model(f\"../{best['model_dir']}\", ax)\n",
    "    ax.set(\n",
    "        title=f\"{best['model_type']}\\n$F_1=${np.round(best['val.macro avg.f1-score'], 4)}\",\n",
    "    )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102c42e",
   "metadata": {},
   "source": [
    "## Get statistics for each hyperparameter combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33406a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:06:17.909166Z",
     "start_time": "2023-10-05T18:06:17.909161Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') & \n",
    "    (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "    (df['preprocessing.seed'] == 42.0)\n",
    "]\n",
    "\n",
    "data[[c for c in subset_cols if 'ffnn.' in c or 'nn.' in c]].head(31)\n",
    "data[subset_cols].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952b865",
   "metadata": {},
   "source": [
    "## Training vs Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da05d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:26:50.933470Z",
     "start_time": "2023-10-06T13:26:49.172557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 2],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 2],\n",
    ")\n",
    "\n",
    "axs[0, 0].plot([0, 0.1], [0, 0.1], color='black', alpha=.1)\n",
    "axs[0, 1].plot([0, 0.005], [0, 0.005], color='black', alpha=.1)\n",
    "axs[0, 2].plot([0, 0.00005], [0, 0.00005], color='black', alpha=.1)\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference times (seconds per observation)\\n',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 2].set(\n",
    "    title='c) Inference times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='d) Inference vs training times (seconds per observation)\\n',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 1].set(\n",
    "    title='e) Inference vs training times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 2].set(\n",
    "    title='f) Inference vs training times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_trn_times_per_obs.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473064",
   "metadata": {},
   "source": [
    "## Inference time vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e99dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:26:40.762129Z",
     "start_time": "2023-10-06T13:26:39.921430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_ylim((-0.001, 0.011))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['val.pred_time_per_obs'] < 0.0001)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    ")\n",
    "plt.tight_layout()\n",
    "axs[0].set_xlim((-0.05, 1.05))\n",
    "axs[1].set_xlim((-0.05, 1.05))\n",
    "axs[0].set_xlabel('$F_1$-score')\n",
    "axs[1].set_xlabel('$F_1$-score')\n",
    "axs[0].set_ylabel('Inference time per observation (s)')\n",
    "axs[1].set_ylabel('Inference time per observation (s)')\n",
    "axs[0].set_title('Inference time per observation against $F_1$ score\\n')\n",
    "axs[1].set_title('Inference time per observation against $F_1$ score\\n(0 to 0.0001s)')\n",
    "\n",
    "axs[0].legend().set_title(\"Model Type\")\n",
    "axs[1].legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inference_time_per_obs_vs_f1.pdf', \n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0978408",
   "metadata": {},
   "source": [
    "## Confusion Matrices of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e34da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:27:06.097415Z",
     "start_time": "2023-10-06T13:27:03.014873Z"
    }
   },
   "outputs": [],
   "source": [
    "ngestures = sorted(df['preprocessing.num_gesture_classes'].unique())\n",
    "model_types = sorted(df['model_type'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(ngestures),\n",
    "    len(model_types),\n",
    "    figsize=(len(model_types)*6, len(ngestures)*6),\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "for i, ngesture in enumerate(ngestures):\n",
    "    for j, model_type in enumerate(model_types):\n",
    "        best = df[\n",
    "            (df['preprocessing.num_gesture_classes'] == ngesture) &\n",
    "            (df['model_type'] == model_type)\n",
    "        ].sort_values('val.macro avg.f1-score', ascending=False)\n",
    "        if len(best) == 0:\n",
    "            axs[i,j].axis('off')\n",
    "            continue\n",
    "        best = best.iloc[0]\n",
    "        print(ngesture, model_type, best['model_dir'])\n",
    "        try:\n",
    "            show_conf_mat_from_model(f\"../{best['model_dir']}\", axs[i, j])\n",
    "        except FileNotFoundError:\n",
    "            show_conf_mat_from_model(f\"./{best['model_dir']}\", axs[i, j])\n",
    "        axs[i, j].set(\n",
    "            title=f\"Best {model_type}: {ngesture} gestures\\n($F_1=${np.round(best['val.macro avg.f1-score'], 4)})\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42904a9",
   "metadata": {},
   "source": [
    "## Mean Confidence Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b56e8",
   "metadata": {},
   "source": [
    "### 5 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cc251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T19:07:35.195329Z",
     "start_time": "2023-10-05T19:07:28.631679Z"
    }
   },
   "outputs": [],
   "source": [
    "nclasses = '5'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "#     conf_mat[-1, -1] = 0\n",
    "#     conf_mat /= conf_mat_totals[hpar_item]\n",
    "    conf_mat /= conf_mat.max()\n",
    "    print(conf_mat_totals[hpar_item])\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29036913",
   "metadata": {},
   "source": [
    "### 50 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866199b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T19:07:44.532395Z",
     "start_time": "2023-10-05T19:07:39.477392Z"
    }
   },
   "outputs": [],
   "source": [
    "nclasses = '50'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "print(conf_mats.keys())\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761cad3b",
   "metadata": {},
   "source": [
    "### 51 Gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0d2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:32:37.897027Z",
     "start_time": "2023-10-06T13:32:37.869528Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df['model_dir'].values[['hffnn_2023-10-06T10:41:04.697895' in d for d in  df['model_dir'].values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4416792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:38:15.841377Z",
     "start_time": "2023-10-06T13:37:56.482102Z"
    }
   },
   "outputs": [],
   "source": [
    "nclasses = '51'\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == nclasses)\n",
    "]\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'model_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    try:\n",
    "        y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    except FileNotFoundError:\n",
    "        y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    f1_score = sklearn.metrics.f1_score(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] += f1_score\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "        conf_mat_totals[hpar_item] = f1_score\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ', flush=True)\n",
    "        \n",
    "fig, axs = plt.subplots(\n",
    "    2, 3,\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat.max()\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item} Confusion Matrices\\n(weighted mean, {nclasses} classes)'\n",
    "    )\n",
    "axs[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_mean_conf_mat_{nclasses}_classes.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ff9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:25:38.674701Z",
     "start_time": "2023-10-06T09:25:38.496434Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = get_npz_data_from_model('../saved_models/hffnn_2023-10-06T11:22:58.625057')\n",
    "\n",
    "cm = tf.math.confusion_matrix(\n",
    "    y_true.flatten(), \n",
    "    y_pred.flatten()\n",
    ").numpy()\n",
    "f1_score = sklearn.metrics.f1_score(\n",
    "    y_true.flatten(), \n",
    "    y_pred.flatten(),\n",
    "    average='macro',\n",
    "    zero_division=0,\n",
    ")\n",
    "cm[-1, -1] = 0\n",
    "print(f1_score)\n",
    "vis.conf_mat(cm, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d18c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:38:50.161871Z",
     "start_time": "2023-10-06T13:38:16.190092Z"
    }
   },
   "outputs": [],
   "source": [
    "# nclasses = '51'\n",
    "model_type = 'FFNN'\n",
    "for model_type in ('FFNN', 'SVM', 'HFFNN', 'CuSUM', 'HMM'):\n",
    "    data = df[\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    conf_mats = {}\n",
    "    conf_mat_totals = {}\n",
    "\n",
    "    hpar = 'preprocessing.num_gesture_classes'\n",
    "\n",
    "    assert len(data[hpar].unique()) < 10\n",
    "    print(model_type, flush=True)\n",
    "\n",
    "    for i, row in data.sort_values(hpar).iterrows():\n",
    "        try:\n",
    "            y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "        except FileNotFoundError:\n",
    "            y_true, y_pred = get_npz_data_from_model('./' + row['model_dir'])\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten()\n",
    "        ).numpy()\n",
    "        f1_score = sklearn.metrics.f1_score(\n",
    "            y_true.flatten(), \n",
    "            y_pred.flatten(),\n",
    "            average='macro',\n",
    "            zero_division=0,\n",
    "        )\n",
    "        hpar_item = row[hpar]\n",
    "\n",
    "        if hpar_item in conf_mats:\n",
    "            conf_mats[hpar_item] += cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] += f1_score\n",
    "        else:\n",
    "            conf_mats[hpar_item] = cm.astype(float) * f1_score\n",
    "            conf_mat_totals[hpar_item] = f1_score\n",
    "        if i % 100 == 0:\n",
    "            print(i, end=' ', flush=True)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, len(conf_mats.keys()),\n",
    "        figsize=(4*len(conf_mats.keys()), 4),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "        if conf_mat.shape[0] == 51:\n",
    "            conf_mat[-1, -1] = 0\n",
    "        conf_mat /= conf_mat.max()\n",
    "        vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "        axs[i].set_title(\n",
    "            f'{model_type} {hpar_item}-class Confusion Matrices\\n(weighted mean)'\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_mean_conf_mat_{model_type.lower()}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1fc7b",
   "metadata": {},
   "source": [
    "## Regularization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a3e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:27.428981Z",
     "start_time": "2023-10-05T18:11:27.021632Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gesture_classes = (\n",
    "    '5',\n",
    "    '50',\n",
    "    '51',\n",
    ")\n",
    "fig, axs = plt.subplots(len(n_gesture_classes), 2, figsize=(6, len(n_gesture_classes)*3))\n",
    "\n",
    "for i, ngestures in enumerate(n_gesture_classes):\n",
    "    data = df[df['preprocessing.num_gesture_classes'] == ngestures]\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.l2_coefficient',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 0]\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 1]\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{ngestures} gestures')\n",
    "    axs[i, 1].set_title(f'{ngestures} gestures')\n",
    "\n",
    "plt.suptitle(\"$F_1$-ratio against regularisation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3fa2",
   "metadata": {},
   "source": [
    "## Ratio $F_1$ scores vs actual $F_1$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:38:51.502115Z",
     "start_time": "2023-10-06T13:38:50.462878Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "axs[0, 0].set_xlim((-0.05, 1.05))\n",
    "axs[0, 0].set_ylim((-0.05, 1.05))\n",
    "axs[0, 0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 0].set_title(\"a) Training vs Validation $F_1$ score\\n\")\n",
    "axs[0, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 0].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 0].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "axs[0, 1].set_xlim((0.5, 1.05))\n",
    "axs[0, 1].set_ylim((0.5, 1.05))\n",
    "axs[0, 1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 1].set_title(\"b) Training vs Validation $F_1$ score\\n(magnified)\")\n",
    "axs[0, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 1].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 1].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "axs[1, 0].set_xlim((-0.05, 1.05))\n",
    "axs[1, 0].set_title(\"c) $F_1$-ratio vs $F_1$-score\\n\")\n",
    "axs[1, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 0].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 0].legend().set_title('Model Type')\n",
    "axs[1, 0].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['val.macro avg.f1-score'] >= 0.5)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "axs[1, 1].set_xlim((0.5, 1.05))\n",
    "axs[1, 1].set_title(\"d) $F_1$-ratio vs $F_1$-score\\n(magnified)\")\n",
    "axs[1, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 1].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 1].legend().set_title('Model Type')\n",
    "axs[1, 1].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_f1_vs_f1_ratio.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f159f",
   "metadata": {},
   "source": [
    "## Training/validation loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341149b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:30.034843Z",
     "start_time": "2023-10-05T18:11:29.736251Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss',\n",
    "    x='trn.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].assign(**{\n",
    "        'ratio.loss': lambda x: x['trn.loss'] / x['val.loss']\n",
    "    }),\n",
    "    x='ratio.loss',\n",
    "    y='val.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "\n",
    "axs[0].set_ylim((-0.05, 3.6))\n",
    "axs[1].set_ylim((-0.05, 3.6))\n",
    "\n",
    "axs[1].plot([1, 1], [0, axs[1].get_ylim()[1]], color='black', alpha=.1)\n",
    "\n",
    "min_max = min(axs[0].get_xlim()[1], axs[0].get_ylim()[1] )\n",
    "axs[0].plot([0, min_max], [0, min_max], color='black', alpha=.1)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation loss vs training loss\\n(FFNN only)',\n",
    "    xlabel='Training Loss',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Validation loss vs loss ratio\\n(FFNN only)',\n",
    "    xlabel=r'Loss ratio ($\\frac{Training}{Validation}$)',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_val_trn_loss_ratios.pdf'\n",
    ")\n",
    "\n",
    "print(\"TODO: The training and validation loss aren't comparable because the training loss is weighed but validation loss is not.\")\n",
    "print(\"TODO: also not comparable because of dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4df90",
   "metadata": {},
   "source": [
    "## Precision vs Recall plots for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53b515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:53:37.306963Z",
     "start_time": "2023-10-06T13:53:35.258842Z"
    }
   },
   "outputs": [],
   "source": [
    "for model_type, color in model_colours.items():\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "    print(f\"{p_min=}, {p_max=}, {r_min=}, {r_max=}, \")\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    print(f1_score.min())\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            10\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    ax.set(\n",
    "        title=f\"Precision vs Recall For {model_type} models\\n($F_1$ contours in grey)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_{model_type.lower()}_p_vs_r.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279aeea",
   "metadata": {},
   "source": [
    "## In depth FFNN plots\n",
    "\n",
    "- Clusters in the recall of different models\n",
    "- Hyperparameters vs f1 score/recall/precision\n",
    "- No correlation with the inference time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b69d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T11:00:18.385148Z",
     "start_time": "2023-10-06T11:00:08.367018Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = (\n",
    "    'f1-score',\n",
    "    'precision',\n",
    "    'recall',\n",
    ")\n",
    "\n",
    "metric_labels = (\n",
    "    '$F_1$',\n",
    "    'Precision',\n",
    "    'Recall',\n",
    ")\n",
    "\n",
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "df[[\n",
    "#     'ffnn.dropout_rate.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "]] = np.log10(df[[\n",
    "#     'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]])\n",
    "xlabels = (\n",
    "    'Dropout Rate',\n",
    "    'L2 Coefficient ($\\log_{10}$)',\n",
    "    'Batch Size ($\\log_{10}$)',\n",
    "    'Learning Rate ($\\log_{10}$)',\n",
    "    'Nodes in Layer 1',\n",
    "    'Nodes in Layer 2',\n",
    "    'Nodes in Layer 3',\n",
    ")\n",
    "\n",
    "max_log10_val_loss = -0.25\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') \n",
    "    & (df['model_type'] == 'FFNN')\n",
    "    & (df['val.loss.log10'] <= max_log10_val_loss)\n",
    "]\n",
    "\n",
    "\n",
    "for metric, metric_label in zip(metrics, metric_labels):\n",
    "    fig, axs = plt.subplots(\n",
    "        4, 2,\n",
    "        figsize=(12, 24),\n",
    "        dpi=100,\n",
    "    )\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y=f'val.macro avg.{metric}',\n",
    "            hue='val.loss.log10',\n",
    "            palette=palette,\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'{metric_label} vs {title_xlabel}\\n'\n",
    "                  f'$\\log_{{10}}($ Validation loss $) < {max_log10_val_loss}$',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel=metric_label,\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "        ax.legend().set_title('Validation Loss\\n($\\log_{10}$)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_ffnn_hpars_vs_{metric}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9bd06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T11:00:49.547541Z",
     "start_time": "2023-10-06T11:00:47.702719Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for hpar, ax in zip(hyperpars, axs.flatten()):\n",
    "    sns.scatterplot(\n",
    "        data=df[\n",
    "            (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "            (df['model_type'] == 'FFNN')\n",
    "        ],\n",
    "        x=hpar,\n",
    "        y='val.loss.log10',\n",
    "        hue='trn.loss.log10',\n",
    "        ax=ax,\n",
    "        palette='Spectral',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.legend().set_title('Training Loss\\n($\\log_{10}$)')\n",
    "# plt.show()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss.log10',\n",
    "    x='trn.loss.log10',\n",
    "    ax=axs[-1, -1],\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f0a91",
   "metadata": {},
   "source": [
    "## In depth HFFNN plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828e718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:54:32.987887Z",
     "start_time": "2023-10-06T13:54:32.960206Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f95aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:55:41.665107Z",
     "start_time": "2023-10-06T13:55:39.775072Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error \n",
    "# This cell isn't used\n",
    "\n",
    "maj_min = (\n",
    "    'majority',\n",
    "    'minority',\n",
    ")\n",
    "for submodel in maj_min:\n",
    "    hyperpars = (\n",
    "        f'hffnn.{submodel}.ffnn.dropout_rate',\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.1',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.2',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.3',\n",
    "    )\n",
    "    df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "    ]] = np.log10(df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient',\n",
    "        f'hffnn.{submodel}.nn.batch_size',\n",
    "        f'hffnn.{submodel}.nn.learning_rate',\n",
    "    ]])\n",
    "    xlabels = (\n",
    "        f'{submodel.title()} Dropout Rate',\n",
    "        f'{submodel.title()} L2 Coefficient ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Batch Size ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Learning Rate ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Nodes in Layer 1',\n",
    "        f'{submodel.title()} Nodes in Layer 2',\n",
    "        f'{submodel.title()} Nodes in Layer 3',\n",
    "    )\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'HFFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        4, 2,\n",
    "        figsize=(6, 12)\n",
    "    )\n",
    "    print(axs.shape)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y='val.macro avg.f1-score',\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "            color='tab:orange',\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'$F_1$ score vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel='$F_1$ score',\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hffnn_{submodel}_hpars.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ae9d7",
   "metadata": {},
   "source": [
    "## In depth CuSUM plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ccf8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:25.026215Z",
     "start_time": "2023-10-06T09:39:24.336270Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'CuSUM')\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10,\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='cusum.thresh',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x='cusum.thresh',\n",
    "    y='val.macro avg.f1-score',\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    "    ax=axs[1],\n",
    "    jitter=0.5,\n",
    "    color=model_colours['CuSUM'],\n",
    "    native_scale=True,\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "axs[0].set(\n",
    "    title=f\"a) Precision vs Recall for CuSUM models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "axs[0].legend().set_title('Threshold')\n",
    "\n",
    "axs[1].set(\n",
    "    title='b) CuSUM Threshold vs $F_1$ score',\n",
    "    xlabel='CuSUM Threshold',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_cusum_p_vs_r_thresh.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5fa9c5",
   "metadata": {},
   "source": [
    "## In depth SVM plots\n",
    "\n",
    "- Correlation with the training time per observation\n",
    "- Correlation with the precision/recall/f1\n",
    "- clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260d8cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:26.097962Z",
     "start_time": "2023-10-06T09:39:25.333493Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='$\\log_{10}(C)$',\n",
    "    style='Class Weight',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='$\\log_{10}(C)$',\n",
    "    y='val.macro avg.f1-score',\n",
    "    style='Class Weight',\n",
    "    alpha=0.75,\n",
    "    s=20,\n",
    "    ax=axs[1],\n",
    "    color='tab:purple',\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title=f\"Precision vs Recall for SVMs\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    ")\n",
    "axs[1].set(\n",
    "    title=f\"SVM Regularization parameter vs $F_1$ score\",\n",
    "    xlabel='SVM Regularization parameter C ($\\log_{10}$)',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_svm_p_vs_r_class_weight_C.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def2128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:28.747223Z",
     "start_time": "2023-10-06T09:39:26.386520Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'svm.class_weight'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(conf_mats), \n",
    "    figsize=(4*len(conf_mats), 4)\n",
    ")\n",
    "\n",
    "\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat_totals[hpar_item]\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} SVMs\\n(Mean of {int(conf_mat_totals[hpar_item])} Confusion Matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_svm_conf_mats_unbalanced.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f047a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:29.382876Z",
     "start_time": "2023-10-06T09:39:29.045182Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "    s=10,\n",
    "    alpha=0.75,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='SVM hyperparameters against fit time',\n",
    "    ylabel='Fit time (seconds per observation)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_svm_hpars_vs_fit_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996824e7",
   "metadata": {},
   "source": [
    "## In depth HMM plots\n",
    "\n",
    "- Clusters in recall-precision space\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec85d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:29.944459Z",
     "start_time": "2023-10-06T09:39:29.723394Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_type = 'HMM'\n",
    "color='tab:red'\n",
    "    \n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == model_type)\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='hmm.covariance_type',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=ax,\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "ax.set(\n",
    "    title=f\"Precision vs Recall for {model_type} models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "ax.legend().set_title('Covariance Type')\n",
    "\n",
    "# plt.savefig(\n",
    "#     f'../../report/src/imgs/graphs/05_in_depth_hmm_p_vs_r_covar_type.pdf',\n",
    "#     bbox_inches='tight',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b20e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:31.205599Z",
     "start_time": "2023-10-06T09:39:30.269780Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title('Covariance Type')\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference time on the Training and Validation sets\\n',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference time on the Training and Validation sets\\n($< 0.02$s)',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='c) Inference and Fitting times\\n',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 1].set(\n",
    "    title='d) Inference and Fitting times\\n($< 0.02$s)',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_inf_trn_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70167aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:35.650276Z",
     "start_time": "2023-10-06T09:39:31.832547Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "f1_scores = {}\n",
    "y_preds_dict = {}\n",
    "y_true_dict = {}\n",
    "reports_dict = {}\n",
    "\n",
    "hpar = 'hmm.covariance_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    precision, recall, f1_score, _support = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten(),\n",
    "#         average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "        precisions[hpar_item] += precision\n",
    "        recalls[hpar_item] += recall\n",
    "        f1_scores[hpar_item] += f1_score\n",
    "        y_preds_dict[hpar_item] = np.concatenate((y_preds_dict[hpar_item], y_pred.flatten()))\n",
    "        y_true_dict[hpar_item] = np.concatenate((y_true_dict[hpar_item], y_true.flatten()))\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "        precisions[hpar_item] = precision\n",
    "        recalls[hpar_item] = recall\n",
    "        f1_scores[hpar_item] = f1_score\n",
    "        y_preds_dict[hpar_item] = np.copy(y_pred.flatten())\n",
    "        y_true_dict[hpar_item] = np.copy(y_true.flatten())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 8),\n",
    "    squeeze=False,\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.conf_mat(conf_mat / conf_mat.max(), ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} HMMs\\n'\n",
    "        f'(Mean of {int(conf_mat_totals[hpar_item])} confusion matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_conf_mats_cov_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2,\n",
    "    figsize=(8, 2),\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    vis.precision_recall_f1(\n",
    "        precision=precisions[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        recall=recalls[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        f1=f1_scores[hpar_item] / conf_mat_totals[hpar_item],\n",
    "        ax=axs[i],\n",
    "    )\n",
    "    axs[i].set_title(hpar_item)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_prf1_plots_conv_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127c75f",
   "metadata": {},
   "source": [
    "## FFNN Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763743c",
   "metadata": {},
   "source": [
    "### Heatmap-based pairplot of FFNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cf8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T09:39:37.874849Z",
     "start_time": "2023-10-06T09:39:35.949349Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') &\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "]\n",
    "\n",
    "hpars_scale = [\n",
    "    ('nn.learning_rate',       'log10'),\n",
    "    ('ffnn.nodes_per_layer.1', 'log10'),\n",
    "    ('ffnn.l2_coefficient',    'log10'),\n",
    "    ('ffnn.dropout_rate',      'linear'),\n",
    "]\n",
    "# x_var_idx = 0\n",
    "# y_var_idx = 1\n",
    "def contour_nicely(x, y, z, xlabel, ylabel, xscale, yscale, fig, ax, levels=8):\n",
    "\n",
    "    ax.tricontour(x, y, z, levels=levels, linewidths=0.25, colors='k')\n",
    "    cntr2 = ax.tricontourf(x, y, z, levels=levels, cmap=palette)\n",
    "\n",
    "    fig.colorbar(cntr2, ax=ax)\n",
    "    ax.scatter(x, y, color='white', s=1)\n",
    "\n",
    "    ax.set_xlabel(f'{xlabel} ({xscale})')\n",
    "    if xscale == 'log10':\n",
    "        ax.set_xticks(ax.get_xticks())\n",
    "        ax.set_xticklabels([f'{np.power(10, t):.3g}' for t in ax.get_xticks()])\n",
    "\n",
    "    ax.set_ylabel(f'{ylabel} ({yscale})')\n",
    "    if yscale == 'log10':\n",
    "        ax.set_yticks(ax.get_yticks())\n",
    "        ax.set_yticklabels([f'{np.power(10, t):.3g}' for t in ax.get_yticks()])\n",
    "\n",
    "    ax.set_title(f'{xlabel} vs {ylabel}')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(\n",
    "    len(hpars_scale), \n",
    "    len(hpars_scale), \n",
    "    dpi=200, \n",
    "    squeeze=False,\n",
    "    figsize=(20,20)\n",
    ")\n",
    "z = data['val.macro avg.f1-score'].values\n",
    "for x_var_idx in range(len(hpars_scale)):\n",
    "    for y_var_idx in range(x_var_idx+1, len(hpars_scale)):\n",
    "    \n",
    "        x = data[hpars_scale[x_var_idx][0]].values\n",
    "        if hpars_scale[x_var_idx][1] == 'log10':\n",
    "            x = np.log10(x)\n",
    "        elif hpars_scale[x_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[x_var_idx][0]} is not implemented\")\n",
    "        y = data[hpars_scale[y_var_idx][0]].values\n",
    "        if hpars_scale[y_var_idx][1] == 'log10':\n",
    "            y = np.log10(y)\n",
    "        elif hpars_scale[y_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[y_var_idx][0]} is not implemented\")\n",
    "            \n",
    "        contour_nicely(\n",
    "            y, x, z,\n",
    "            hpars_scale[y_var_idx][0],\n",
    "            hpars_scale[x_var_idx][0],\n",
    "            hpars_scale[y_var_idx][1],\n",
    "            hpars_scale[x_var_idx][1],\n",
    "            fig, axs[x_var_idx, y_var_idx]\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d59541",
   "metadata": {},
   "source": [
    "## Plot inference/training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e10eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:56:57.837629Z",
     "start_time": "2023-10-06T13:56:57.385281Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'fit_time_per_obs': lambda x: x['fit_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='fit_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'trn.pred_time_per_obs': lambda x: x['trn.pred_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'val.pred_time_per_obs': lambda x: x['val.pred_time'] / x['val.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='val.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    alpha=0.5,\n",
    "    s=3,\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25942adc",
   "metadata": {},
   "source": [
    "## Inference times vs num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054f297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:14:33.405697Z",
     "start_time": "2023-10-06T14:14:32.912143Z"
    }
   },
   "outputs": [],
   "source": [
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['val.pred_time_per_obs.log10'] = np.log10(df['val.pred_time_per_obs'].fillna(0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "model_types = [m for m in model_colours.keys() if m != 'HFFNN']\n",
    "for ax, model_type in zip(axs, model_types):\n",
    "    sns.stripplot(\n",
    "        data=df[\n",
    "            df['model_type'] == model_type\n",
    "        ].sort_values('preprocessing.num_gesture_classes'),\n",
    "        x='preprocessing.num_gesture_classes',\n",
    "        y='val.pred_time_per_obs',\n",
    "        hue='model_type',\n",
    "#         dodge=True,\n",
    "        s=2,\n",
    "        legend=False,\n",
    "        hue_order=list(model_colours.keys()),\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(model_type)\n",
    "\n",
    "# sns.stripplot(\n",
    "#     data=df[\n",
    "#         df['val.pred_time_per_obs'] < 0.02\n",
    "#     ].sort_values('preprocessing.num_gesture_classes'),\n",
    "#     hue='preprocessing.num_gesture_classes',\n",
    "#     x='model_type',\n",
    "#     y='val.pred_time_per_obs',\n",
    "#     dodge=True,\n",
    "#     s=2,\n",
    "# #     hue_order=list(model_colours.keys()),\n",
    "#     alpha=0.5,\n",
    "#     ax=axs[1]\n",
    "# )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181109be",
   "metadata": {},
   "source": [
    "## Example Confusion Matrices from baseline models\n",
    "\n",
    "TODO: Also include models with perfect precision / perfect recall / perfect precision for non-g255 gestures / perfect precision for g255 / perfect recall for non-g255 gestures / perfect recall for g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640592fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:34:50.332663Z",
     "start_time": "2023-10-05T18:34:49.537720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d36d37",
   "metadata": {},
   "source": [
    "### Plot a model that only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81fc63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:34:51.190732Z",
     "start_time": "2023-10-05T18:34:51.141353Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A function for plotting precision-recall + confusion matrices\n",
    "def plt_pr_conf_mat(y_true, y_preds):\n",
    "    \"\"\"Given true and predicted labels, \n",
    "    create a confusion matrix and a precision-recall plot.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "    if len(y_preds.shape) == 1:\n",
    "        y_preds = np.array([y_preds])\n",
    "    # Confusion matrix\n",
    "    # Get the median confusion matrix\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    cm_sum = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for y_pred in y_preds:\n",
    "        cm_sum += tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "    cm = cm_sum / len(y_preds)\n",
    "    vis.conf_mat(cm, ax=axs[1])\n",
    "    \n",
    "    f1_sum = 0\n",
    "    for y_pred in y_preds:\n",
    "        f1_sum += sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_sum / len(y_preds)\n",
    "\n",
    "    # Precision-recall plot\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(0, 1, 100), \n",
    "        np.linspace(0, 1, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    ps = []\n",
    "    rs = []\n",
    "    for y_pred in y_preds:\n",
    "        ps.append(sklearn.metrics.precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "        rs.append(sklearn.metrics.recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    p = np.mean(ps)\n",
    "    r = np.mean(rs)\n",
    "\n",
    "    axs[0].scatter(\n",
    "        ps, rs,\n",
    "        color='black',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    axs[0].set_xlabel('Precision')\n",
    "    axs[0].set_ylabel('Recall')\n",
    "    axs[0].set_xlim((-0.01, 1.01))\n",
    "    axs[0].set_ylim((-0.01, 1.01))\n",
    "    axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "#     axs[0].set_title(f'Precision-Recall Graph\\n(contours indicate the $F_1$-score)')\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff657758",
   "metadata": {},
   "source": [
    "#### Only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da06a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:35:38.801378Z",
     "start_time": "2023-10-05T18:35:33.770855Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Only predicts 50\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_only_50.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa4bba",
   "metadata": {},
   "source": [
    "#### Completely random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:35:47.567104Z",
     "start_time": "2023-10-05T18:35:42.528802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts randomly\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_random_preds.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894af3ed",
   "metadata": {},
   "source": [
    "#### Wrong orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da562bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:35:51.122938Z",
     "start_time": "2023-10-05T18:35:47.814316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong orientation\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn_repeated + 10*np.random.randint(\n",
    "        -(y_trn_repeated // 10), \n",
    "        +(5 - y_trn_repeated // 10), \n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_orientation.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78100f19",
   "metadata": {},
   "source": [
    "#### Wrong finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdaab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:35:54.672478Z",
     "start_time": "2023-10-05T18:35:51.368739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong finger\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 10), \n",
    "        +(10 - np.mod(y_trn_repeated, 10)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba12ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:35:58.241618Z",
     "start_time": "2023-10-05T18:35:54.919678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong finger (but correct hand)\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 5), \n",
    "        +(5 - np.mod(y_trn_repeated, 5)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger_correct_hand.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072cb6",
   "metadata": {},
   "source": [
    "#### Predict 50 as a random gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35c745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:36:03.545313Z",
     "start_time": "2023-10-05T18:35:58.481292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_no_gesture_50.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32086956",
   "metadata": {},
   "source": [
    "#### High recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74628a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:36:10.175864Z",
     "start_time": "2023-10-05T18:36:03.784790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 51, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_recall.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801984",
   "metadata": {},
   "source": [
    "#### High precision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88419278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:36:11.001597Z",
     "start_time": "2023-10-05T18:36:10.429070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 5, axis=0)\n",
    "y_preds = np.where(\n",
    "    y_trn_repeated == 50,\n",
    "    y_trn_repeated,\n",
    "    50,\n",
    ")\n",
    "\n",
    "# np.clip(np.random.randint(-1, 1, size=y_trn_repeated.shape) + y_trn_repeated, 0, 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_precision.pdf', bbox_inches='tight')\n",
    "\n",
    "# f1_scores = []\n",
    "# for y_pred in y_preds:\n",
    "#     f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "# f1_scores = np.array(f1_scores)\n",
    "# print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f508a",
   "metadata": {},
   "source": [
    "### Finally, plot all confusion matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fdc45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:36:23.210107Z",
     "start_time": "2023-10-05T18:36:21.498118Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Random model:\n",
    "y_pred = np.random.randint(0, 51, y_trn.shape)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[0])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[0].set_title(f\"Random model\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Only predicts 50\n",
    "y_pred = np.full(y_trn.shape, 50)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[1])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[1].set_title(f\"Only predicts 50\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random orientation:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn + 10*np.random.randint(\n",
    "        -(y_trn // 10), \n",
    "        +(5 - y_trn // 10), \n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[2])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[2].set_title(f\"Perfect,\\nbut random orientation\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 10), \n",
    "        +(10 - np.mod(y_trn, 10)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[3])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[3].set_title(f\"Perfect,\\nbut random finger\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger (same hand):\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 5), \n",
    "        +(5 - np.mod(y_trn, 5)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[4])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[4].set_title(f\"Perfect,\\nbut random finger on the correct hand\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Never predicts 50\n",
    "y_pred = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn.shape), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(\n",
    "    y_trn, \n",
    "    y_pred,\n",
    ").numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[5])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[5].set_title(f\"Perfect,\\nbut predicts 50 as a random gesture\\n$F_1$={f1:.4}\")\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_example_conf_mats.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b0430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:14:01.407546Z",
     "start_time": "2023-10-02T08:14:01.371428Z"
    }
   },
   "source": [
    "## PCA Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fa9de",
   "metadata": {},
   "source": [
    "### PCA decomposition only including the gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f03a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:07:57.283855Z",
     "start_time": "2023-10-02T08:07:56.624369Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:17:34.621469Z",
     "start_time": "2023-10-02T08:17:28.111638Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "\n",
    "argsort = np.argsort(y_trn[y_trn != 50])\n",
    "\n",
    "hues = np.array([ \"0$^\\circ$\", \"45$^\\circ$\", \"90$^\\circ$\", \"135$^\\circ$\", \"180$^\\circ$\" ])\n",
    "styles = np.array([ \"L5\", \"L4\", \"L3\", \"L2\", \"L1\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\" ])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 16), dpi=300)\n",
    "sns.scatterplot(\n",
    "    x=X_tfrm[:, 0][argsort],\n",
    "    y=X_tfrm[:, 1][argsort],\n",
    "    hue=hues[(y_trn[y_trn != 50][argsort] // 10)],\n",
    "    style=styles[(y_trn[y_trn != 50][argsort] % 10)],\n",
    "    s=10,\n",
    "    ax=axs[0]\n",
    ")\n",
    "axs[0].set_title(\"PCA plot of the training data\\nExcluding class 50\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=300)\n",
    "mask = (y_trn == 50)\n",
    "axs[1].scatter(\n",
    "    X_tfrm[:, 0][mask],\n",
    "    X_tfrm[:, 1][mask],\n",
    "    color='black',\n",
    "    alpha=0.1,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "axs[1].scatter(\n",
    "    X_tfrm[:, 0][~mask],\n",
    "    X_tfrm[:, 1][~mask],\n",
    "    color=colours[(y_trn[~mask] // 10)],\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "axs[1].set_title('PCA plot of the training data\\n(class 50 in black)')\n",
    "\n",
    "axs[0].set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    ")\n",
    "axs[1].set(\n",
    "    xlabel='Principal Component 1',\n",
    "    ylabel='Principal Component 2',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_pca_plot.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4231b",
   "metadata": {},
   "source": [
    "### PCA plot showing just an interesting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.831911Z",
     "start_time": "2023-10-02T08:05:56.831906Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec25ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.835445Z",
     "start_time": "2023-10-02T08:05:56.835439Z"
    },
    "code_folding": [
     2,
     8
    ]
   },
   "outputs": [],
   "source": [
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "@interact(\n",
    "    x_start=(-1500, 1500, 50),\n",
    "    y_start=(-1500, 1500, 50),\n",
    "    x_length=(-1500, 1500, 50),\n",
    "    y_length=(-1500, 1500, 50),\n",
    ")\n",
    "def fn(x_start=-150, y_start=1000, x_length=500, y_length=500):\n",
    "    x_finsh = x_start + x_length\n",
    "    y_finsh = y_start + y_length\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "\n",
    "    selection_mask = (\n",
    "        (x_start <= X_tfrm[:, 0]) & (X_tfrm[:, 0] <= x_finsh) &\n",
    "        (y_start <= X_tfrm[:, 1]) & (X_tfrm[:, 1] <= y_finsh)\n",
    "    )\n",
    "    X_subset = X_tfrm[selection_mask]\n",
    "    y_subset = y_trn[selection_mask]\n",
    "#     ax.scatter(\n",
    "#         X_subset[:, 0],\n",
    "#         X_subset[:, 1],\n",
    "#         c='black',\n",
    "#         alpha=0.1,\n",
    "#     )\n",
    "    \n",
    "    y_mask = (y_trn == 50)\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset == 50],\n",
    "        X_subset[:, 1][y_subset == 50],\n",
    "        color='black',\n",
    "        alpha=0.1,\n",
    "        s=20,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset != 50],\n",
    "        X_subset[:, 1][y_subset != 50],\n",
    "        color=colours[(y_subset[y_subset != 50] // 10)],\n",
    "        alpha=0.75,\n",
    "#         s=5,\n",
    "        edgecolor='none',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d3579",
   "metadata": {},
   "source": [
    "### PCA plot that connects sequential datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa9f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.838493Z",
     "start_time": "2023-10-02T08:05:56.838481Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "order = np.argsort(dt_trn)\n",
    "X_tfrm = X_tfrm[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.841832Z",
     "start_time": "2023-10-02T08:05:56.841827Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "limit = 1000\n",
    "@interact(start=(0, len(X_tfrm), 25), length=(0, len(X_tfrm), 50))\n",
    "def fn(start=0, length=500):\n",
    "    finsh = min(start + length, len(X_tfrm))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "    ax.plot(\n",
    "        X_tfrm[:, 0][start:finsh],\n",
    "        X_tfrm[:, 1][start:finsh],\n",
    "        zorder=0,\n",
    "        c='black',\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_tfrm[:, 0][start:finsh],\n",
    "        y=X_tfrm[:, 1][start:finsh],\n",
    "        hue=dt_trn[order][start:finsh],\n",
    "        legend=False,\n",
    "        s=(10 + 90*(y_trn != 50)[order][start:finsh]),\n",
    "        edgecolor=np.where((y_trn != 50)[order][start:finsh], 'black', 'none'),\n",
    "        linewidth=.5,\n",
    "    )\n",
    "    \n",
    "    idxs = np.nonzero(y_trn[order][start:finsh] != 50)[0]\n",
    "    for idx in idxs:\n",
    "        ax.text(\n",
    "            X_tfrm[start:finsh][idx, 0],\n",
    "            X_tfrm[start:finsh][idx, 1],\n",
    "            y_trn[order][start:finsh][idx],\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "#     ax.set_xlim((\n",
    "#         X_tfrm[:, 0].min() / 1.1,\n",
    "#         X_tfrm[:, 0].max() * 1.1,\n",
    "#     ))\n",
    "#     ax.set_ylim((\n",
    "#         X_tfrm[:, 1].min() / 1.1,\n",
    "#         X_tfrm[:, 1].max() * 1.1,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e39f0",
   "metadata": {},
   "source": [
    "### PCA plot of a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6f0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.844633Z",
     "start_time": "2023-10-02T08:05:56.844628Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = (\n",
    "    (,),\n",
    "    (,),\n",
    ")\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5233e5",
   "metadata": {},
   "source": [
    "## Visualise mis-predictions\n",
    "\n",
    "1. Load in a continuous dataset\n",
    "2. Load in a classifier\n",
    "3. Use the classifier to make predictions on the dataset\n",
    "4. Visualise the mispredictions, but *with context*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8970",
   "metadata": {},
   "source": [
    "### Load in a model for which to evaluate the mis-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58bae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:56.847617Z",
     "start_time": "2023-10-02T08:05:56.847613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "clf = models.load_tf('../src/saved_models/ffnn_2023-09-18T14:05:16.363404')\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce0a33",
   "metadata": {},
   "source": [
    "### Visualise True and Mispredicted gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61f5b4",
   "metadata": {},
   "source": [
    "Plot all the observations which have the ground truth being gesture 255 but the model is not predicting g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a359ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.152469Z",
     "start_time": "2023-10-02T08:05:02.152457Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "for gidx in np.unique(y_val):\n",
    "    if gidx == 50: continue\n",
    "    pred_indxs = np.nonzero((y_val == 50) & (y_pred == gidx))[0]\n",
    "    true_indxs = np.nonzero(y_val == gidx)[0]\n",
    "    axs = vis.cmp_ts(\n",
    "        X_val[true_indxs],\n",
    "    )\n",
    "    vis.cmp_ts(\n",
    "        X_val[pred_indxs],\n",
    "        color='tab:red',\n",
    "        axs=axs,\n",
    "    )\n",
    "\n",
    "#     distances = np.abs(true_indxs[:, np.newaxis] - pred_indxs).min(axis=0)\n",
    "\n",
    "    plt.suptitle(f'Model predicted {gidx}, ground truth: 50 \\\n",
    "                 \\nGesture {gidx} in grey, mispredicted in red ({len(pred_indxs)} observations) \\\n",
    "                 \\nindices: {pred_indxs}')\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'../src/notebooks/pred_{gidx:0>2}_truth_50.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     if gidx > 5:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1601b8",
   "metadata": {},
   "source": [
    "# Interactive plot to see data at a certain time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.153164Z",
     "start_time": "2023-10-02T08:05:02.153159Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "#     constants_path='../src/constants.yaml',\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "\n",
    "@interact(dt='2022-10-08T20:23:46.665276000')\n",
    "def fn(dt='2022-10-08T20:23:46.665276000'):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    mask = df['datetime'].between(\n",
    "        dt - pd.to_timedelta(1, 'second'),\n",
    "        dt + pd.to_timedelta(1, 'second')\n",
    "    )\n",
    "    \n",
    "    vis.cmp_ts(\n",
    "        [df.loc[mask, sensor_names].values]\n",
    "    )\n",
    "#     ax.plot(\n",
    "#         df.loc[mask, sensor_names].values\n",
    "#     )\n",
    "#     dt_labels = df.loc[mask, 'datetime']\n",
    "#     gidx_labels = df.loc[mask, 'gidx']\n",
    "#     ax.set_xticks(range(len(dt_labels)))\n",
    "#     ax.set_xticklabels([\n",
    "#         f'{gidx_label} {str(dt_label)[5:-3]}'\n",
    "#         for dt_label, gidx_label\n",
    "#         in zip(dt_labels, gidx_labels)\n",
    "#     ], rotation=90)\n",
    "# 2022-10-08T20:23:46.665276000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed1079",
   "metadata": {},
   "source": [
    "# Plot a CSV file + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c36ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T10:58:04.748150Z",
     "start_time": "2023-10-05T10:58:03.479326Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = '../gesture_data/saved_from_cli_alphabet.csv'\n",
    "model_dir = '../src/saved_models/ffnn_2023-10-04T12:02:09.749144'\n",
    "\n",
    "sensors = list(common.read_constants('./constants.yaml')[\"sensors\"].values())\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    names=[\"datetime\", \"gesture\"] + sensors,\n",
    "    parse_dates=[\"datetime\"],\n",
    "    date_format='ISO8601',\n",
    ")\n",
    "df['file'] = csv_path\n",
    "X, y, dt = common.make_windows(\n",
    "    df,\n",
    "    20,\n",
    "    constants_path='../src/constants.yaml',\n",
    "    pbar=tqdm.tqdm(total=len(df), desc=\"Making windows\"),\n",
    ")\n",
    "clf = models.load_tf(model_dir)\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466f635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T11:00:11.020831Z",
     "start_time": "2023-10-05T11:00:10.539150Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clf=None\n",
    "@interact(start=(0, len(df), 20), duration=(0, len(df), 20))\n",
    "def fn(start=0, duration=4000):\n",
    "    \n",
    "    fig, axs = plt.subplots(3 if clf is not None else 2, 1, figsize=(10, 5))\n",
    "    for i in range(X.shape[-1]):\n",
    "        axs[0].plot(\n",
    "            X[start:start+duration, 0, i],\n",
    "            alpha=0.5,\n",
    "            c=['tab:red', 'tab:green', 'tab:blue'][i%3],\n",
    "            lw=1,\n",
    "        )\n",
    "    sns.heatmap(\n",
    "        X[start:start+duration, 0, :].T,\n",
    "        cmap='jet',\n",
    "        ax=axs[1],\n",
    "        cbar=False,\n",
    "        vmin=290,\n",
    "        vmax=910,\n",
    "    )\n",
    "\n",
    "    if clf is not None:\n",
    "        sns.heatmap(\n",
    "            y_pred_probs[start-10:start+duration-10, :].T,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            ax=axs[2],\n",
    "            cbar=False,\n",
    "        )\n",
    "        axs[2].set(\n",
    "            ylabel='Predicted\\ngesture',\n",
    "        )\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "    \n",
    "    axs[0].set(\n",
    "        ylabel='Sensor value',\n",
    "        xticks=[],\n",
    "        ylim=(250, 950)\n",
    "    )\n",
    "    axs[1].set(\n",
    "        ylabel='Sensor number',\n",
    "        xticks=[],\n",
    "    )\n",
    "    axs[0].margins(0)\n",
    "    with_clf =' and model predictions' if clf is not None else ''\n",
    "    axs[0].set_title(f'Sensor values{with_clf} over time at {np.round(start/40, 2)}s\\n(duration: {np.round(duration/40, 2)} seconds')\n",
    "#     plt.savefig(\n",
    "#         f'sensors_over_time_{start}_{duration}.pdf',\n",
    "#         bbox_inches='tight',\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61445582",
   "metadata": {},
   "source": [
    "# Misc Research Chapter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f431f5",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100164fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.154203Z",
     "start_time": "2023-10-02T08:05:02.154194Z"
    }
   },
   "outputs": [],
   "source": [
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml'\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c88cf",
   "metadata": {},
   "source": [
    "## Correlations between the different gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13163f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T10:01:02.685366Z",
     "start_time": "2023-10-06T10:01:01.502051Z"
    }
   },
   "outputs": [],
   "source": [
    "timestep = 0\n",
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())\n",
    "X_data = X_trn[y_trn != 50][:, timestep, :]\n",
    "y_data = y_trn[y_trn != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b96229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T10:38:12.958744Z",
     "start_time": "2023-10-06T10:37:26.480316Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    5, 10,\n",
    "    figsize=(40, 20),\n",
    "    dpi=200,\n",
    ")\n",
    "for i in range(5):\n",
    "    print(f'gesture {i}_', flush=True)\n",
    "    for j in range(10):\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(X_data[y_data == (i * 10 + j)]).corr(),\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            ax=axs[i, j],\n",
    "            xticklabels=[s.upper() for s in sensor_names],\n",
    "            yticklabels=[s.upper() for s in sensor_names],\n",
    "            square=True,\n",
    "        )\n",
    "        axs[i, j].set_title(f'Gesture {i * 10 + j}')\n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0ee62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T10:35:45.212065Z",
     "start_time": "2023-10-06T10:35:44.423883Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    pd.DataFrame(X_data).corr(),\n",
    "    vmin=-1, \n",
    "    vmax=1,\n",
    "    center=0,\n",
    "#     cbar=False,\n",
    "    xticklabels=[s.upper() for s in sensor_names],\n",
    "    yticklabels=[s.upper() for s in sensor_names],\n",
    "    square=True,\n",
    ")\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Sensor')\n",
    "plt.title('Correlations between sensors\\n(over all training data)')\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_correlations.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce50b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T10:19:30.866240Z",
     "start_time": "2023-10-06T10:19:30.590658Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axis = ['X', 'Y', 'Z']\n",
    "for i in range(3):\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(X_data[:, i::3]).corr(),\n",
    "        vmin=-1, \n",
    "        vmax=1,\n",
    "        center=0,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        ax=axs[i]\n",
    "    )\n",
    "    axs[i].set_title(f'Correlations between {axis[i]}-axis sensors\\n(over all training data)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f86",
   "metadata": {},
   "source": [
    "## Time-series heatmap + line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf9df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.154898Z",
     "start_time": "2023-10-02T08:05:02.154892Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plt_subset(s, f):\n",
    "    df = read.read_data(\n",
    "        '../gesture_data/train/', \n",
    "        constants_path='../src/constants.yaml'\n",
    "    )\n",
    "    df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "    const = common.read_constants('../src/constants.yaml')\n",
    "    sensor_names = list(const['sensors'].values())\n",
    "    data = df[sensor_names].values[s:f]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        data.T,\n",
    "        ax=axs[0],\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    axs[1].plot(\n",
    "        data,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    plt.margins(0)\n",
    "    plt.show()\n",
    "# plt_subset(91_000, 95_000)\n",
    "plt_subset(93_000, 93_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46355c0e",
   "metadata": {},
   "source": [
    "## Histogram of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b45e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.155728Z",
     "start_time": "2023-10-02T08:05:02.155723Z"
    }
   },
   "outputs": [],
   "source": [
    "df['gidx'].hist()\n",
    "plt.show()\n",
    "df.loc[df['gidx'] != 50, 'gidx'].hist()\n",
    "df['gidx'].value_counts() / len(df['gidx']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da38f",
   "metadata": {},
   "source": [
    "## All observations of one gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de297a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.156281Z",
     "start_time": "2023-10-02T08:05:02.156276Z"
    }
   },
   "outputs": [],
   "source": [
    "gidx = 0\n",
    "before = 10\n",
    "after = 10\n",
    "idxs = np.nonzero(df['gidx'] == gidx)[0][:, np.newaxis] + np.arange(-before, after+1)\n",
    "\n",
    "vis.cmp_ts(df[sensor_names].values[idxs + 10]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20810d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.157056Z",
     "start_time": "2023-10-02T08:05:02.157048Z"
    }
   },
   "outputs": [],
   "source": [
    "np.arange(-before, after+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01077c33",
   "metadata": {},
   "source": [
    "## 3D plot of the raw acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c84cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T08:05:02.157667Z",
     "start_time": "2023-10-02T08:05:02.157662Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vals = df[['l5x', 'l5y', 'l5z']].values[:10000]\n",
    "ax.plot(\n",
    "    vals[:, 0], \n",
    "    vals[:, 1], \n",
    "    vals[:, 2], \n",
    "    label='3D Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97194d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6face1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo-venv",
   "language": "python",
   "name": "ergo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
