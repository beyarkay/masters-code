{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69b0d03",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff0b1d",
   "metadata": {},
   "source": [
    "## Notes and Quick ideas\n",
    "\n",
    "- Now do plots with the repetitions baked in. Show which hyperparameter combinations have the least variance\n",
    "\n",
    "- Figure out what went wrong in the labelling\n",
    "    - Potentially relabel validation/training/testing(!)\n",
    "- Redo difference graph after the relabelling\n",
    "- Give a description of the dataset, what's in it\n",
    "- Load dataset onto zenodo\n",
    "- Create a bridge from background chapter to how the models are used\n",
    "\n",
    "### Meeting notes\n",
    "- [x] Check (before writing results chapter) that the delay isn't too big\n",
    "- [x] Make *very* sure that the model can be run in real time, with the gloves\n",
    "- [x] Conf matrix should be %age of the class\n",
    "- [x] Explain Conf matrix structure (diagonals/orientations/fingers) in thesis\n",
    "- [x] Include 'dummy' models which perfectly predict only finger/orientation/hand, etc\n",
    "     - put it in a separate section in methodology\n",
    "- [x] Look into plotting error on FFNN\n",
    "- Discuss precision/recall for 51 gesture FFNN/HMM/CuSUM  -> Why would this happen\n",
    "- Error types: (wrong timestep) x (wrong gesture)\n",
    "    - It seems like the FFNN is not getting the timestep wrong, it's just wrong\n",
    "- Explore plots of hpars affecting regularization and validation performance\n",
    "- Make note that the HMM is only predicting 200 g255 gestures\n",
    "\n",
    "### Changes made\n",
    "\n",
    "- F1 score was being set to NaN, resulting in the average being too high (and F1 ~= 1.0)\n",
    "- Grid search was unable to explore the search space fully, so [Optuna](https://optuna.readthedocs.io/en/stable/) was used for the search.\n",
    "    - Specifically, the [Tree-structured Parzen Estimator](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler) performs the search. Bergstra, James et al. “Algorithms for Hyper-Parameter Optimization.” NIPS (2011). [Explanatory Blog](http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#tree-structured-parzen-estimators-tpe)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139088",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a2aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:32:54.919570Z",
     "start_time": "2023-10-01T18:32:54.880460Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change directory to keep paths consistent\n",
    "%cd /Users/brk/projects/masters/SU/ergo/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22165a6e",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d078368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:32:56.408202Z",
     "start_time": "2023-10-01T18:32:56.366928Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import models\n",
    "import vis\n",
    "import common\n",
    "import read\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import tqdm\n",
    "import logging as l\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f\n",
    "\n",
    "mpl.rc('font', family='serif', serif='cmr10')\n",
    "mpl.rc('axes.formatter', use_mathtext=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbd3fa",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:32:56.780772Z",
     "start_time": "2023-10-01T18:32:56.738828Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# minimise me\n",
    "def prettify_col_name(x):\n",
    "    return x.split('.')[-1].replace('_', ' ').title()\n",
    "\n",
    "def calculate_prediction_ellipse(x, y, alpha=0.5):\n",
    "    \"\"\"Given some x and y data, calculate the (1-alpha) confidence ellipse.\"\"\"\n",
    "    data = np.column_stack((x, y)) # Combine x and y into a single data array\n",
    "    num_dimensions = data.shape[1]\n",
    "    num_data_points = data.shape[0]\n",
    "    # Estimate the sample covariance matrix\n",
    "    sample_covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Calculate the sample mean for each dimension\n",
    "    sample_mean = np.mean(data, axis=0)\n",
    "    # Generate angles for the ellipse\n",
    "    theta = np.linspace(0, 2*np.pi, num=100)\n",
    "    # Calculate the radius of the ellipse. `f.ppf` is the inverse of the CDF\n",
    "    radius = np.sqrt(\n",
    "        num_dimensions * (num_data_points - 1) / (num_data_points - num_dimensions) *\n",
    "        (1 + 1/num_data_points) * f.ppf(1 - alpha, num_dimensions, num_data_points - num_dimensions)\n",
    "    )\n",
    "#     print(sample_covariance_matrix)\n",
    "    # Compute the Cholesky decomposition of the covariance matrix\n",
    "    chol_cov_matrix = np.linalg.cholesky(sample_covariance_matrix)\n",
    "    # Generate ellipse offset based on Cholesky decomposition\n",
    "    ellipse_offset = np.outer(np.cos(theta), chol_cov_matrix[0, :]) + np.outer(np.sin(theta), chol_cov_matrix[1, :])\n",
    "    # Calculate the points of the prediction interval ellipse\n",
    "    prediction_ellipse_points = sample_mean + radius * ellipse_offset\n",
    "    return prediction_ellipse_points\n",
    "\n",
    "def get_npz_data_from_model(model_dir):\n",
    "    \"\"\"Given a directory of a model, return it's y_pred and y_true.\"\"\"\n",
    "    data = np.load(f'{model_dir}/y_val_true_y_val_pred.npz')\n",
    "    y_true = data['y_true']\n",
    "    y_pred = data['y_pred']\n",
    "    return y_true, y_pred\n",
    "\n",
    "def show_conf_mat_from_model(model_dir, ax=None):\n",
    "    \"\"\"Given a directory of a model, plot its confidence matrix\"\"\"\n",
    "    y_true, y_pred = get_npz_data_from_model(model_dir)\n",
    "    cm_val = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    p = vis.conf_mat(cm_val / cm_val.sum(axis=0), ax=ax)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa46788",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:32:58.464057Z",
     "start_time": "2023-10-01T18:32:57.716416Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in data from hpar optimisation\n",
    "paths = sorted(glob.glob('../saved_models/results_*_optuna.jsonl'))\n",
    "print(f'Reading data from\\n', \"\\n\".join(paths))\n",
    "dfs = map(\n",
    "    lambda path: pd.read_json(path, lines=True),\n",
    "    paths\n",
    ")\n",
    "# Concat the dataframes together, and then do a \n",
    "# copy to avoid a dataframe fragmentation warning\n",
    "# Reset the index to avoid a seaborn error https://github.com/mwaskom/seaborn/issues/3291\n",
    "df = pd.concat(dfs).reset_index(drop=True).copy()\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].fillna('51')\n",
    "df['preprocessing.num_gesture_classes'] = df['preprocessing.num_gesture_classes'].astype(int).astype(str)\n",
    "\n",
    "df.groupby(['model_type', 'preprocessing.num_gesture_classes']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1f85",
   "metadata": {},
   "source": [
    "## Calculate some auxillary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18c065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:01.775957Z",
     "start_time": "2023-10-01T18:33:01.721338Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data a little bit, and get a list of dependant variables\n",
    "# Preprocess the df a bit to get some nice-to-use columns\n",
    "\n",
    "prefixes = (\n",
    "    'ffnn.nodes_per_layer',\n",
    "    'hffnn.majority.ffnn.nodes_per_layer',\n",
    "    'hffnn.minority.ffnn.nodes_per_layer',\n",
    ")\n",
    "for i in (1, 2, 3):\n",
    "    for prefix in prefixes:\n",
    "        df[f'{prefix}.{i}'] = df[prefix].apply(\n",
    "            lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else None\n",
    "        )\n",
    "\n",
    "# Calculate ratios\n",
    "avgs = ('macro avg', 'weighted avg')\n",
    "metrics = ('f1-score', 'precision', 'recall')\n",
    "\n",
    "for avg in avgs:\n",
    "    for metric in metrics:\n",
    "        df[f'ratio.{avg}.{metric}'] = df[f'trn.{avg}.{metric}'] / df[f'val.{avg}.{metric}']\n",
    "        df[f'ratio.{avg}.{metric}'] = np.where(\n",
    "            np.isfinite(df[f'ratio.{avg}.{metric}']),\n",
    "            df[f'ratio.{avg}.{metric}'],\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "# Print out a list of dependant variables\n",
    "dep_vars = sorted([\n",
    "    c for c in df.columns \n",
    "    if 'val' not in c and 'trn' not in c and 'ratio' not in c and c not in (\n",
    "        'saved_at', 'fit_time', 'preprocessing.gesture_allowlist', \n",
    ")], key=lambda c: str(c))\n",
    "print(f\"Dependant variables: {dep_vars}\")\n",
    "# print(\"\\nVariables which change:\")\n",
    "# max_len = max(map(lambda x: len(x), dep_vars))\n",
    "# Print out all dependant variables that change\n",
    "# for var in dep_vars:\n",
    "#     uniq = df[var].apply(lambda x: str(x) if isinstance(x, list) else x).unique()\n",
    "#     if len(uniq) > 1:\n",
    "#         print(f\"{var: <{max_len}} {uniq}\")\n",
    "        \n",
    "df['ffnn.dropout_rate'] = np.round(df['ffnn.dropout_rate'], 6)\n",
    "\n",
    "df['val.pred_time_per_obs'] = df['val.pred_time'] / df['val.num_observations']\n",
    "df['trn.pred_time_per_obs'] = df['trn.pred_time'] / df['trn.num_observations']\n",
    "df['fit_time_per_obs'] = df['fit_time'] / df['trn.num_observations']\n",
    "\n",
    "# There are a *lot* of columns. Here's a more-useful subset\n",
    "subset_cols = [\n",
    "    c for c in df.columns\n",
    "    if (not re.search(r'((trn|val)\\.\\d+\\.)|weighted avg', c)) and \n",
    "        (c not in [\n",
    "            'hmm', 'lstm', 'ffnn', 'nn', 'hffnn', 'cusum', 'svm',\n",
    "            'preprocessing.n_timesteps',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "            'preprocessing.gesture_allowlist',\n",
    "        ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5643dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:04.669908Z",
     "start_time": "2023-10-01T18:33:03.740548Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "ngestures = ('51', '50', '5')\n",
    "for ax, ngesture in zip(axs, ngestures):\n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == ngesture],\n",
    "        x='saved_at',\n",
    "        y='preprocessing.seed',\n",
    "        hue='model_type',\n",
    "        s=10,\n",
    "    #     alpha=0.1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f'{ngesture} gestures')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49356a4",
   "metadata": {},
   "source": [
    "## Constants to keep colours consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d325959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:06.360045Z",
     "start_time": "2023-10-01T18:33:06.323343Z"
    }
   },
   "outputs": [],
   "source": [
    "model_colours = {\n",
    "    'FFNN': 'tab:blue',\n",
    "    'HFFNN': 'tab:orange',\n",
    "    'CuSUM': 'tab:green',\n",
    "    'HMM': 'tab:red',\n",
    "    'SVM': 'tab:purple',\n",
    "}\n",
    "palette = 'flare'\n",
    "other_colours = [\n",
    "    'tab:brown',\n",
    "    'tab:pink',\n",
    "    'tab:grey',\n",
    "    'tab:olive',\n",
    "    'tab:cyan',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eeb4a",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c94d8c",
   "metadata": {},
   "source": [
    "## Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4427f33",
   "metadata": {},
   "source": [
    "### 51 classes, Precision vs Recall vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:08.787956Z",
     "start_time": "2023-10-01T18:33:08.162478Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(0.1, 1, 10), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.precision',\n",
    "    y='val.macro avg.recall',\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_xlim((-0.1, 1.1))\n",
    "axs[0].set_ylim((-0.1, 1.1))\n",
    "axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0].set_title(f'Precision vs Recall for models trained on 51 classes\\n(contours denote $F_1$)')\n",
    "axs[0].set_xlabel(f'Precision')\n",
    "axs[0].set_ylabel(f'Recall')\n",
    "axs[0].legend().set_title(\"Model \")\n",
    "\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    y='val.macro avg.f1-score',\n",
    "    x='model_type',\n",
    "    s=2,\n",
    "    alpha=0.5,\n",
    "    order=list(model_colours.keys()),\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    ")\n",
    "axs[1].set_title(f'$F_1$-score for models trained on 51 classes')\n",
    "axs[1].set_xlabel(f'Model Type')\n",
    "axs[1].set_ylabel(f'$F_1$-score')\n",
    "axs[1].set_ylim((-0.1, 1.1))\n",
    "axs[1].grid(axis='y')\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_precision_recall_51_classes.pdf', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:30:48.130519Z",
     "start_time": "2023-10-01T18:30:47.677026Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "data = df.loc[\n",
    "    df['preprocessing.num_gesture_classes'] == '51',\n",
    "    ['model_type', 'val.macro avg.recall', 'val.macro avg.precision']\n",
    "].melt(\n",
    "    id_vars=['model_type'], \n",
    "    var_name='metric', \n",
    "    value_name='value'\n",
    ")\n",
    "data['metric'] = data['metric'].replace({\n",
    "    'val.macro avg.recall': 'Recall',\n",
    "    'val.macro avg.precision': 'Precision',\n",
    "})\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x=\"model_type\", \n",
    "    y=\"value\", \n",
    "    hue=\"metric\",\n",
    "    order=list(model_colours.keys()),\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    alpha=0.5,\n",
    "    size=2,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "\n",
    "ax.set_title(f'Precision and recall for all model types')\n",
    "ax.set_xlabel(f'Model Type')\n",
    "ax.set_ylabel(f'Metric Value')\n",
    "ax.legend().set_title(\"Metric\")\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "ax.set_yticklabels(np.round(np.arange(0, 1.1, .1), 1))\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_precision_recall_stripplot.pdf', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1b84",
   "metadata": {},
   "source": [
    "### Precision vs Recall for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760213ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:31:02.212421Z",
     "start_time": "2023-10-01T18:31:01.688939Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "n_gesture_classes = ('51', '50', '5')\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(0, 1, 100), \n",
    "    np.linspace(0, 1, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "for ax, n_classes in zip(axs, n_gesture_classes):\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df[df['preprocessing.num_gesture_classes'] == n_classes],\n",
    "        x='val.macro avg.precision',\n",
    "        y='val.macro avg.recall',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        hue='model_type',\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlim((-0.1, 1.1))\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "    ax.plot([0,1], [0,1], color='black', alpha=.1)\n",
    "    ax.set_title(f'{n_classes} gesture classes')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77f603",
   "metadata": {},
   "source": [
    "## Average Models by hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109bfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:31:07.601765Z",
     "start_time": "2023-10-01T18:31:07.528132Z"
    }
   },
   "outputs": [],
   "source": [
    "type_to_hpars = {\n",
    "    'CuSUM': ['cusum.thresh'],\n",
    "    'HMM': ['hmm.covariance_type'],\n",
    "    'FFNN': [\n",
    "        'ffnn.dropout_rate',\n",
    "        'ffnn.l2_coefficient',\n",
    "        'ffnn.nodes_per_layer.1',\n",
    "        'ffnn.nodes_per_layer.2',\n",
    "        'ffnn.nodes_per_layer.3',\n",
    "        'nn.batch_size',\n",
    "        'nn.learning_rate',\n",
    "    ],\n",
    "    'HFFNN': [\n",
    "        'hffnn.majority.ffnn.dropout_rate',\n",
    "        'hffnn.majority.ffnn.l2_coefficient',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.majority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.majority.nn.epochs',\n",
    "        'hffnn.majority.nn.batch_size',\n",
    "        'hffnn.majority.nn.learning_rate',\n",
    "        'hffnn.minority.ffnn.dropout_rate',\n",
    "        'hffnn.minority.ffnn.l2_coefficient',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.1',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.2',\n",
    "        'hffnn.minority.ffnn.nodes_per_layer.3',\n",
    "        'hffnn.minority.nn.epochs',\n",
    "        'hffnn.minority.nn.batch_size',\n",
    "        'hffnn.minority.nn.learning_rate',\n",
    "    ],\n",
    "    'SVM': ['svm.c', 'svm.class_weight', 'svm.max_iter'],\n",
    "}\n",
    "\n",
    "agg_functions = {\n",
    "    'val.macro avg.f1-score': ['min', 'mean', 'median', 'max', 'std', 'count']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_type, hpars in type_to_hpars.items():\n",
    "    print(model_type, hpars)\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == model_type)\n",
    "    ]\n",
    "    # Group by the specified columns and calculate the statistics for 'metric'\n",
    "    # result_df = df.groupby(hpars)['val.macro avg.f1-score'].mean()\n",
    "    result_df = data.groupby(hpars).agg(agg_functions).reset_index()\n",
    "\n",
    "    # Flatten the multi-level column index\n",
    "    result_df.columns = ['.'.join(col).strip() if col[1] else col[0] for col in result_df.columns.values]\n",
    "    result_df['model_type'] = model_type\n",
    "    results.append(result_df)\n",
    "\n",
    "results_df = pd.concat(results)\n",
    "results_df\n",
    "# df[hpars]\n",
    "# TODO delete all the old observations which only have one repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c6477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:31:10.156588Z",
     "start_time": "2023-10-01T18:31:09.869811Z"
    }
   },
   "outputs": [],
   "source": [
    "hpars = [\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "for hpar, ax in zip(hpars, axs.flatten()):\n",
    "    sns.scatterplot(\n",
    "        data=result_df,\n",
    "        x=hpar,\n",
    "        y='val.macro avg.f1-score.mean',\n",
    "        ax=ax,\n",
    "    )\n",
    "#     result_df[hpar]\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0e507",
   "metadata": {},
   "source": [
    "## Top X performing models by precision/recall/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c55ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:17.549177Z",
     "start_time": "2023-10-01T18:33:15.728934Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Since every model gets 5 repetitions, the \"top 5\" will likely only contain one model.\n",
    "top_n = 9\n",
    "metric = 'val.macro avg.f1-score'\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "].sort_values(metric, ascending=False).head(top_n)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    best = data.iloc[i]\n",
    "    show_conf_mat_from_model(f\"../{best['model_dir']}\", ax)\n",
    "    ax.set(\n",
    "        title=f\"{best['model_type']}\\n$F_1=${np.round(best['val.macro avg.f1-score'], 4)}\",\n",
    "    )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102c42e",
   "metadata": {},
   "source": [
    "## Get statistics for each hyperparameter combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33406a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T15:15:03.704128Z",
     "start_time": "2023-09-29T15:15:03.662800Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') & \n",
    "    (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "    (df['preprocessing.seed'] == 42.0)\n",
    "]\n",
    "\n",
    "data[[c for c in subset_cols if 'ffnn.' in c or 'nn.' in c]].head(31)\n",
    "data[subset_cols].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78772aa",
   "metadata": {},
   "source": [
    "## Training vs Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f55e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:49.883374Z",
     "start_time": "2023-10-01T18:33:48.373381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0, 2],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['trn.pred_time_per_obs'] < 0.00005)\n",
    "    ],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1, 2],\n",
    ")\n",
    "\n",
    "axs[0, 0].plot([0, 0.1], [0, 0.1], color='black', alpha=.1)\n",
    "axs[0, 1].plot([0, 0.005], [0, 0.005], color='black', alpha=.1)\n",
    "axs[0, 2].plot([0, 0.00005], [0, 0.00005], color='black', alpha=.1)\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference times (seconds per observation)\\n',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[0, 2].set(\n",
    "    title='c) Inference times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Inference time per observation (validation)',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='d) Inference vs training times (seconds per observation)\\n',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 1].set(\n",
    "    title='e) Inference vs training times (seconds per observation)\\n(training time $< 0.005$s)',\n",
    "    xlabel='Inference time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "axs[1, 2].set(\n",
    "    title='f) Inference vs training times (seconds per observation)\\n(training time $< 0.00005$s)',\n",
    "    xlabel='Training time per observation',\n",
    "    ylabel='Inference time per observation (training)',\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title(\"Model Type\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inf_trn_times_per_obs.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2473064",
   "metadata": {},
   "source": [
    "## Inference time vs $F_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e99dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:33:57.234414Z",
     "start_time": "2023-10-01T18:33:56.709209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Three plots showing the precision and recall for all models.\n",
    "# Each plot showing either 51, 50, or 5 gesture classes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_ylim((-0.001, 0.011))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['val.pred_time_per_obs'] < 0.0001)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='val.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    ax=axs[1],\n",
    ")\n",
    "plt.tight_layout()\n",
    "axs[0].set_xlim((-0.05, 1.05))\n",
    "axs[1].set_xlim((-0.05, 1.05))\n",
    "axs[0].set_xlabel('$F_1$-score')\n",
    "axs[1].set_xlabel('$F_1$-score')\n",
    "axs[0].set_ylabel('Inference time per observation (s)')\n",
    "axs[1].set_ylabel('Inference time per observation (s)')\n",
    "axs[0].set_title('Inference time per observation against $F_1$ score\\n')\n",
    "axs[1].set_title('Inference time per observation against $F_1$ score\\n(0 to 0.0001s)')\n",
    "\n",
    "axs[0].legend().set_title(\"Model Type\")\n",
    "axs[1].legend().set_title(\"Model Type\")\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_inference_time_per_obs_vs_f1.pdf', \n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0978408",
   "metadata": {},
   "source": [
    "## Confusion Matrices of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e34da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:03.526459Z",
     "start_time": "2023-10-01T18:33:59.272294Z"
    }
   },
   "outputs": [],
   "source": [
    "ngestures = sorted(df['preprocessing.num_gesture_classes'].unique())\n",
    "model_types = sorted(df['model_type'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(ngestures),\n",
    "    len(model_types),\n",
    "    figsize=(len(model_types)*6, len(ngestures)*6),\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "for i, ngesture in enumerate(ngestures):\n",
    "    for j, model_type in enumerate(model_types):\n",
    "        best = df[\n",
    "            (df['preprocessing.num_gesture_classes'] == ngesture) &\n",
    "            (df['model_type'] == model_type)\n",
    "        ].sort_values('val.macro avg.f1-score', ascending=False)\n",
    "        if len(best) == 0:\n",
    "            continue\n",
    "        best = best.iloc[0]\n",
    "        print(ngesture, model_type, best['model_dir'])\n",
    "        show_conf_mat_from_model(f\"../{best['model_dir']}\", axs[i, j])\n",
    "        axs[i, j].set(\n",
    "            title=f\"Best {model_type}: {ngesture} gestures\\n($F_1=${np.round(best['val.macro avg.f1-score'], 4)})\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1fc7b",
   "metadata": {},
   "source": [
    "## Regularization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a3e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:13.116520Z",
     "start_time": "2023-10-01T18:34:11.153877Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gesture_classes = (\n",
    "    '5', \n",
    "    '50', \n",
    "    '51'\n",
    ")\n",
    "fig, axs = plt.subplots(len(n_gesture_classes), 2, figsize=(6, len(n_gesture_classes)*3))\n",
    "\n",
    "for i, ngestures in enumerate(n_gesture_classes):\n",
    "    data = df[df['preprocessing.num_gesture_classes'] == ngestures]\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.l2_coefficient',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 0]\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='ffnn.dropout_rate',\n",
    "        y='ratio.macro avg.f1-score',\n",
    "        ax=axs[i, 1]\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{ngestures} gestures')\n",
    "    axs[i, 1].set_title(f'{ngestures} gestures')\n",
    "\n",
    "plt.suptitle(\"$F_1$-ratio against regularisation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3fa2",
   "metadata": {},
   "source": [
    "## Ratio $F_1$ scores vs actual $F_1$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:17.160657Z",
     "start_time": "2023-10-01T18:34:16.274237Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "axs[0, 0].set_xlim((-0.05, 1.05))\n",
    "axs[0, 0].set_ylim((-0.05, 1.05))\n",
    "axs[0, 0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 0].set_title(\"a) Training vs Validation $F_1$ score\\n\")\n",
    "axs[0, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 0].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 0].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='trn.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "axs[0, 1].set_xlim((0.5, 1.05))\n",
    "axs[0, 1].set_ylim((0.5, 1.05))\n",
    "axs[0, 1].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "axs[0, 1].set_title(\"b) Training vs Validation $F_1$ score\\n(magnified)\")\n",
    "axs[0, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[0, 1].set_ylabel(\"Training $F_1$\")\n",
    "axs[0, 1].legend().set_title('Model Type')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[df['preprocessing.num_gesture_classes'] == '51'],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "axs[1, 0].set_xlim((-0.05, 1.05))\n",
    "axs[1, 0].set_title(\"c) $F_1$-ratio vs $F_1$-score\\n\")\n",
    "axs[1, 0].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 0].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 0].legend().set_title('Model Type')\n",
    "axs[1, 0].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['val.macro avg.f1-score'] >= 0.5)\n",
    "    ],\n",
    "    x='val.macro avg.f1-score',\n",
    "    y='ratio.macro avg.f1-score',\n",
    "    s=5,\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    alpha=0.5,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "axs[1, 1].set_xlim((0.5, 1.05))\n",
    "axs[1, 1].set_title(\"d) $F_1$-ratio vs $F_1$-score\\n(magnified)\")\n",
    "axs[1, 1].set_xlabel(\"Validation $F_1$\")\n",
    "axs[1, 1].set_ylabel(r\"$F_1$-ratio ($\\frac{Training}{Validation}$)\")\n",
    "axs[1, 1].legend().set_title('Model Type')\n",
    "axs[1, 1].plot([0,1], [1, 1], color='black', alpha=.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_f1_vs_f1_ratio.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe434de1",
   "metadata": {},
   "source": [
    "## Training/validation loss ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acad09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:30.260438Z",
     "start_time": "2023-10-01T18:34:30.021875Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ],\n",
    "    y='val.loss',\n",
    "    x='trn.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == 'FFNN')\n",
    "    ].assign(**{\n",
    "        'ratio.loss': lambda x: x['trn.loss'] / x['val.loss']\n",
    "    }),\n",
    "    x='ratio.loss',\n",
    "    y='val.loss',\n",
    "    color='tab:blue',\n",
    "    s=20,\n",
    "    alpha=0.5,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "\n",
    "axs[0].set_ylim((-0.05, 3.6))\n",
    "axs[1].set_ylim((-0.05, 3.6))\n",
    "\n",
    "axs[1].plot([1, 1], [0, axs[1].get_ylim()[1]], color='black', alpha=.1)\n",
    "\n",
    "min_max = min(axs[0].get_xlim()[1], axs[0].get_ylim()[1] )\n",
    "axs[0].plot([0, min_max], [0, min_max], color='black', alpha=.1)\n",
    "\n",
    "axs[0].set(\n",
    "    title='Validation loss vs training loss\\n(FFNN only)',\n",
    "    xlabel='Training Loss',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "axs[1].set(\n",
    "    title='Validation loss vs loss ratio\\n(FFNN only)',\n",
    "    xlabel=r'Loss ratio ($\\frac{Training}{Validation}$)',\n",
    "    ylabel='Validation Loss',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_val_trn_loss_ratios.pdf'\n",
    ")\n",
    "\n",
    "print(\"TODO: The training and validation loss aren't comparable because the training loss is weighed but validation loss is not.\")\n",
    "print(\"TODO: also not comparable because of dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ee621",
   "metadata": {},
   "source": [
    "## FFNN vs HMM vs CuSUM ($F_1$ scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6f4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:51.397284Z",
     "start_time": "2023-10-01T18:34:50.646255Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df,\n",
    "    x='model_type',\n",
    "    y='val.macro avg.f1-score',\n",
    "    col='preprocessing.num_gesture_classes',\n",
    "    kind='violin',\n",
    ")\n",
    "plt.suptitle('$F_1$-score across different models and different gestures')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034cf83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:16:46.310919Z",
     "start_time": "2023-09-25T12:16:45.936134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subset = df\n",
    "(\n",
    "    so.Plot(\n",
    "        subset.sort_values(['preprocessing.num_gesture_classes', 'model_type']), \n",
    "        x='model_type', \n",
    "        y='val.macro avg.f1-score', \n",
    "        color='model_type'\n",
    "    )\n",
    "    .layout(size=(8, 6))\n",
    "    .add(so.Dots(pointsize=3), so.Jitter())\n",
    "    .facet(row='preprocessing.num_gesture_classes')\n",
    "    .limit(y=(-0.05, 1.05))\n",
    "    .label(\n",
    "        x=\"Model Type\",\n",
    "        color='Model Type',\n",
    "        y=\"Macro Average\\n$F_1$ Score\",\n",
    "        title=\"{} Gesture Classes\".format,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f1a36",
   "metadata": {},
   "source": [
    "## Precision vs Recall plots for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841fa23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:34:59.064056Z",
     "start_time": "2023-10-01T18:34:58.064800Z"
    }
   },
   "outputs": [],
   "source": [
    "for model_type, color in model_colours.items():\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "        & (df['model_type'] == model_type)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "    p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "    r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "    r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "    print(f\"{p_min=}, {p_max=}, {r_min=}, {r_max=}, \")\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(p_min, p_max, 100), \n",
    "        np.linspace(r_min, r_max, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    print(f1_score.min())\n",
    "    contours = ax.contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(\n",
    "            f1_score.min(),\n",
    "            f1_score.max(),\n",
    "            10\n",
    "        ), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        y='val.macro avg.recall',\n",
    "        x='val.macro avg.precision',\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    p_range = p_max - p_min\n",
    "    r_range = r_max - r_min\n",
    "    ax.set(\n",
    "        title=f\"Precision vs Recall For {model_type} models\\n($F_1$ contours in grey)\",\n",
    "        xlabel='Precision',\n",
    "        ylabel='Recall',\n",
    "        xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "        ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_{model_type.lower()}_p_vs_r.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2507bb1",
   "metadata": {},
   "source": [
    "## In depth FFNN plots\n",
    "\n",
    "- Clusters in the recall of different models\n",
    "- Hyperparameters vs f1 score/recall/precision\n",
    "- No correlation with the inference time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49f780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:35:11.013298Z",
     "start_time": "2023-10-01T18:35:09.568067Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = (\n",
    "    'recall',\n",
    "    'precision',\n",
    "    'f1-score',\n",
    ")\n",
    "\n",
    "metric_labels = (\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    '$F_1$',\n",
    ")\n",
    "\n",
    "hyperpars = (\n",
    "    'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "    'ffnn.nodes_per_layer.1',\n",
    "    'ffnn.nodes_per_layer.2',\n",
    "    'ffnn.nodes_per_layer.3',\n",
    ")\n",
    "df[[\n",
    "#     'ffnn.dropout_rate.log10',\n",
    "    'ffnn.l2_coefficient.log10',\n",
    "    'nn.batch_size.log10',\n",
    "    'nn.learning_rate.log10',\n",
    "]] = np.log10(df[[\n",
    "#     'ffnn.dropout_rate',\n",
    "    'ffnn.l2_coefficient',\n",
    "    'nn.batch_size',\n",
    "    'nn.learning_rate',\n",
    "]])\n",
    "xlabels = (\n",
    "    'Dropout Rate',\n",
    "    'L2 Coefficient ($\\log_{10}$)',\n",
    "    'Batch Size ($\\log_{10}$)',\n",
    "    'Learning Rate ($\\log_{10}$)',\n",
    "    'Nodes in Layer 1',\n",
    "    'Nodes in Layer 2',\n",
    "    'Nodes in Layer 3',\n",
    ")\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "    (df['model_type'] == 'FFNN')\n",
    "]\n",
    "\n",
    "\n",
    "for metric, metric_label in zip(metrics, metric_labels):\n",
    "    fig, axs = plt.subplots(\n",
    "        4, 2,\n",
    "        figsize=(4, 8)\n",
    "    )\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y=f'val.macro avg.{metric}',\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'{metric_label} vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel=metric_label,\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_ffnn_hpars_vs_{metric}.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a5a1e",
   "metadata": {},
   "source": [
    "## In depth HFFNN plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056d9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:35:17.773101Z",
     "start_time": "2023-10-01T18:35:16.610072Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error \n",
    "# This cell isn't used\n",
    "\n",
    "maj_min = (\n",
    "    'majority',\n",
    "    'minority',\n",
    ")\n",
    "for submodel in maj_min:\n",
    "    hyperpars = (\n",
    "        f'hffnn.{submodel}.ffnn.dropout_rate',\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.1',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.2',\n",
    "        f'hffnn.{submodel}.ffnn.nodes_per_layer.3',\n",
    "    )\n",
    "    df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient.log10',\n",
    "        f'hffnn.{submodel}.nn.batch_size.log10',\n",
    "        f'hffnn.{submodel}.nn.learning_rate.log10',\n",
    "    ]] = np.log10(df[[\n",
    "        f'hffnn.{submodel}.ffnn.l2_coefficient',\n",
    "        f'hffnn.{submodel}.nn.batch_size',\n",
    "        f'hffnn.{submodel}.nn.learning_rate',\n",
    "    ]])\n",
    "    xlabels = (\n",
    "        f'{submodel.title()} Dropout Rate',\n",
    "        f'{submodel.title()} L2 Coefficient ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Batch Size ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Learning Rate ($\\log_{{10}}$)',\n",
    "        f'{submodel.title()} Nodes in Layer 1',\n",
    "        f'{submodel.title()} Nodes in Layer 2',\n",
    "        f'{submodel.title()} Nodes in Layer 3',\n",
    "    )\n",
    "\n",
    "    data = df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51') &\n",
    "        (df['model_type'] == 'HFFNN')\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        4, 2,\n",
    "        figsize=(6, 12)\n",
    "    )\n",
    "    print(axs.shape)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if len(hyperpars) <= i:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=data,\n",
    "            x=hyperpars[i],\n",
    "            y='val.macro avg.f1-score',\n",
    "            s=10,\n",
    "            ax=ax,\n",
    "            color='tab:orange',\n",
    "        )\n",
    "        title_xlabel = xlabels[i].replace(\" ($\\log_{10}$)\", \"\")\n",
    "        ax.set(\n",
    "            title=f'$F_1$ score vs {title_xlabel}',\n",
    "            xlabel=xlabels[i],\n",
    "            ylabel='$F_1$ score',\n",
    "            ylim=(-0.1, 1.1),\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../../report/src/imgs/graphs/05_in_depth_hffnn_{submodel}_hpars.pdf',\n",
    "        bbox_inches='tight',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e174e",
   "metadata": {},
   "source": [
    "## In depth CuSUM plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849260e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T20:23:52.082295Z",
     "start_time": "2023-10-01T20:23:50.947251Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'CuSUM')\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10,\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='cusum.thresh',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=data,\n",
    "    x='cusum.thresh',\n",
    "    y='val.macro avg.f1-score',\n",
    "    alpha=0.5,\n",
    "    s=5,\n",
    "    ax=axs[1],\n",
    "    jitter=0.5,\n",
    "    color=model_colours['CuSUM'],\n",
    "    native_scale=True,\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "axs[0].set(\n",
    "    title=f\"a) Precision vs Recall for CuSUM models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "axs[0].legend().set_title('Threshold')\n",
    "\n",
    "axs[1].set(\n",
    "    title='b) CuSUM Threshold vs $F_1$ score',\n",
    "    xlabel='CuSUM Threshold',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_cusum_p_vs_r_thresh.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd9c92",
   "metadata": {},
   "source": [
    "## In depth SVM plots\n",
    "\n",
    "- Correlation with the training time per observation\n",
    "- Correlation with the precision/recall/f1\n",
    "- clusters in recall-precision space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f4b7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:47:38.061148Z",
     "start_time": "2023-10-01T18:47:37.547146Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = axs[0].contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='$\\log_{10}(C)$',\n",
    "    style='Class Weight',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=axs[0],\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='$\\log_{10}(C)$',\n",
    "    y='val.macro avg.f1-score',\n",
    "    style='Class Weight',\n",
    "    alpha=0.75,\n",
    "    s=20,\n",
    "    ax=axs[1],\n",
    "    color='tab:purple',\n",
    ")\n",
    "\n",
    "axs[0].set(\n",
    "    title=f\"Precision vs Recall for SVMs\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    ")\n",
    "axs[1].set(\n",
    "    title=f\"SVM Regularization parameter vs $F_1$ score\",\n",
    "    xlabel='SVM Regularization parameter C ($\\log_{10}$)',\n",
    "    ylabel='$F_1$ score',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_svm_p_vs_r_class_weight_C.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364398df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T19:44:03.591846Z",
     "start_time": "2023-10-01T19:44:01.351290Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'svm.class_weight'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(conf_mats), \n",
    "    figsize=(4*len(conf_mats), 4)\n",
    ")\n",
    "\n",
    "\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat_totals[hpar_item]\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} SVMs\\n(Mean of {int(conf_mat_totals[hpar_item])} Confusion Matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_svm_conf_mats_unbalanced.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc36fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T20:13:37.268400Z",
     "start_time": "2023-10-01T20:13:36.721338Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'SVM')\n",
    "]\n",
    "\n",
    "data['svm.c.log10'] = np.log10(data['svm.c'])\n",
    "data['svm.class_weight'] = data['svm.class_weight'].fillna('unbalanced')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'svm.c.log10': '$\\log_{10}(C)$', \n",
    "    'svm.class_weight': 'Class Weight'\n",
    "})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='fit_time_per_obs',\n",
    "    x='$\\log_{10}(C)$',\n",
    "    s=10,\n",
    "    alpha=0.75,\n",
    "#     hue='',\n",
    "    style='Class Weight',\n",
    "    color='tab:purple',\n",
    "    palette=palette,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title='SVM hyperparameters against fit time',\n",
    "    ylabel='Fit time (seconds per observation)',\n",
    "    xlabel='$\\log_{10}(C)$',\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_svm_hpars_vs_fit_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b424d48",
   "metadata": {},
   "source": [
    "## In depth HMM plots\n",
    "\n",
    "- Clusters in recall-precision space\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b8259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:36:05.964598Z",
     "start_time": "2023-10-01T18:36:05.688849Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_type = 'HMM'\n",
    "color='tab:red'\n",
    "    \n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == model_type)\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "p_min = data['val.macro avg.precision'].min() / 1.10\n",
    "p_max = data['val.macro avg.precision'].max() * 1.10\n",
    "r_min = data['val.macro avg.recall'].min()    / 1.10\n",
    "r_max = data['val.macro avg.recall'].max()    * 1.10\n",
    "\n",
    "recall_grid, precision_grid = np.meshgrid(\n",
    "    np.linspace(p_min, p_max, 100), \n",
    "    np.linspace(r_min, r_max, 100)\n",
    ")\n",
    "f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "contours = ax.contour(\n",
    "    recall_grid, \n",
    "    precision_grid,\n",
    "    f1_score, \n",
    "    levels=np.linspace(\n",
    "        f1_score.min(),\n",
    "        f1_score.max(),\n",
    "        10\n",
    "    ), \n",
    "    colors='black',\n",
    "    alpha=0.25\n",
    ")\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    y='val.macro avg.recall',\n",
    "    x='val.macro avg.precision',\n",
    "    hue='hmm.covariance_type',\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    ax=ax,\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "p_range = p_max - p_min\n",
    "r_range = r_max - r_min\n",
    "ax.set(\n",
    "    title=f\"Precision vs Recall for {model_type} models\\n($F_1$ contours in grey)\",\n",
    "    xlabel='Precision',\n",
    "    ylabel='Recall',\n",
    "    xlim=(p_min - p_range*0.025, p_max + p_range*0.025),\n",
    "    ylim=(r_min - r_range*0.025, r_max + r_range*0.025),\n",
    ")\n",
    "\n",
    "ax.legend().set_title('Covariance Type')\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../report/src/imgs/graphs/05_in_depth_hmm_p_vs_r_covar_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2421c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:36:33.112267Z",
     "start_time": "2023-10-01T18:36:32.458367Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 0],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='val.pred_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[0, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data[data['trn.pred_time_per_obs'] <= 0.02],\n",
    "    x='fit_time_per_obs',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    s=10,\n",
    "    alpha=0.5,\n",
    "    hue='hmm.covariance_type',\n",
    "    ax=axs[1, 1],\n",
    "    palette=other_colours\n",
    ")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend().set_title('Covariance Type')\n",
    "\n",
    "axs[0, 0].set(\n",
    "    title='a) Inference time on the Training and Validation sets\\n',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[0, 1].set(\n",
    "    title='b) Inference time on the Training and Validation sets\\n($< 0.02$s)',\n",
    "    xlabel='Validation inference time (seconds per observation)',\n",
    "    ylabel='Training inference time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 0].set(\n",
    "    title='c) Inference and Fitting times\\n',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "axs[1, 1].set(\n",
    "    title='d) Inference and Fitting times\\n($< 0.02$s)',\n",
    "    ylabel='Inference time (seconds per observation)',\n",
    "    xlabel='Fitting time (seconds per observation)',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_inf_trn_time.pdf',\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46718009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T19:43:34.097872Z",
     "start_time": "2023-10-01T19:43:31.363725Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    & (df['model_type'] == 'HMM')\n",
    "]\n",
    "data['hmm.covariance_type'] = data['hmm.covariance_type'].replace({\n",
    "    'spherical': 'Spherical',\n",
    "    'diag': 'Diagonal',\n",
    "    'full': 'Full',\n",
    "    'tied': 'Tied',\n",
    "})\n",
    "\n",
    "conf_mats = {}\n",
    "conf_mat_totals = {}\n",
    "\n",
    "hpar = 'hmm.covariance_type'\n",
    "\n",
    "assert len(data[hpar].unique()) < 10\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    y_true, y_pred = get_npz_data_from_model('../' + row['model_dir'])\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true.flatten(), \n",
    "        y_pred.flatten()\n",
    "    ).numpy()\n",
    "    hpar_item = row[hpar]\n",
    "    \n",
    "    if hpar_item in conf_mats:\n",
    "        conf_mats[hpar_item] += cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] += 1.0\n",
    "    else:\n",
    "        conf_mats[hpar_item] = cm.astype(float)\n",
    "        conf_mat_totals[hpar_item] = 1.0\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,2,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "axs = axs.flatten()\n",
    "for i, (hpar_item, conf_mat) in enumerate(conf_mats.items()):\n",
    "    conf_mat[-1, -1] = 0\n",
    "    conf_mat /= conf_mat_totals[hpar_item]\n",
    "    vis.conf_mat(conf_mat, ax=axs[i], norm=None)\n",
    "    axs[i].set_title(\n",
    "        f'{hpar_item.title()} HMMs\\n(Mean of {int(conf_mat_totals[hpar_item])} Confusion Matrices)'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../../report/src/imgs/graphs/05_in_depth_hmm_conf_mats_cov_type.pdf',\n",
    "    bbox_inches='tight',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127c75f",
   "metadata": {},
   "source": [
    "## FFNN Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763743c",
   "metadata": {},
   "source": [
    "### Heatmap-based pairplot of FFNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cf8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:37:11.585431Z",
     "start_time": "2023-10-01T18:37:09.831557Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data = df[\n",
    "    (df['model_type'] == 'FFNN') &\n",
    "    (df['preprocessing.num_gesture_classes'] == '51')\n",
    "]\n",
    "\n",
    "hpars_scale = [\n",
    "    ('nn.learning_rate',       'log10'),\n",
    "    ('ffnn.nodes_per_layer.1', 'log10'),\n",
    "    ('ffnn.l2_coefficient',    'log10'),\n",
    "    ('ffnn.dropout_rate',      'linear'),\n",
    "]\n",
    "# x_var_idx = 0\n",
    "# y_var_idx = 1\n",
    "def contour_nicely(x, y, z, xlabel, ylabel, xscale, yscale, fig, ax, levels=8):\n",
    "\n",
    "    ax.tricontour(x, y, z, levels=levels, linewidths=0.25, colors='k')\n",
    "    cntr2 = ax.tricontourf(x, y, z, levels=levels, cmap=palette)\n",
    "\n",
    "    fig.colorbar(cntr2, ax=ax)\n",
    "    ax.scatter(x, y, color='white', s=1)\n",
    "\n",
    "    ax.set_xlabel(f'{xlabel} ({xscale})')\n",
    "    if xscale == 'log10':\n",
    "        ax.set_xticks(ax.get_xticks())\n",
    "        ax.set_xticklabels([f'{np.power(10, t):.3g}' for t in ax.get_xticks()])\n",
    "\n",
    "    ax.set_ylabel(f'{ylabel} ({yscale})')\n",
    "    if yscale == 'log10':\n",
    "        ax.set_yticks(ax.get_yticks())\n",
    "        ax.set_yticklabels([f'{np.power(10, t):.3g}' for t in ax.get_yticks()])\n",
    "\n",
    "    ax.set_title(f'{xlabel} vs {ylabel}')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(\n",
    "    len(hpars_scale), \n",
    "    len(hpars_scale), \n",
    "    dpi=200, \n",
    "    squeeze=False,\n",
    "    figsize=(20,20)\n",
    ")\n",
    "z = data['val.macro avg.f1-score'].values\n",
    "for x_var_idx in range(len(hpars_scale)):\n",
    "    for y_var_idx in range(x_var_idx+1, len(hpars_scale)):\n",
    "    \n",
    "        x = data[hpars_scale[x_var_idx][0]].values\n",
    "        if hpars_scale[x_var_idx][1] == 'log10':\n",
    "            x = np.log10(x)\n",
    "        elif hpars_scale[x_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[x_var_idx][0]} is not implemented\")\n",
    "        y = data[hpars_scale[y_var_idx][0]].values\n",
    "        if hpars_scale[y_var_idx][1] == 'log10':\n",
    "            y = np.log10(y)\n",
    "        elif hpars_scale[y_var_idx][1] != 'linear':\n",
    "            raise NotImplementedError(f\"Scale {hpars_scale[y_var_idx][0]} is not implemented\")\n",
    "            \n",
    "        contour_nicely(\n",
    "            y, x, z,\n",
    "            hpars_scale[y_var_idx][0],\n",
    "            hpars_scale[x_var_idx][0],\n",
    "            hpars_scale[y_var_idx][1],\n",
    "            hpars_scale[x_var_idx][1],\n",
    "            fig, axs[x_var_idx, y_var_idx]\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d59541",
   "metadata": {},
   "source": [
    "## Plot inference/training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e10eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:39:24.368180Z",
     "start_time": "2023-10-01T18:39:23.890928Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'fit_time_per_obs': lambda x: x['fit_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='fit_time_per_obs',\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'trn.pred_time_per_obs': lambda x: x['trn.pred_time'] / x['trn.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='trn.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()\n",
    "sns.stripplot(\n",
    "    data=df[\n",
    "        (df['preprocessing.num_gesture_classes'] == '51')\n",
    "    ].assign(**{\n",
    "        'val.pred_time_per_obs': lambda x: x['val.pred_time'] / x['val.num_observations']\n",
    "    }),\n",
    "    x='model_type',\n",
    "    y='val.pred_time_per_obs',\n",
    "    hue='model_type',\n",
    "    hue_order=list(model_colours.keys()),\n",
    "    order=list(model_colours.keys()),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181109be",
   "metadata": {},
   "source": [
    "## Example Confusion Matrices from baseline models\n",
    "\n",
    "TODO: Also include models with perfect precision / perfect recall / perfect precision for non-g255 gestures / perfect precision for g255 / perfect recall for non-g255 gestures / perfect recall for g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640592fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:39:55.405943Z",
     "start_time": "2023-10-01T18:39:54.570065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d36d37",
   "metadata": {},
   "source": [
    "### Plot a model that only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81fc63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:39:56.013918Z",
     "start_time": "2023-10-01T18:39:55.968706Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A function for plotting precision-recall + confusion matrices\n",
    "def plt_pr_conf_mat(y_true, y_preds):\n",
    "    \"\"\"Given true and predicted labels, \n",
    "    create a confusion matrix and a precision-recall plot.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "    if len(y_preds.shape) == 1:\n",
    "        y_preds = np.array([y_preds])\n",
    "    # Confusion matrix\n",
    "    # Get the median confusion matrix\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    cm_sum = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for y_pred in y_preds:\n",
    "        cm_sum += tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "    cm = cm_sum / len(y_preds)\n",
    "    vis.conf_mat(cm, ax=axs[1])\n",
    "    \n",
    "    f1_sum = 0\n",
    "    for y_pred in y_preds:\n",
    "        f1_sum += sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_sum / len(y_preds)\n",
    "\n",
    "    # Precision-recall plot\n",
    "    recall_grid, precision_grid = np.meshgrid(\n",
    "        np.linspace(0, 1, 100), \n",
    "        np.linspace(0, 1, 100)\n",
    "    )\n",
    "    f1_score = 2 * (precision_grid * recall_grid) / (precision_grid + recall_grid)\n",
    "\n",
    "    contours = axs[0].contour(\n",
    "        recall_grid, \n",
    "        precision_grid,\n",
    "        f1_score, \n",
    "        levels=np.linspace(0.1, 1, 10), \n",
    "        colors='black',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    axs[0].clabel(contours, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "    ps = []\n",
    "    rs = []\n",
    "    for y_pred in y_preds:\n",
    "        ps.append(sklearn.metrics.precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "        rs.append(sklearn.metrics.recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    p = np.mean(ps)\n",
    "    r = np.mean(rs)\n",
    "\n",
    "    axs[0].scatter(\n",
    "        ps, rs,\n",
    "        color='black',\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    axs[0].set_xlabel('Precision')\n",
    "    axs[0].set_ylabel('Recall')\n",
    "    axs[0].set_xlim((-0.01, 1.01))\n",
    "    axs[0].set_ylim((-0.01, 1.01))\n",
    "    axs[0].plot([0,1], [0,1], color='black', alpha=.1)\n",
    "#     axs[0].set_title(f'Precision-Recall Graph\\n(contours indicate the $F_1$-score)')\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff657758",
   "metadata": {},
   "source": [
    "#### Only predicts the non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da06a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:39:58.028965Z",
     "start_time": "2023-10-01T18:39:57.354615Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Only predicts 50\n",
    "y_pred = np.full(y_trn.shape, 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_pred);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_only_50.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa4bba",
   "metadata": {},
   "source": [
    "#### Completely random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:03.750839Z",
     "start_time": "2023-10-01T18:39:58.549383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts randomly\n",
    "y_preds = np.random.randint(0, 51, size=(30, y_trn.shape[0]))\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_random_preds.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894af3ed",
   "metadata": {},
   "source": [
    "#### Wrong orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da562bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:07.149411Z",
     "start_time": "2023-10-01T18:40:03.814405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong orientation\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn_repeated + 10*np.random.randint(\n",
    "        -(y_trn_repeated // 10), \n",
    "        +(5 - y_trn_repeated // 10), \n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_orientation.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78100f19",
   "metadata": {},
   "source": [
    "#### Wrong finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdaab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:10.531322Z",
     "start_time": "2023-10-01T18:40:07.216532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong finger\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 10), \n",
    "        +(10 - np.mod(y_trn_repeated, 10)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba12ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:13.917797Z",
     "start_time": "2023-10-01T18:40:10.596426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts wrong finger (but correct hand)\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "\n",
    "y_preds = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn_repeated != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn_repeated + np.random.randint(\n",
    "        -np.mod(y_trn_repeated, 5), \n",
    "        +(5 - np.mod(y_trn_repeated, 5)),\n",
    "        y_trn_repeated.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_wrong_finger_correct_hand.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072cb6",
   "metadata": {},
   "source": [
    "#### Predict 50 as a random gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35c745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:19.050194Z",
     "start_time": "2023-10-01T18:40:13.982160Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_no_gesture_50.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32086956",
   "metadata": {},
   "source": [
    "#### High recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74628a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:24.218325Z",
     "start_time": "2023-10-01T18:40:19.115150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 30, axis=0)\n",
    "y_preds = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn_repeated == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 51, y_trn_repeated.shape), \n",
    "    # else keep it the same\n",
    "    y_trn_repeated\n",
    ")\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_recall.pdf', bbox_inches='tight')\n",
    "\n",
    "f1_scores = []\n",
    "for y_pred in y_preds:\n",
    "    f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "f1_scores = np.array(f1_scores)\n",
    "print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801984",
   "metadata": {},
   "source": [
    "#### High precision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88419278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:25.086417Z",
     "start_time": "2023-10-01T18:40:24.477681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts 50 as random gesture\n",
    "y_trn_repeated = np.repeat(y_trn[np.newaxis, :], 5, axis=0)\n",
    "y_preds = np.where(\n",
    "    y_trn_repeated == 50,\n",
    "    y_trn_repeated,\n",
    "    50,\n",
    ")\n",
    "\n",
    "# np.clip(np.random.randint(-1, 1, size=y_trn_repeated.shape) + y_trn_repeated, 0, 50)\n",
    "fig, axs = plt_pr_conf_mat(y_trn, y_preds);\n",
    "# plt.savefig('../../report/src/imgs/graphs/05_pr_conf_mat_high_precision.pdf', bbox_inches='tight')\n",
    "\n",
    "# f1_scores = []\n",
    "# for y_pred in y_preds:\n",
    "#     f1_scores.append(sklearn.metrics.f1_score(y_trn, y_pred, average='macro', zero_division=0))\n",
    "# f1_scores = np.array(f1_scores)\n",
    "# print(f1_scores.min(), f1_scores.mean(), f1_scores.std(), f1_score.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f508a",
   "metadata": {},
   "source": [
    "### Finally, plot all confusion matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fdc45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:40:28.663260Z",
     "start_time": "2023-10-01T18:40:25.150956Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Random model:\n",
    "y_pred = np.random.randint(0, 51, y_trn.shape)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[0])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[0].set_title(f\"Random model\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Only predicts 50\n",
    "y_pred = np.full(y_trn.shape, 50)\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[1])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[1].set_title(f\"Only predicts 50\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random orientation:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Add/subtract some random multiple of 10\n",
    "    y_trn + 10*np.random.randint(\n",
    "        -(y_trn // 10), \n",
    "        +(5 - y_trn // 10), \n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # Else do nothing\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[2])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[2].set_title(f\"Perfect,\\nbut random orientation\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger:\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 10), \n",
    "        +(10 - np.mod(y_trn, 10)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[3])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[3].set_title(f\"Perfect,\\nbut random finger\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Perfect, but random finger (same hand):\n",
    "y_pred = np.where(\n",
    "    # If the gesture is not g255\n",
    "    y_trn != 50, \n",
    "    # Then change only the last digit\n",
    "    y_trn + np.random.randint(\n",
    "        -np.mod(y_trn, 5), \n",
    "        +(5 - np.mod(y_trn, 5)),\n",
    "        y_trn.shape\n",
    "    ), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(y_trn, y_pred).numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[4])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[4].set_title(f\"Perfect,\\nbut random finger on the correct hand\\n$F_1$={f1:.4}\")\n",
    "\n",
    "# Never predicts 50\n",
    "y_pred = np.where(\n",
    "    # If the gesture IS g255\n",
    "    y_trn == 50, \n",
    "    # Then choose a random non-g255 gesture\n",
    "    np.random.randint(0, 50, y_trn.shape), \n",
    "    # else keep it the same\n",
    "    y_trn\n",
    ")\n",
    "cm_val = tf.math.confusion_matrix(\n",
    "    y_trn, \n",
    "    y_pred,\n",
    ").numpy()\n",
    "vis.conf_mat(cm_val, ax=axs[5])\n",
    "f1 = sklearn.metrics.f1_score(y_trn, y_pred, average='macro')\n",
    "axs[5].set_title(f\"Perfect,\\nbut predicts 50 as a random gesture\\n$F_1$={f1:.4}\")\n",
    "\n",
    "plt.savefig('../../report/src/imgs/graphs/05_example_conf_mats.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fa9de",
   "metadata": {},
   "source": [
    "## PCA decomposition only including the gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f03a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:45:13.827723Z",
     "start_time": "2023-09-26T09:45:12.668924Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:45:16.456473Z",
     "start_time": "2023-09-26T09:45:15.559368Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped[y_trn != 50])\n",
    "\n",
    "argsort = np.argsort(y_trn[y_trn != 50])\n",
    "\n",
    "hues = np.array([ \"0°\", \"45°\", \"90°\", \"135°\", \"180°\" ])\n",
    "styles = np.array([ \"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"R5\", \"R4\", \"R3\", \"R2\", \"R1\" ])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=300)\n",
    "sns.scatterplot(\n",
    "    x=X_tfrm[:, 0][argsort],\n",
    "    y=X_tfrm[:, 1][argsort],\n",
    "    hue=hues[(y_trn[y_trn != 50][argsort] // 10)],\n",
    "    style=styles[(y_trn[y_trn != 50][argsort] % 10)],\n",
    "    s=10,\n",
    "    ax=ax\n",
    ")\n",
    "plt.title(\"PCA plot of the training data\\nExcluding gesture 50\")\n",
    "# TODO maybe have an overlay of the datapoints that the model gets wrong?\n",
    "# TODO 3D plot would be cool, but it just kinda hangs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad306d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:47:54.802270Z",
     "start_time": "2023-09-26T09:47:54.758507Z"
    }
   },
   "source": [
    "## PCA plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edd801",
   "metadata": {},
   "source": [
    "### PCA decomposition including non-gesture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f8d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:45:24.253769Z",
     "start_time": "2023-09-26T09:45:17.833824Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfc1ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:45:24.253769Z",
     "start_time": "2023-09-26T09:45:17.833824Z"
    }
   },
   "outputs": [],
   "source": [
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=300)\n",
    "mask = (y_trn == 50)\n",
    "ax.scatter(\n",
    "    X_tfrm[:, 0][mask],\n",
    "    X_tfrm[:, 1][mask],\n",
    "    color='black',\n",
    "    alpha=0.1,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "ax.scatter(\n",
    "    X_tfrm[:, 0][~mask],\n",
    "    X_tfrm[:, 1][~mask],\n",
    "    color=colours[(y_trn[~mask] // 10)],\n",
    "    alpha=0.75,\n",
    "    s=5,\n",
    "    edgecolor='none',\n",
    ")\n",
    "# plt.title(\"PCA plot of the training data\\nExcluding gesture 50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4231b",
   "metadata": {},
   "source": [
    "### PCA plot showing just an interesting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T10:17:51.401883Z",
     "start_time": "2023-09-26T10:17:47.486609Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec25ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T10:31:32.576368Z",
     "start_time": "2023-09-26T10:31:32.373167Z"
    },
    "code_folding": [
     2,
     8
    ]
   },
   "outputs": [],
   "source": [
    "colours = np.array([ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"])\n",
    "\n",
    "@interact(\n",
    "    x_start=(-1500, 1500, 50),\n",
    "    y_start=(-1500, 1500, 50),\n",
    "    x_length=(-1500, 1500, 50),\n",
    "    y_length=(-1500, 1500, 50),\n",
    ")\n",
    "def fn(x_start=-150, y_start=1000, x_length=500, y_length=500):\n",
    "    x_finsh = x_start + x_length\n",
    "    y_finsh = y_start + y_length\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "\n",
    "    selection_mask = (\n",
    "        (x_start <= X_tfrm[:, 0]) & (X_tfrm[:, 0] <= x_finsh) &\n",
    "        (y_start <= X_tfrm[:, 1]) & (X_tfrm[:, 1] <= y_finsh)\n",
    "    )\n",
    "    X_subset = X_tfrm[selection_mask]\n",
    "    y_subset = y_trn[selection_mask]\n",
    "#     ax.scatter(\n",
    "#         X_subset[:, 0],\n",
    "#         X_subset[:, 1],\n",
    "#         c='black',\n",
    "#         alpha=0.1,\n",
    "#     )\n",
    "    \n",
    "    y_mask = (y_trn == 50)\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset == 50],\n",
    "        X_subset[:, 1][y_subset == 50],\n",
    "        color='black',\n",
    "        alpha=0.1,\n",
    "        s=20,\n",
    "        edgecolor='none',\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_subset[:, 0][y_subset != 50],\n",
    "        X_subset[:, 1][y_subset != 50],\n",
    "        color=colours[(y_subset[y_subset != 50] // 10)],\n",
    "        alpha=0.75,\n",
    "#         s=5,\n",
    "        edgecolor='none',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d3579",
   "metadata": {},
   "source": [
    "### PCA plot that connects sequential datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa9f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T10:45:20.632118Z",
     "start_time": "2023-09-26T10:45:16.686722Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reshaped = X_trn.reshape((X_trn.shape[0], 600))\n",
    "X_tfrm = pca.fit_transform(X_reshaped)\n",
    "\n",
    "order = np.argsort(dt_trn)\n",
    "X_tfrm = X_tfrm[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T10:46:31.707735Z",
     "start_time": "2023-09-26T10:46:31.508188Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "limit = 1000\n",
    "@interact(start=(0, len(X_tfrm), 25), length=(0, len(X_tfrm), 50))\n",
    "def fn(start=0, length=500):\n",
    "    finsh = min(start + length, len(X_tfrm))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=100)\n",
    "    ax.plot(\n",
    "        X_tfrm[:, 0][start:finsh],\n",
    "        X_tfrm[:, 1][start:finsh],\n",
    "        zorder=0,\n",
    "        c='black',\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_tfrm[:, 0][start:finsh],\n",
    "        y=X_tfrm[:, 1][start:finsh],\n",
    "        hue=dt_trn[order][start:finsh],\n",
    "        legend=False,\n",
    "        s=(10 + 90*(y_trn != 50)[order][start:finsh]),\n",
    "        edgecolor=np.where((y_trn != 50)[order][start:finsh], 'black', 'none'),\n",
    "        linewidth=.5,\n",
    "    )\n",
    "    \n",
    "    idxs = np.nonzero(y_trn[order][start:finsh] != 50)[0]\n",
    "    for idx in idxs:\n",
    "        ax.text(\n",
    "            X_tfrm[start:finsh][idx, 0],\n",
    "            X_tfrm[start:finsh][idx, 1],\n",
    "            y_trn[order][start:finsh][idx],\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "#     ax.set_xlim((\n",
    "#         X_tfrm[:, 0].min() / 1.1,\n",
    "#         X_tfrm[:, 0].max() * 1.1,\n",
    "#     ))\n",
    "#     ax.set_ylim((\n",
    "#         X_tfrm[:, 1].min() / 1.1,\n",
    "#         X_tfrm[:, 1].max() * 1.1,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e39f0",
   "metadata": {},
   "source": [
    "### PCA plot of a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6f0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:46:20.782854Z",
     "start_time": "2023-09-26T09:46:20.758163Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = (\n",
    "    (,),\n",
    "    (,),\n",
    ")\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5233e5",
   "metadata": {},
   "source": [
    "## Visualise mis-predictions\n",
    "\n",
    "1. Load in a continuous dataset\n",
    "2. Load in a classifier\n",
    "3. Use the classifier to make predictions on the dataset\n",
    "4. Visualise the mispredictions, but *with context*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8970",
   "metadata": {},
   "source": [
    "### Load in a model for which to evaluate the mis-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58bae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T12:05:35.774660Z",
     "start_time": "2023-09-18T12:05:31.996341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the dataset/classifier\n",
    "(\n",
    "    X_trn, X_val, y_trn, y_val, dt_trn, dt_val\n",
    ") = common.read_and_split_from_npz(\"../gesture_data/trn_20_10.npz\")\n",
    "\n",
    "clf = models.load_tf('../src/saved_models/ffnn_2023-09-18T14:05:16.363404')\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce0a33",
   "metadata": {},
   "source": [
    "### Visualise True and Mispredicted gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61f5b4",
   "metadata": {},
   "source": [
    "Plot all the observations which have the ground truth being gesture 255 but the model is not predicting g255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a359ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T12:05:39.601069Z",
     "start_time": "2023-09-18T12:05:38.540882Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "for gidx in np.unique(y_val):\n",
    "    if gidx == 50: continue\n",
    "    pred_indxs = np.nonzero((y_val == 50) & (y_pred == gidx))[0]\n",
    "    true_indxs = np.nonzero(y_val == gidx)[0]\n",
    "    axs = vis.cmp_ts(\n",
    "        X_val[true_indxs],\n",
    "    )\n",
    "    vis.cmp_ts(\n",
    "        X_val[pred_indxs],\n",
    "        color='tab:red',\n",
    "        axs=axs,\n",
    "    )\n",
    "\n",
    "#     distances = np.abs(true_indxs[:, np.newaxis] - pred_indxs).min(axis=0)\n",
    "\n",
    "    plt.suptitle(f'Model predicted {gidx}, ground truth: 50 \\\n",
    "                 \\nGesture {gidx} in grey, mispredicted in red ({len(pred_indxs)} observations) \\\n",
    "                 \\nindices: {pred_indxs}')\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'../src/notebooks/pred_{gidx:0>2}_truth_50.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     if gidx > 5:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1601b8",
   "metadata": {},
   "source": [
    "# Interactive plot to see data at a certain time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T09:46:40.284227Z",
     "start_time": "2023-09-15T09:46:39.175451Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "#     constants_path='../src/constants.yaml',\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "\n",
    "@interact(dt='2022-10-08T20:23:46.665276000')\n",
    "def fn(dt='2022-10-08T20:23:46.665276000'):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    mask = df['datetime'].between(\n",
    "        dt - pd.to_timedelta(1, 'second'),\n",
    "        dt + pd.to_timedelta(1, 'second')\n",
    "    )\n",
    "    \n",
    "    vis.cmp_ts(\n",
    "        [df.loc[mask, sensor_names].values]\n",
    "    )\n",
    "#     ax.plot(\n",
    "#         df.loc[mask, sensor_names].values\n",
    "#     )\n",
    "#     dt_labels = df.loc[mask, 'datetime']\n",
    "#     gidx_labels = df.loc[mask, 'gidx']\n",
    "#     ax.set_xticks(range(len(dt_labels)))\n",
    "#     ax.set_xticklabels([\n",
    "#         f'{gidx_label} {str(dt_label)[5:-3]}'\n",
    "#         for dt_label, gidx_label\n",
    "#         in zip(dt_labels, gidx_labels)\n",
    "#     ], rotation=90)\n",
    "# 2022-10-08T20:23:46.665276000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61445582",
   "metadata": {},
   "source": [
    "# Misc Research Chapter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f431f5",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100164fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T08:44:08.199377Z",
     "start_time": "2023-09-26T08:44:07.536712Z"
    }
   },
   "outputs": [],
   "source": [
    "df = read.read_data(\n",
    "    '../gesture_data/train/', \n",
    "    constants_path='../src/constants.yaml'\n",
    ")\n",
    "df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "const = common.read_constants('../src/constants.yaml')\n",
    "sensor_names = list(const['sensors'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311f86",
   "metadata": {},
   "source": [
    "## Time-series heatmap + line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf9df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T16:48:19.768002Z",
     "start_time": "2023-09-25T16:48:18.958310Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plt_subset(s, f):\n",
    "    df = read.read_data(\n",
    "        '../gesture_data/train/', \n",
    "        constants_path='../src/constants.yaml'\n",
    "    )\n",
    "    df['gidx'] = df['gesture'].apply(lambda g: int(g[-4:]) if g != 'gesture0255' else 50)\n",
    "    const = common.read_constants('../src/constants.yaml')\n",
    "    sensor_names = list(const['sensors'].values())\n",
    "    data = df[sensor_names].values[s:f]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        data.T,\n",
    "        ax=axs[0],\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    axs[1].plot(\n",
    "        data,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    plt.margins(0)\n",
    "    plt.show()\n",
    "# plt_subset(91_000, 95_000)\n",
    "plt_subset(93_000, 93_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46355c0e",
   "metadata": {},
   "source": [
    "## Histogram of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b45e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T17:49:46.430330Z",
     "start_time": "2023-09-25T17:49:46.221789Z"
    }
   },
   "outputs": [],
   "source": [
    "df['gidx'].hist()\n",
    "plt.show()\n",
    "df.loc[df['gidx'] != 50, 'gidx'].hist()\n",
    "df['gidx'].value_counts() / len(df['gidx']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da38f",
   "metadata": {},
   "source": [
    "## All observations of one gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de297a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T18:19:32.710811Z",
     "start_time": "2023-09-25T18:19:30.874601Z"
    }
   },
   "outputs": [],
   "source": [
    "gidx = 0\n",
    "before = 10\n",
    "after = 10\n",
    "idxs = np.nonzero(df['gidx'] == gidx)[0][:, np.newaxis] + np.arange(-before, after+1)\n",
    "\n",
    "vis.cmp_ts(df[sensor_names].values[idxs + 10]);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20810d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T18:17:33.798479Z",
     "start_time": "2023-09-25T18:17:33.773480Z"
    }
   },
   "outputs": [],
   "source": [
    "np.arange(-before, after+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01077c33",
   "metadata": {},
   "source": [
    "## 3D plot of the raw acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c84cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T08:52:58.212143Z",
     "start_time": "2023-09-26T08:52:58.001314Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vals = df[['l5x', 'l5y', 'l5z']].values[:10000]\n",
    "ax.plot(\n",
    "    vals[:, 0], \n",
    "    vals[:, 1], \n",
    "    vals[:, 2], \n",
    "    label='3D Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97194d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6face1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo-venv",
   "language": "python",
   "name": "ergo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
